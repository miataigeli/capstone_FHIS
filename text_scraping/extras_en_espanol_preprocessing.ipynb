{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra en Espanol Transcript Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textract\n",
      "  Downloading textract-1.6.3-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: chardet==3.0.4 in c:\\users\\dasha\\miniconda3\\lib\\site-packages (from textract) (3.0.4)\n",
      "Collecting argcomplete==1.10.0\n",
      "  Downloading argcomplete-1.10.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting beautifulsoup4==4.8.0\n",
      "  Downloading beautifulsoup4-4.8.0-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\dasha\\miniconda3\\lib\\site-packages (from beautifulsoup4==4.8.0->textract) (2.0.1)\n",
      "Collecting docx2txt==0.8\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.3.0 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
      "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.20.1+mkl which is incompatible.\n",
      "tensorflow 2.3.0 requires opt-einsum>=2.3.2, but you have opt-einsum 0+untagged.61.gd905544.dirty which is incompatible.\n",
      "tensorflow 2.3.0 requires scipy==1.4.1, but you have scipy 1.6.0 which is incompatible.\n",
      "tensorflow 2.3.0 requires tensorflow-estimator<2.4.0,>=2.3.0, but you have tensorflow-estimator 2.4.0 which is incompatible.\n",
      "pipwin 0.5.1 requires beautifulsoup4>=4.9.0, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
      "google-api-core 1.25.1 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting EbookLib==0.17.1\n",
      "  Downloading EbookLib-0.17.1.tar.gz (111 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\dasha\\miniconda3\\lib\\site-packages (from EbookLib==0.17.1->textract) (4.6.2)\n",
      "Collecting extract-msg==0.23.1\n",
      "  Downloading extract_msg-0.23.1-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: olefile==0.46 in c:\\users\\dasha\\miniconda3\\lib\\site-packages (from extract-msg==0.23.1->textract) (0.46)\n",
      "Collecting imapclient==2.1.0\n",
      "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
      "Collecting pdfminer.six==20181108\n",
      "  Downloading pdfminer.six-20181108-py2.py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dasha\\miniconda3\\lib\\site-packages (from pdfminer.six==20181108->textract) (2.3.0)\n",
      "Collecting python-pptx==0.6.18\n",
      "  Downloading python-pptx-0.6.18.tar.gz (8.9 MB)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\dasha\\miniconda3\\lib\\site-packages (from python-pptx==0.6.18->textract) (8.1.0)\n",
      "Collecting six==1.12.0\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting SpeechRecognition==3.8.1\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Collecting tzlocal==1.5.1\n",
      "  Downloading tzlocal-1.5.1.tar.gz (16 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\dasha\\miniconda3\\lib\\site-packages (from tzlocal==1.5.1->extract-msg==0.23.1->textract) (2020.5)\n",
      "Collecting xlrd==1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Downloading XlsxWriter-1.4.3-py2.py3-none-any.whl (149 kB)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.10.1-cp35-abi3-win_amd64.whl (1.6 MB)\n",
      "Building wheels for collected packages: docx2txt, EbookLib, python-pptx, tzlocal\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3966 sha256=dcd03dd1115dc2654621b2bf03db824b2e51d27783a94c4be992d0b5455a9436\n",
      "  Stored in directory: c:\\users\\dasha\\appdata\\local\\pip\\cache\\wheels\\55\\f0\\2c\\81637d42670985178b77df6d41b9b6c6dc18c94818447414b9\n",
      "  Building wheel for EbookLib (setup.py): started\n",
      "  Building wheel for EbookLib (setup.py): finished with status 'done'\n",
      "  Created wheel for EbookLib: filename=EbookLib-0.17.1-py3-none-any.whl size=38162 sha256=32ef553600f7ec2f6236eba2c0c502dd95ef33efe0b340080b1b5eb607834db0\n",
      "  Stored in directory: c:\\users\\dasha\\appdata\\local\\pip\\cache\\wheels\\b4\\eb\\66\\00c65b5bbf31ec34329090ec9fe8c8a8d9cb7a3a3d93841386\n",
      "  Building wheel for python-pptx (setup.py): started\n",
      "  Building wheel for python-pptx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-pptx: filename=python_pptx-0.6.18-py3-none-any.whl size=275704 sha256=b695aeb3cf9f96dec656e088e9bffc605149b924f648c76dff30ee9890c49e9a\n",
      "  Stored in directory: c:\\users\\dasha\\appdata\\local\\pip\\cache\\wheels\\11\\2b\\97\\d82ca57932fa62d52c723024419c5ec3b7c0f7ecf0a0f06332\n",
      "  Building wheel for tzlocal (setup.py): started\n",
      "  Building wheel for tzlocal (setup.py): finished with status 'done'\n",
      "  Created wheel for tzlocal: filename=tzlocal-1.5.1-py3-none-any.whl size=17541 sha256=f7ca2d885ec765e77b56e54d5328dd64bbade180c0669174cabd891c886b3784\n",
      "  Stored in directory: c:\\users\\dasha\\appdata\\local\\pip\\cache\\wheels\\3a\\14\\ce\\9c504116f6b89e4a05ce0bc0f41983df280d7e00f463481900\n",
      "Successfully built docx2txt EbookLib python-pptx tzlocal\n",
      "Installing collected packages: six, XlsxWriter, tzlocal, pycryptodome, imapclient, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, EbookLib, docx2txt, beautifulsoup4, argcomplete, textract\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: tzlocal\n",
      "    Found existing installation: tzlocal 2.1\n",
      "    Uninstalling tzlocal-2.1:\n",
      "      Successfully uninstalled tzlocal-2.1\n",
      "  Attempting uninstall: SpeechRecognition\n",
      "    Found existing installation: SpeechRecognition 3.7.1\n",
      "    Uninstalling SpeechRecognition-3.7.1:\n",
      "      Successfully uninstalled SpeechRecognition-3.7.1\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.9.3\n",
      "    Uninstalling beautifulsoup4-4.9.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.9.3\n",
      "Successfully installed EbookLib-0.17.1 SpeechRecognition-3.8.1 XlsxWriter-1.4.3 argcomplete-1.10.0 beautifulsoup4-4.8.0 docx2txt-0.8 extract-msg-0.23.1 imapclient-2.1.0 pdfminer.six-20181108 pycryptodome-3.10.1 python-pptx-0.6.18 six-1.12.0 textract-1.6.3 tzlocal-1.5.1 xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_dir = \"/Capstone/Extra en Espanol/\"\n",
    "files_dir = \"C:/Users/dasha/Documents/Education/UBC/Capstone/Extra en Espanol/\"\n",
    "filenames = ['01 La llegada de Sam.docx',\n",
    "              '02 Sam va de compras.doc',\n",
    "              '03 Sam aprende a ligar.doc',\n",
    "              '04 Sam busca un trabajo.doc',\n",
    "              '05 Ha nacido una estrella.docx',\n",
    "              '06 El día de la primitiva.doc',\n",
    "              '07 La gemela.doc',\n",
    "              '08 La prima de la dueña.doc',\n",
    "              '09 Trabajos para los chicos.doc',\n",
    "              '10 ANA PROTESTA.doc',\n",
    "              '11 Tiempo de vacaciones.doc',\n",
    "              '12 Fanáticos del fútbol.doc',\n",
    "              '13 Boda en el aire.doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = 'C:/Users/dasha/Documents/Education/UBC/Capstone/capstone_FHIS/text/'\n",
    "text_list = []\n",
    "for filename in filenames:\n",
    "    text = textract.process(files_dir+filename).decode('utf-8')\n",
    "    with open(text_dir + filename[:filename.index('.')] + \".txt\", 'w') as text_file:\n",
    "        text_file.write(text)\n",
    "    text_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON files\n",
    "from collections import defaultdict\n",
    "dict_list = []\n",
    "author = \"Channel 4 Learning\" #the author is the producer in this case\n",
    "level = \"A1\"\n",
    "source_list = ['https://www.dropbox.com/s/8ia5r3wfsmobg07/01%20La%20llegada%20de%20Sam.docx?dl=0',\n",
    "              'https://www.dropbox.com/s/x92adnk4cp3u93p/02%20Sam%20va%20de%20compras.doc',\n",
    "              '']\n",
    "for idx, text in enumerate(text_list):\n",
    "    # metadata\n",
    "    # source\n",
    "    source = source_list[idx]\n",
    "    \n",
    "    # Title\n",
    "    title_start = filenames[idx].index(' ')+1\n",
    "    title_end = filenames[idx].index('.')\n",
    "    title = filenames[idx][title_start:title_end]\n",
    "    \n",
    "    # content\n",
    "    content = text\n",
    "    # make dictionary\n",
    "    text_dict = defaultdict(str)\n",
    "    text_dict['author'] = author\n",
    "    text_dict['source'] = source\n",
    "    text_dict['level'] = level\n",
    "    text_dict['title'] = title\n",
    "    text_dict['content'] = content\n",
    "    dict_list.append(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_dir = \"C:/Users/dasha/Documents/Education/UBC/Capstone/capstone_FHIS/corpus/\"\n",
    "with open(files_dir + 'extra_en_espanol.json', 'w') as outfile:\n",
    "    json.dump(dict_list, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
