{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aventura Joven Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OotNOM4KF5QT"
      },
      "source": [
        "Pipeline for Extracting Text from Aventura Joven Books"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBSWME1K9R17",
        "outputId": "f957f9e3-14a6-4e07-bb89-2ee5c79ee24e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAjmp5XmRYTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb54f859-ff00-4d3a-8ab8-a8fe5a418c70"
      },
      "source": [
        "!pip install tika"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (56.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp37-none-any.whl size=32885 sha256=c01bc3d711eb64fc9855829492b64a90c687d987b892e6769f57173ecc7787ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdhA9xqkGd6j"
      },
      "source": [
        "files_dir = \"/content/drive/MyDrive/capstone/\"\n",
        "filenames = ['Aventura Joven 01 - Persecucion - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 02 - Misterio en - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 03 - Perdidos en - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 04 - La chica de - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 05 - El fantasma - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 06 - El monstruo - Elvira Sancho, Jordi Suris.pdf']"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "tEZYkcy19Jft",
        "outputId": "facb5a50-7d57-4544-ec69-9399e96d2e93"
      },
      "source": [
        "# import parser object from tika\n",
        "from tika import parser  \n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "for filename in filenames:\n",
        "  parsed_pdf = parser.from_file(files_dir+filename) \n",
        "  data = parsed_pdf['content'] \n",
        "\n",
        "  # Find beginning and end of text\n",
        "  beg_idx = data.lower().index('capítulo')\n",
        "  end_idx = data.lower().index('después de la lectura\\n')\n",
        "  text = data[beg_idx:end_idx]\n",
        "\n",
        "  # write the initial text to a file (no preprocessing done here)\n",
        "  with open(files_dir+filename[:17]+' Text No Preproc.txt', 'w') as f:\n",
        "    f.write(text)\n",
        "\n",
        "  # preprocess text\n",
        "  # remove words with numbers in them, ex altura1 or hostal2 (footnote indicator)\n",
        "  text_wo_ft_words = text\n",
        "  for word in re.findall('[-a-zA-ZÀ-ÖØ-öø-ÿ]+»?\\,?\\.?{0,3}[1234567890]{1,2}', text_wo_ft_words):\n",
        "    word_idx = text_wo_ft_words.index(word)\n",
        "    m = re.search('[-a-zA-ZÀ-ÖØ-öø-ÿ]+»?\\,?\\.?{0,3}', word)\n",
        "    stripped_word = m.group(0)\n",
        "    text_wo_ft_words = text_wo_ft_words[:word_idx] + stripped_word + text_wo_ft_words[word_idx+len(word):]\n",
        "\n",
        "  # remove words that contain '-\\n' because they didn't fit on one line\n",
        "  text_wo_broken_words = text_wo_ft_words\n",
        "  for word in re.findall('[-a-zA-ZÀ-ÖØ-öø-ÿ]+\\-\\n{1,2}[-a-zØ-öø-ÿ]+', text_wo_broken_words):\n",
        "    word_idx = text_wo_broken_words.index(word)\n",
        "    hyphen_idx = word.index('-')\n",
        "    if '-\\n\\n' in word:\n",
        "      len_sep = 3\n",
        "    else:\n",
        "      len_sep = 2\n",
        "    modified_word = word[:hyphen_idx] + word[hyphen_idx+len_sep:]\n",
        "    text_wo_broken_words = text_wo_broken_words[:word_idx] + modified_word + text_wo_broken_words[word_idx+len(word):]\n",
        "\n",
        "  with open(files_dir+ filename[:17] + ' Text No Ft Broken Words.txt', 'w') as f:\n",
        "    f.write(text_wo_broken_words)\n",
        "\n",
        "  # remove page numbers\n",
        "  text_wo_page_nums = text_wo_broken_words\n",
        "  for word in re.findall('\\n[0-9]{1,2}\\n', text_wo_page_nums):\n",
        "    word_idx = text_wo_page_nums.index(word)\n",
        "    m = re.search('[0-9]{1,2}', word)\n",
        "    text_wo_page_nums = text_wo_page_nums[:word_idx] + '\\n' + text_wo_page_nums[word_idx+len(word):]\n",
        "\n",
        "  with open(files_dir+ filename[:17] + ' Text No Page Nums.txt', 'w') as f:\n",
        "    f.write(text_wo_page_nums)\n",
        "  \n",
        "  # remove unnecessary newline breaks\n",
        "  text_wo_sent_breaks = text_wo_page_nums\n",
        "  for word in re.findall('[-a-zA-ZÀ-ÖØ-öø-ÿ]+ ?\\n\\n[-a-zA-ZÀ-ÖØ-öø-ÿ]+', text_wo_sent_breaks):\n",
        "    word_idx = text_wo_sent_breaks.index(word)\n",
        "    newline_idx = word.index('\\n\\n')\n",
        "    modified_word = word[:newline_idx] + word[newline_idx+2:]\n",
        "    text_wo_sent_breaks = text_wo_sent_breaks[:word_idx] + modified_word + text_wo_sent_breaks[word_idx+len(word):]\n",
        "\n",
        "  with open(files_dir+ filename[:17] + ' Text No Sent Breaks.txt', 'w') as f:\n",
        "    f.write(text_wo_sent_breaks)\n",
        "  \n",
        "  with open(files_dir+ filename[:17] + ' Text.txt', 'w') as f:\n",
        "    f.write(text_wo_sent_breaks)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-1410933c6071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# remove words with numbers in them, ex altura1 or hostal2 (footnote indicator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mtext_wo_ft_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[-a-zA-ZÀ-ÖØ-öø-ÿ]+»?\\,?\\.!?{0,3}[1234567890]{1,2}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_wo_ft_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mword_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_wo_ft_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[-a-zA-ZÀ-ÖØ-öø-ÿ]+»?\\,?\\.!?{0,3}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 420\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                 raise source.error(\"multiple repeat\",\n\u001b[0;32m--> 648\u001b[0;31m                                    source.tell() - here + len(this))\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mSUBPATTERN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: multiple repeat at position 28"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFbzF87zNso0"
      },
      "source": [
        "Attempt at Removing Footnote Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvCM5gUsNf6v"
      },
      "source": [
        "# def modify_words(regex_find, regex_modify, text, modify):\n",
        "#   ''' Modifies all words in text that match the regex_find regex to match the regex_modify regex. '''\n",
        "#   text_removed = text\n",
        "#   for word in re.findall(regex_find, text_removed):\n",
        "#     word_idx = text_removed.index(word)\n",
        "    \n",
        "#     if modify == 'regex':\n",
        "#       m = re.search(regex_modify, word)\n",
        "#       modified_word = m.group(0)\n",
        "#     elif modify == 'remove':\n",
        "#       rm_char_idx = word.index(regex_modify)\n",
        "#       modified_word = word[:rm_char_idx] + word[rm_char_idx+len(regex_modify):]\n",
        "    \n",
        "#     text_removed = text_removed[:word_idx] + modified_word + text_removed[word_idx+len(word):]\n",
        "\n",
        "#   return text_removed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STSN5IHiQOD8"
      },
      "source": [
        "#text_wo_broken_words = modify_words('[-a-zA-ZÀ-ÖØ-öø-ÿ]+\\-\\n{1,2}[-a-zØ-öø-ÿ]+', '-\\n', text_wo_ft_words, 'remove')\n",
        "#print(text_wo_broken_words[800:2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy2wBMBIHRtD"
      },
      "source": [
        "# remove the footnotes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "ASOHuL-vEhak",
        "outputId": "0bdc07bc-c531-4c1d-9c01-b350fc28fddb"
      },
      "source": [
        "# Attempt at removing the footnotes\n",
        "import re\n",
        "\n",
        "# normalize the data to ignore special characters in Spanish\n",
        "#norm_data = unicodedata.normalize('NFD', data).encode('ascii', 'ignore').decode('utf-8')\n",
        "#norm_text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')\n",
        "\n",
        "# m = re.search('[A-z]+[1234567890]{1,2}', norm_data[1880:])\n",
        "\n",
        "# m.group(0)\n",
        "# footnoted_words = [word.strip() for word in re.findall('[A-z]+[1234567890]', norm_data[1880:])]\n",
        "# footnote_defs = [word.strip() for word in re.findall('[0-9]{1,2}  [A-z]+[\\s\\w]*:[\\w \\n]*\\.', norm_data[1880:])]\n",
        "\n",
        "#print(footnoted_words)\n",
        "#print(footnote_defs)\n",
        "all_matches = re.findall('([0-9]{1,2}  [A-z]+: ((([A-z]|[0-9]|,)+ ?)+\\n))', '''1  altura: Cusco esta a unos 3500 metros de altura, lo que en algunas personas \n",
        "provoca el llamado mal de altura o soroche. Los sintomas del mal de altura \n",
        "son: dolor de cabeza, mareos, trastornos estomacales y cansancio. Puede com-\n",
        "batirse con pastillas, ejercicios de respiracion o mate.\n",
        "\n",
        "2  hostal: alojamiento normalmente mas barato y personal que un hotel, aunque \n",
        "sin sus comodidades. La palabra se utiliza principalmente en medios rurales. \n",
        "''')\n",
        "print(len(all_matches))\n",
        "print(all_matches)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:An unexpected error occurred while tokenizing input\n",
            "The following traceback may be corrupted or invalid\n",
            "The error message is: ('EOF in multi-line string', (1, 0))\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-773d9a34b7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0mhostal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malojamiento\u001b[0m \u001b[0mnormalmente\u001b[0m \u001b[0mmas\u001b[0m \u001b[0mbarato\u001b[0m \u001b[0my\u001b[0m \u001b[0mpersonal\u001b[0m \u001b[0mque\u001b[0m \u001b[0mun\u001b[0m \u001b[0mhotel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maunque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msin\u001b[0m \u001b[0msus\u001b[0m \u001b[0mcomodidades\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mLa\u001b[0m \u001b[0mpalabra\u001b[0m \u001b[0mse\u001b[0m \u001b[0mutiliza\u001b[0m \u001b[0mprincipalmente\u001b[0m \u001b[0men\u001b[0m \u001b[0mmedios\u001b[0m \u001b[0mrurales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m ''')\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDZxXbjyF33T"
      },
      "source": [
        ""
      ]
    }
  ]
}