{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aventura Joven Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OotNOM4KF5QT"
      },
      "source": [
        "Pipeline for Extracting Text from Aventura Joven Books"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBSWME1K9R17",
        "outputId": "3569008f-3181-418e-816d-c52e547f9173"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAjmp5XmRYTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42786d4f-5e08-454e-97d6-667b063fade7"
      },
      "source": [
        "!pip install tika"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (56.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp37-none-any.whl size=32885 sha256=71154154143d7e5a5f1eaf7b0d8807367a00efe41ccba55fd3cf1322888da73f\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdhA9xqkGd6j"
      },
      "source": [
        "files_dir = \"/content/drive/MyDrive/capstone/\"\n",
        "filenames = ['Aventura Joven 01 - Persecucion - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 02 - Misterio en - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 03 - Perdidos en - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 04 - La chica de - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 05 - El fantasma - Elvira Sancho, Jordi Suris.pdf',\n",
        "              'Aventura Joven 06 - El monstruo - Elvira Sancho, Jordi Suris.pdf']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZYkcy19Jft"
      },
      "source": [
        "# import parser object from tika\n",
        "from tika import parser  \n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "data_list = []\n",
        "text_orig_list = []\n",
        "text_proc_list = []\n",
        "for filename in filenames:\n",
        "  parsed_pdf = parser.from_file(files_dir+filename) \n",
        "  data = parsed_pdf['content'] \n",
        "  data_list.append(data)\n",
        "\n",
        "  # Find beginning and end of text\n",
        "  beg_idx = data.lower().index('capítulo')\n",
        "  end_idx = data.lower().index('después de la lectura\\n')\n",
        "  text = data[beg_idx:end_idx]\n",
        "  text_orig_list.append(text)\n",
        "\n",
        "  # write the initial text to a file (no preprocessing done here)\n",
        "  with open(files_dir+filename[:17]+' Text No Preproc.txt', 'w') as f:\n",
        "    f.write(text)\n",
        "\n",
        "  # preprocess text\n",
        "  # remove words with numbers in them, ex altura1 or hostal2 (footnote indicator)\n",
        "  text_wo_ft_words = text\n",
        "  for word in re.findall('[-a-zA-ZÀ-ÖØ-öø-ÿ]+»?,?!?\\.{0,3}[1234567890]{1,2}', text_wo_ft_words):\n",
        "    word_idx = text_wo_ft_words.index(word)\n",
        "    m = re.search('[-a-zA-ZÀ-ÖØ-öø-ÿ]+»?,?!?\\.{0,3}', word)\n",
        "    stripped_word = m.group(0)\n",
        "    text_wo_ft_words = text_wo_ft_words[:word_idx] + stripped_word + text_wo_ft_words[word_idx+len(word):]\n",
        "\n",
        "  # remove words that contain '-\\n' because they didn't fit on one line\n",
        "  text_wo_broken_words = text_wo_ft_words\n",
        "  for word in re.findall('[-a-zA-ZÀ-ÖØ-öø-ÿ]+\\-\\n{1,2}[-a-zØ-öø-ÿ]+', text_wo_broken_words):\n",
        "    word_idx = text_wo_broken_words.index(word)\n",
        "    hyphen_idx = word.index('-')\n",
        "    if '-\\n\\n' in word:\n",
        "      len_sep = 3\n",
        "    else:\n",
        "      len_sep = 2\n",
        "    modified_word = word[:hyphen_idx] + word[hyphen_idx+len_sep:]\n",
        "    text_wo_broken_words = text_wo_broken_words[:word_idx] + modified_word + text_wo_broken_words[word_idx+len(word):]\n",
        "\n",
        "  # remove page numbers\n",
        "  text_wo_page_nums = text_wo_broken_words\n",
        "  for word in re.findall('\\n[0-9]{1,2}\\n', text_wo_page_nums):\n",
        "    word_idx = text_wo_page_nums.index(word)\n",
        "    m = re.search('[0-9]{1,2}', word)\n",
        "    text_wo_page_nums = text_wo_page_nums[:word_idx] + '\\n' + text_wo_page_nums[word_idx+len(word):]\n",
        "  \n",
        "  # remove unnecessary newline breaks\n",
        "  text_wo_sent_breaks = text_wo_page_nums\n",
        "  for word in re.findall('[-a-zA-ZÀ-ÖØ-öø-ÿ]+ ?\\n\\n[-a-zA-ZÀ-ÖØ-öø-ÿ]+', text_wo_sent_breaks):\n",
        "    word_idx = text_wo_sent_breaks.index(word)\n",
        "    newline_idx = word.index('\\n\\n')\n",
        "    modified_word = word[:newline_idx] + word[newline_idx+2:]\n",
        "    text_wo_sent_breaks = text_wo_sent_breaks[:word_idx] + modified_word + text_wo_sent_breaks[word_idx+len(word):]\n",
        "  \n",
        "  text_proc_list.append(text_wo_sent_breaks)\n",
        "  \n",
        "  with open(files_dir+ filename[:17] + ' Text.txt', 'w') as f:\n",
        "    f.write(text_wo_sent_breaks)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7ISTx-RP3VH"
      },
      "source": [
        "Turning the files into JSON objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sybc4dfOSDcA",
        "outputId": "ba6c66ea-0216-43e1-a21a-16b4846d3cfb"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "chapter_indices = defaultdict(str)\n",
        "data_chap = data_list[0]\n",
        "print(data_chap.lower().index('capítulo'))\n",
        "text_len = len(data_list[0])\n",
        "i = 0\n",
        "cur_data_chap = 0\n",
        "while 'capítulo' in data_chap:\n",
        "  chapter_index = data_chap.lower().index('capítulo')\n",
        "  newline_after_chapter_index = data_chap[chapter_index+8:].index('\\n') + chapter_index+8\n",
        "  chapter_indices[str(i)] = chapter_index + cur_data_chap\n",
        "  i += 1\n",
        "  cur_data_chap += newline_after_chapter_index\n",
        "  data_chap = data_chap[newline_after_chapter_index:]\n",
        "  print(len(data_chap))\n",
        "  \n",
        "\n",
        "print(chapter_indices)\n",
        "for chap, chap_idx in chapter_indices.items():\n",
        "  print(data_list[0][chap_idx: chap_idx+100])\n",
        "  print(\"--------------------------------------------------\")\n",
        "  print()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1771\n",
            "61710\n",
            "54513\n",
            "50167\n",
            "44807\n",
            "37934\n",
            "29508\n",
            "23185\n",
            "16622\n",
            "15098\n",
            "13621\n",
            "12119\n",
            "11051\n",
            "9239\n",
            "8421\n",
            "7343\n",
            "6168\n",
            "5700\n",
            "defaultdict(<class 'str'>, {'0': 1771, '1': 8968, '2': 13314, '3': 18674, '4': 25547, '5': 33973, '6': 40296, '7': 46856, '8': 48382, '9': 49860, '10': 51362, '11': 52388, '12': 54242, '13': 55029, '14': 56138, '15': 57313, '16': 57730})\n",
            "caPítulo 1\n",
            "\n",
            "—¡Eh, Lucas!, ¡mira, allí!\n",
            "—¿Dónde?\n",
            "—Allí. ¿Ves a ese chico?\n",
            "—¿Quién?\n",
            "—Aquél, el de los \n",
            "--------------------------------------------------\n",
            "\n",
            "caPítulo 2\n",
            "\n",
            "Sergio conduce por las rondas de Madrid, moviéndose entre los \n",
            "coches. Detrás, un poco l\n",
            "--------------------------------------------------\n",
            "\n",
            "caPítulo 3\n",
            "\n",
            "—¡Hola, primo! —el chico del pelo negro entra en la sala de \n",
            "estar y saluda a Sergio.\n",
            "\n",
            "—\n",
            "--------------------------------------------------\n",
            "\n",
            "caPítulo 4\n",
            "\n",
            "Cuando llegan a la sala del Guernica hay mucha gente mirando \n",
            "el cuadro.\n",
            "\n",
            "—¡Impresionant\n",
            "--------------------------------------------------\n",
            "\n",
            "caPítulo �\n",
            "\n",
            "Sergio vuelve al bar para coger la moto. Cerca de la moto, dos \n",
            "hombres miran unas revis\n",
            "--------------------------------------------------\n",
            "\n",
            "caPítulo 6\n",
            "\n",
            "Cuando el metro para en la estación «Sol», Laura y sus amigos \n",
            "bajan.\n",
            "\n",
            "—Me gusta este me\n",
            "--------------------------------------------------\n",
            "\n",
            "caPítulo �\n",
            "\n",
            "—¡Hola, «Pelao»!1\n",
            "—¡Hola, Carlos!\n",
            "Carlos saca un paquete de la mochila. Está envuelto en\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulos 1-2\n",
            "\n",
            "1. ¿Quién es quién?\n",
            "\n",
            "A.  Busca en el recuadro las palabras adecuadas para describir a\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulos? \n",
            "\n",
            "a. un parque:  \n",
            "\n",
            "b. un museo:  \n",
            "\n",
            "c. un cuadro:  \n",
            "\n",
            "d. un barrio:  \n",
            "\n",
            "e. una estación de t\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulo 3\n",
            "\n",
            "7. ¿Qué?\n",
            "\n",
            "Contesta con tus propias palabras.\n",
            "\n",
            "a. ¿Qué le cuenta Carlos a Sergio sobre Va\n",
            "--------------------------------------------------\n",
            "\n",
            "Capítulo 4\n",
            "\n",
            "11. ¿Qué significa?\n",
            "\n",
            "A.  Un inmigrante:\t\n",
            "a.\t un\textranjero.\t\n",
            "b.\t un\textranjero\tque\tvive\t\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulo aparecen descritos elementos del Guernica. \n",
            "Búscalos en el texto e indica dónde están repre\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulo 5\n",
            "\n",
            "16. ¿Es verdad?\n",
            "\n",
            "Di si estas frases son verdaderas o falsas.\n",
            "\n",
            "a. Sergio está triste porq\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulo, según creas que son normales o \n",
            "extraordinarias para Sergio.\n",
            "\n",
            "V F\n",
            "V F\n",
            "V F\n",
            "\n",
            "V F\n",
            "V F\n",
            "\n",
            "V F\n",
            "\n",
            "5\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulo 6\n",
            "\n",
            "19. ¿Dónde?\n",
            "\n",
            "Busca y señala con una flecha en el mapa de Madrid de la página \n",
            "48 los sig\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulo 7\n",
            "\n",
            "23 ¿Por qué?\n",
            "\n",
            "a.  ¿Por qué le pregunta «El Pelao» a Carlos si tiene un hermano \n",
            "gemelo?\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "capítulo y se ha equivocado 10 veces. Subraya los errores en \n",
            "el texto y a continuación escribe los \n",
            "--------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azRKxpK6P2pM"
      },
      "source": [
        "dict_list = []\n",
        "author = \"Elvira Sancho, Jordi Suris\"\n",
        "for i, (data, text) in enumerate(zip(data_list,text_proc_list)):\n",
        "  # metadata\n",
        "  # ISBN\n",
        "  isbn_index = data_list[0].index('ISBN')\n",
        "  newline_after_isbn = data_list[0][isbn_index+5:].index('\\n\\n') + isbn_index+5\n",
        "  source = data_list[0][isbn_index+6:newline_after_isbn]\n",
        "\n",
        "  # Level\n",
        "  if i <= 4:\n",
        "    level = \"A1\"\n",
        "  else:\n",
        "    level= \"A2\"\n",
        "\n",
        "  # Title\n",
        "  title_index = data_list[0].index('Título')\n",
        "  newline_after_title = data_list[0][title_index+7:].index('\\n\\n') + title_index+7\n",
        "  title = data_list[0][title_index+8:newline_after_title]\n",
        "  content = text\n",
        "  # separate by chapters\n",
        "\n",
        "  # make a dictionary\n",
        "\n",
        "  dict_list.append(chap_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFbzF87zNso0"
      },
      "source": [
        "Attempt at Removing Footnote Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvCM5gUsNf6v"
      },
      "source": [
        "# def modify_words(regex_find, regex_modify, text, modify):\n",
        "#   ''' Modifies all words in text that match the regex_find regex to match the regex_modify regex. '''\n",
        "#   text_removed = text\n",
        "#   for word in re.findall(regex_find, text_removed):\n",
        "#     word_idx = text_removed.index(word)\n",
        "    \n",
        "#     if modify == 'regex':\n",
        "#       m = re.search(regex_modify, word)\n",
        "#       modified_word = m.group(0)\n",
        "#     elif modify == 'remove':\n",
        "#       rm_char_idx = word.index(regex_modify)\n",
        "#       modified_word = word[:rm_char_idx] + word[rm_char_idx+len(regex_modify):]\n",
        "    \n",
        "#     text_removed = text_removed[:word_idx] + modified_word + text_removed[word_idx+len(word):]\n",
        "\n",
        "#   return text_removed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STSN5IHiQOD8"
      },
      "source": [
        "#text_wo_broken_words = modify_words('[-a-zA-ZÀ-ÖØ-öø-ÿ]+\\-\\n{1,2}[-a-zØ-öø-ÿ]+', '-\\n', text_wo_ft_words, 'remove')\n",
        "#print(text_wo_broken_words[800:2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy2wBMBIHRtD"
      },
      "source": [
        "# remove the footnotes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "ASOHuL-vEhak",
        "outputId": "0bdc07bc-c531-4c1d-9c01-b350fc28fddb"
      },
      "source": [
        "# Attempt at removing the footnotes\n",
        "import re\n",
        "\n",
        "# normalize the data to ignore special characters in Spanish\n",
        "#norm_data = unicodedata.normalize('NFD', data).encode('ascii', 'ignore').decode('utf-8')\n",
        "#norm_text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')\n",
        "\n",
        "# m = re.search('[A-z]+[1234567890]{1,2}', norm_data[1880:])\n",
        "\n",
        "# m.group(0)\n",
        "# footnoted_words = [word.strip() for word in re.findall('[A-z]+[1234567890]', norm_data[1880:])]\n",
        "# footnote_defs = [word.strip() for word in re.findall('[0-9]{1,2}  [A-z]+[\\s\\w]*:[\\w \\n]*\\.', norm_data[1880:])]\n",
        "\n",
        "#print(footnoted_words)\n",
        "#print(footnote_defs)\n",
        "all_matches = re.findall('([0-9]{1,2}  [A-z]+: ((([A-z]|[0-9]|,)+ ?)+\\n))', '''1  altura: Cusco esta a unos 3500 metros de altura, lo que en algunas personas \n",
        "provoca el llamado mal de altura o soroche. Los sintomas del mal de altura \n",
        "son: dolor de cabeza, mareos, trastornos estomacales y cansancio. Puede com-\n",
        "batirse con pastillas, ejercicios de respiracion o mate.\n",
        "\n",
        "2  hostal: alojamiento normalmente mas barato y personal que un hotel, aunque \n",
        "sin sus comodidades. La palabra se utiliza principalmente en medios rurales. \n",
        "''')\n",
        "print(len(all_matches))\n",
        "print(all_matches)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:An unexpected error occurred while tokenizing input\n",
            "The following traceback may be corrupted or invalid\n",
            "The error message is: ('EOF in multi-line string', (1, 0))\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-773d9a34b7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0mhostal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malojamiento\u001b[0m \u001b[0mnormalmente\u001b[0m \u001b[0mmas\u001b[0m \u001b[0mbarato\u001b[0m \u001b[0my\u001b[0m \u001b[0mpersonal\u001b[0m \u001b[0mque\u001b[0m \u001b[0mun\u001b[0m \u001b[0mhotel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maunque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msin\u001b[0m \u001b[0msus\u001b[0m \u001b[0mcomodidades\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mLa\u001b[0m \u001b[0mpalabra\u001b[0m \u001b[0mse\u001b[0m \u001b[0mutiliza\u001b[0m \u001b[0mprincipalmente\u001b[0m \u001b[0men\u001b[0m \u001b[0mmedios\u001b[0m \u001b[0mrurales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m ''')\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDZxXbjyF33T"
      },
      "source": [
        ""
      ]
    }
  ]
}