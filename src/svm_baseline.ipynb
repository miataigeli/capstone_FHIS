{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c15d21",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1851e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e926fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731a44b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf53ac3",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7cfb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and val data\n",
    "with open(os.path.abspath('../data/X_train.txt'), 'r') as f:\n",
    "    X_train = f.read().strip().split('#'*20)\n",
    "with open(os.path.abspath('../data/X_val.txt'), 'r') as f:\n",
    "    X_val = f.read().strip().split('#'*20)\n",
    "with open(os.path.abspath('../data/y_train.txt'), 'r') as f:\n",
    "    y_train = f.read().strip().split('\\n')\n",
    "with open(os.path.abspath('../data/y_val.txt'), 'r') as f:\n",
    "    y_val = f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b829f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and val data\n",
    "with open(os.path.abspath('../data/train_features.json'), 'r') as f:\n",
    "    train_feat = json.load(f)\n",
    "with open(os.path.abspath('../data/val_features.json'), 'r') as f:\n",
    "    val_feat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b03b2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat = train_feat_df.drop(['level'], axis=1)\n",
    "y_train_feat = [level[0] for level in train_feat_df['level'].tolist()]\n",
    "X_val_feat = val_feat_df.drop(['level'], axis=1)\n",
    "y_val_feat = [level[0] for level in val_feat_df['level'].tolist()]\n",
    "y_train_fine = train_feat_df['level'].tolist()\n",
    "y_val_fine = val_feat_df['level'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac98c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33. EL CANAL DE SUEZ\n",
      "El proyecto del canal moderno a través del\n",
      "istmo de Suez, para facilitar el paso de los\n",
      "buques desde el Mediterráneo al Mar Rojo,\n",
      "nació de Napoleón el Grande durante su invasión\n",
      "de Egipto. Pero muchísimos siglos antes\n",
      "de él, esto es, 1,300 años antes de la Era cristiana,\n",
      "se construyó un canal desde un ramal\n",
      "del Nilo hasta el Mar Rojo. Ese canal fué\n",
      "obstruido varias veces por la arena y en el año\n",
      "767 de nuestra Era fué destruido por el califa\n",
      "Almanzor.\n",
      "En 1854, un ingeniero francés, Fernando de\n",
      "Lesseps, obtuvo del virrey de Egipto, Said-Bajá,\n",
      "una concesión a favor de una Compañía\n",
      "por espacio de noventa y nueve años\n",
      "para construir un canal navegable a través del\n",
      "istmo. Organizóse la Compañía en 1858 con un\n",
      "capital en acciones de 200,000,000 de francos,\n",
      "que en 1867 fué necesario ampliar con otros\n",
      "100 millones. Las obras duraron once años.\n",
      "El canal tiene de un extremo a otro 162\n",
      "kilómetros de largo; pero una cuarta parte de\n",
      "esa longitud consiste en lagos naturales. La\n",
      "mayor anchura del canal es de unos 100 metros.\n",
      "En algunos puntos es de 60 en la superficie y\n",
      "de 20 al fondo. La profundidad es de 8 metros.\n",
      "El canal se inauguró oficialmente, con gran\n",
      "solemnidad, el 17 de noviembre de 1869, pasando\n",
      "por él 50 buques de un mar a otro. En\n",
      "1871 utilizaron el canal 765 buques, entre ellos\n",
      "63 buques de guerra. Por esta vía se acortan\n",
      "considerablemente los viajes de Europa a las\n",
      "Indias y otros puntos de Asia, que antes se\n",
      "hacían por el Cabo de Buena Esperanza.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b41e24",
   "metadata": {},
   "source": [
    "## Model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09426ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy']\n",
    "\n",
    "# results dictionary\n",
    "results_df = {}\n",
    "\n",
    "# tokenizer\n",
    "def tokenizer(text):\n",
    "    return [tok.text for tok in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e59985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_and_display(preprocessor, model, name, train_set, fine_grained=False):\n",
    "    '''\n",
    "    train model and display cross validation results\n",
    "    \n",
    "    preprocessor: (sklearn ColumnTransformer) sklearn object for feature transformation\n",
    "    model: (sklearn Classifier) initialized sklearn classifier\n",
    "    name: (str) a name that is shown when the result is displayed\n",
    "    train_set: (DataFrame) the input train set encoding features\n",
    "    '''\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessor, model\n",
    "    )\n",
    "    if fine_grained == False:\n",
    "        scores = cross_validate(pipeline, train_set, y_train, scoring = scoring, return_train_score=True)\n",
    "    else:\n",
    "        scores = cross_validate(pipeline, train_set, y_train_fine, scoring = scoring, return_train_score=True)\n",
    "    \n",
    "    results_df[name] = pd.DataFrame(scores).mean()\n",
    "    display(pd.DataFrame(results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d5ec1",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc0a2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>22.103144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>5.216887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.804805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.827651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SVM baseline\n",
       "fit_time           22.103144\n",
       "score_time          5.216887\n",
       "test_accuracy       0.804805\n",
       "train_accuracy      0.827651"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_and_display(CountVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), SVC(random_state=123), 'SVM baseline', X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c9e8e",
   "metadata": {},
   "source": [
    "## Classification analysis - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc8b2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"bow\", CountVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer)), \n",
    "        (\"model\", SVC(random_state=123))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa2a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(max_features=30000, ngram_range=(1, 2),\n",
       "                                 tokenizer=<function tokenizer at 0x147a44e50>)),\n",
       "                ('model', SVC(random_state=123))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b301c45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_pipeline.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af61707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.71      0.99      0.83       101\n",
      "           B       0.99      0.77      0.87       176\n",
      "\n",
      "    accuracy                           0.85       277\n",
      "   macro avg       0.85      0.88      0.85       277\n",
      "weighted avg       0.89      0.85      0.85       277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = baseline_pipeline.predict(X_train)\n",
    "print(classification_report(y_pred, y_train))\n",
    "\n",
    "## the model seems to be predicting some B level texts as A level\n",
    "## precision: 71% of texts that are predicted as A level are actually A level\n",
    "## recall: 99% of texts that are actually A level are predicted as A level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "503f9798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.75      0.92      0.83        13\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.84      0.85      0.84        31\n",
      "weighted avg       0.86      0.84      0.84        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = baseline_pipeline.predict(X_val)\n",
    "print(classification_report(y_val_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a871036",
   "metadata": {},
   "source": [
    "## With features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d00f656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_tokens_w/o_stopwords</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>proportion_of_A_level_tokens</th>\n",
       "      <th>proportion_of_A_level_types</th>\n",
       "      <th>num_connectives</th>\n",
       "      <th>logical_operator_density</th>\n",
       "      <th>pronoun_density</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>EOL</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>FUNCTION</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>el canal de suez el proyecto del canal moderno...</td>\n",
       "      <td>293</td>\n",
       "      <td>124</td>\n",
       "      <td>22.538462</td>\n",
       "      <td>0.346774</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.474403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112628</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.311538</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>el tonto vivían en cierto pueblo un labriego y...</td>\n",
       "      <td>1803</td>\n",
       "      <td>694</td>\n",
       "      <td>11.967105</td>\n",
       "      <td>0.358790</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.044007</td>\n",
       "      <td>0.070665</td>\n",
       "      <td>0.313367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169163</td>\n",
       "      <td>0.042152</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.144759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600936</td>\n",
       "      <td>0.399064</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>una lección de español el maestro:—¿qué lecció...</td>\n",
       "      <td>299</td>\n",
       "      <td>132</td>\n",
       "      <td>7.475000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>8</td>\n",
       "      <td>0.031034</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.454849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210702</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.673729</td>\n",
       "      <td>0.326271</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capítulo i que trata de la condición y ejercic...</td>\n",
       "      <td>2153</td>\n",
       "      <td>869</td>\n",
       "      <td>61.514286</td>\n",
       "      <td>0.336018</td>\n",
       "      <td>0.178637</td>\n",
       "      <td>17</td>\n",
       "      <td>0.064261</td>\n",
       "      <td>0.070612</td>\n",
       "      <td>0.340455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130051</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604378</td>\n",
       "      <td>0.395622</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capítulo —¿qué hora es? —pregunta guillermo mi...</td>\n",
       "      <td>1621</td>\n",
       "      <td>654</td>\n",
       "      <td>9.210227</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>16</td>\n",
       "      <td>0.047158</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>0.268970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.107341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650622</td>\n",
       "      <td>0.349378</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   preprocessed_text  total_tokens  \\\n",
       "0  el canal de suez el proyecto del canal moderno...           293   \n",
       "1  el tonto vivían en cierto pueblo un labriego y...          1803   \n",
       "2  una lección de español el maestro:—¿qué lecció...           299   \n",
       "3  capítulo i que trata de la condición y ejercic...          2153   \n",
       "4  capítulo —¿qué hora es? —pregunta guillermo mi...          1621   \n",
       "\n",
       "   total_tokens_w/o_stopwords  avg_sent_length  proportion_of_A_level_tokens  \\\n",
       "0                         124        22.538462                      0.346774   \n",
       "1                         694        11.967105                      0.358790   \n",
       "2                         132         7.475000                      0.484848   \n",
       "3                         869        61.514286                      0.336018   \n",
       "4                         654         9.210227                      0.477064   \n",
       "\n",
       "   proportion_of_A_level_types  num_connectives  logical_operator_density  \\\n",
       "0                     0.239130                5                  0.013841   \n",
       "1                     0.250000               25                  0.044007   \n",
       "2                     0.465909                8                  0.031034   \n",
       "3                     0.178637               17                  0.064261   \n",
       "4                     0.430556               16                  0.047158   \n",
       "\n",
       "   pronoun_density  type_token_ratio  ...     PUNCT     SCONJ       SYM  \\\n",
       "0         0.028070          0.474403  ...  0.112628  0.006826  0.000000   \n",
       "1         0.070665          0.313367  ...  0.169163  0.042152  0.001109   \n",
       "2         0.038194          0.454849  ...  0.210702  0.010033  0.000000   \n",
       "3         0.070612          0.340455  ...  0.130051  0.061774  0.000000   \n",
       "4         0.043786          0.268970  ...  0.252930  0.016039  0.003701   \n",
       "\n",
       "       VERB    X  EOL  SPACE   CONTENT  FUNCTION  level  \n",
       "0  0.054608  0.0  0.0    0.0  0.688462  0.311538     A2  \n",
       "1  0.144759  0.0  0.0    0.0  0.600936  0.399064     A2  \n",
       "2  0.120401  0.0  0.0    0.0  0.673729  0.326271     A1  \n",
       "3  0.092429  0.0  0.0    0.0  0.604378  0.395622     A2  \n",
       "4  0.107341  0.0  0.0    0.0  0.650622  0.349378     A1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_df = pd.DataFrame(train_feat)\n",
    "val_feat_df = pd.DataFrame(val_feat)\n",
    "\n",
    "train_feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264afb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM baseline</th>\n",
       "      <th>SVM + all feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>22.103144</td>\n",
       "      <td>17.394472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>5.216887</td>\n",
       "      <td>4.266932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.834091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.827651</td>\n",
       "      <td>0.925087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SVM baseline  SVM + all feats\n",
       "fit_time           22.103144        17.394472\n",
       "score_time          5.216887         4.266932\n",
       "test_accuracy       0.804805         0.834091\n",
       "train_accuracy      0.827651         0.925087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "passthrough_features = []\n",
    "categorical_features = []\n",
    "numeric_features = ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_tokens', \n",
    "                    'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', \n",
    "                    'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence',\n",
    "                    'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT',\n",
    "                    'SCONJ', 'SYM', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
    "text_feature = 'preprocessed_text'\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature),\n",
    ")\n",
    "\n",
    "all_feat_model = SVC(random_state=123)\n",
    "\n",
    "cv_and_display(preprocessor, all_feat_model, 'SVM + all feats', X_train_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb870dc",
   "metadata": {},
   "source": [
    "## Classification analysis - Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d50ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat_pipeline = make_pipeline(\n",
    "        preprocessor, all_feat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "916735ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['total_tokens',\n",
       "                                                   'total_tokens_w/o_stopwords',\n",
       "                                                   'avg_sent_length',\n",
       "                                                   'proportion_of_A_level_tokens',\n",
       "                                                   'proportion_of_A_level_types',\n",
       "                                                   'num_connectives',\n",
       "                                                   'logical_operator_density',\n",
       "                                                   'pronoun_density',\n",
       "                                                   'type_token_ratio',\n",
       "                                                   'avg_rank_of_lemmas_in_freq_list',\n",
       "                                                   'fernandez_huerta_score',\n",
       "                                                   'syllables_per_sentence',\n",
       "                                                   'ADJ', 'ADP', 'ADV', 'AUX',\n",
       "                                                   'CONJ', 'CCONJ', 'DET',\n",
       "                                                   'INTJ', 'NOUN', 'NUM',\n",
       "                                                   'PART', 'PRON', 'PROPN',\n",
       "                                                   'PUNCT', 'SCONJ', 'SYM',\n",
       "                                                   'VERB', 'X', ...]),\n",
       "                                                 ('tfidfvectorizer',\n",
       "                                                  TfidfVectorizer(max_features=30000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=<function tokenizer at 0x147a44e50>),\n",
       "                                                  'preprocessed_text')])),\n",
       "                ('svc', SVC(random_state=123))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feat_pipeline.fit(X_train_feat, y_train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "868bf35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feat_pipeline.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a95c91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.92      0.91      0.92       141\n",
      "           B       0.91      0.92      0.92       136\n",
      "\n",
      "    accuracy                           0.92       277\n",
      "   macro avg       0.92      0.92      0.92       277\n",
      "weighted avg       0.92      0.92      0.92       277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_feat = all_feat_pipeline.predict(X_train_feat)\n",
    "print(classification_report(y_pred_feat, y_train_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a02d1f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.88      0.91        17\n",
      "           B       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.90        31\n",
      "   macro avg       0.90      0.91      0.90        31\n",
      "weighted avg       0.91      0.90      0.90        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_feat = all_feat_pipeline.predict(X_val_feat)\n",
    "print(classification_report(y_val_pred_feat, y_val_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c892d40",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4012ac5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zP9jfTWTkaM",
    "outputId": "02691f47-d448-4518-a73e-ef0dd9856faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 44.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['total_tokens',\n",
       "                                                                                'total_tokens_w/o_stopwords',\n",
       "                                                                                'avg_sent_length',\n",
       "                                                                                'proportion_of_A_level_tokens',\n",
       "                                                                                'proportion_of_A_level_types',\n",
       "                                                                                'num_connectives',\n",
       "                                                                                'logical_operator_density',\n",
       "                                                                                'pronoun_density',\n",
       "                                                                                'type_token_ratio',\n",
       "                                                                                'avg_r...\n",
       "       1.0240e+03, 2.0480e+03, 4.0960e+03, 8.1920e+03, 1.6384e+04]),\n",
       "                                        'svc__gamma': array([3.05175781e-05, 6.10351562e-05, 1.22070312e-04, 2.44140625e-04,\n",
       "       4.88281250e-04, 9.76562500e-04, 1.95312500e-03, 3.90625000e-03,\n",
       "       7.81250000e-03, 1.56250000e-02, 3.12500000e-02, 6.25000000e-02,\n",
       "       1.25000000e-01, 2.50000000e-01, 5.00000000e-01, 1.00000000e+00,\n",
       "       2.00000000e+00, 4.00000000e+00])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gamma and C value range taken from https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "param_grid = {\n",
    "    \"svc__gamma\": 2.0 ** np.arange(-15, 3),\n",
    "    \"svc__C\": 2.0 ** np.arange(-5, 15)\n",
    "}\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature),\n",
    ")\n",
    "\n",
    "best_model = make_pipeline(\n",
    "        preprocessor, SVC(random_state=123)\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(best_model, \n",
    "                                   scoring='accuracy', \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_jobs=-1, \n",
    "                                   n_iter=50, \n",
    "                                   cv=5,\n",
    "                                   return_train_score=True,\n",
    "                                   verbose=10) # default n_iter=10\n",
    "random_search.fit(X_train_feat, y_train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e60d112",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "BT1DKXKEZ2SZ",
    "outputId": "7f8c491d-b685-42ec-f3d5-ab46996c667d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.870260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>37.460074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.870000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>256.0</td>\n",
       "      <td>36.905247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>37.130772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.862987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>36.935218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.862922</td>\n",
       "      <td>0.990074</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>37.860035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.862922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>37.093434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.862922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.058430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.855909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>37.039209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.848636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>36.982854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.848636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>37.252066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.848442</td>\n",
       "      <td>0.889010</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>37.390518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.848442</td>\n",
       "      <td>0.882695</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>512.0</td>\n",
       "      <td>38.349609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.845130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>38.874903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.845065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>37.029720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>37.147985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.921788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>37.581247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.545547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.841234</td>\n",
       "      <td>0.911557</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>128.0</td>\n",
       "      <td>37.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.902540</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>512.0</td>\n",
       "      <td>36.988574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.921491</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>512.0</td>\n",
       "      <td>37.422635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.834091</td>\n",
       "      <td>0.985561</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.848091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.801623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>36.907207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.801623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>512.0</td>\n",
       "      <td>36.826546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.801494</td>\n",
       "      <td>0.822205</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.822932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.797922</td>\n",
       "      <td>0.821300</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.25</td>\n",
       "      <td>35.736834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.776364</td>\n",
       "      <td>0.790612</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.178445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.762143</td>\n",
       "      <td>0.822188</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>37.227526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.736883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.065445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.711558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>37.316617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.599481</td>\n",
       "      <td>0.597460</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.569452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.577792</td>\n",
       "      <td>0.581220</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.5</td>\n",
       "      <td>36.791865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.548701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.920168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.548701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.087922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.548701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>33.434939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.519870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.006232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.516299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.711419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.509091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>36.938557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.509091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>38.150451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.509091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.407530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>37.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>38.501286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>37.535631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>37.902738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>37.303306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.5</td>\n",
       "      <td>37.200239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.516245</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>37.051337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.808744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.505418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>36.878524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score  mean_train_score param_svc__gamma  \\\n",
       "rank_test_score                                                       \n",
       "1                       0.870260          1.000000         0.000244   \n",
       "2                       0.870000          1.000000          0.03125   \n",
       "3                       0.866688          1.000000         0.000244   \n",
       "4                       0.862987          1.000000         0.000244   \n",
       "5                       0.862922          0.990074         0.000031   \n",
       "5                       0.862922          1.000000         0.015625   \n",
       "5                       0.862922          1.000000         0.015625   \n",
       "8                       0.855909          1.000000         0.000488   \n",
       "9                       0.848636          1.000000         0.000977   \n",
       "9                       0.848636          1.000000         0.000977   \n",
       "11                      0.848442          0.889010         0.000031   \n",
       "11                      0.848442          0.882695         0.000031   \n",
       "13                      0.845130          1.000000         0.003906   \n",
       "14                      0.845065          1.000000         0.001953   \n",
       "15                      0.845000          1.000000           0.0625   \n",
       "15                      0.845000          1.000000           0.0625   \n",
       "15                      0.845000          1.000000           0.0625   \n",
       "15                      0.845000          1.000000           0.0625   \n",
       "19                      0.841234          0.911557         0.000488   \n",
       "20                      0.837662          0.902540         0.000122   \n",
       "20                      0.837662          0.921491         0.000244   \n",
       "22                      0.834091          0.985561           0.0625   \n",
       "23                      0.801623          1.000000            0.125   \n",
       "23                      0.801623          1.000000            0.125   \n",
       "25                      0.801494          0.822205         0.000977   \n",
       "26                      0.797922          0.821300         0.003906   \n",
       "27                      0.776364          0.790612         0.000061   \n",
       "28                      0.762143          0.822188          0.03125   \n",
       "29                      0.736883          1.000000             0.25   \n",
       "30                      0.711558          1.000000              0.5   \n",
       "31                      0.599481          0.597460         0.000061   \n",
       "32                      0.577792          0.581220         0.000488   \n",
       "33                      0.548701          1.000000              1.0   \n",
       "33                      0.548701          1.000000              1.0   \n",
       "33                      0.548701          1.000000              1.0   \n",
       "36                      0.519870          1.000000              2.0   \n",
       "37                      0.516299          1.000000              2.0   \n",
       "38                      0.509091          1.000000              4.0   \n",
       "38                      0.509091          1.000000              4.0   \n",
       "38                      0.509091          1.000000              4.0   \n",
       "41                      0.505455          0.505418             0.25   \n",
       "41                      0.505455          0.505418              0.5   \n",
       "41                      0.505455          0.505418              2.0   \n",
       "41                      0.505455          0.505418              4.0   \n",
       "41                      0.505455          0.505418         0.000031   \n",
       "41                      0.505455          0.505418         0.000977   \n",
       "41                      0.505455          0.505418         0.000122   \n",
       "41                      0.505455          0.516245              2.0   \n",
       "41                      0.505455          1.000000              4.0   \n",
       "41                      0.505455          0.505418              0.5   \n",
       "\n",
       "                param_svc__C  mean_fit_time  \n",
       "rank_test_score                              \n",
       "1                     8192.0      37.460074  \n",
       "2                      256.0      36.905247  \n",
       "3                     4096.0      37.130772  \n",
       "4                    16384.0      36.935218  \n",
       "5                    16384.0      37.860035  \n",
       "5                     4096.0      37.093434  \n",
       "5                       64.0      37.058430  \n",
       "8                     2048.0      37.039209  \n",
       "9                    16384.0      36.982854  \n",
       "9                     2048.0      37.252066  \n",
       "11                    1024.0      37.390518  \n",
       "11                     512.0      38.349609  \n",
       "13                    1024.0      38.874903  \n",
       "14                    4096.0      37.029720  \n",
       "15                    4096.0      37.147985  \n",
       "15                       8.0      37.921788  \n",
       "15                    8192.0      37.581247  \n",
       "15                      32.0      36.545547  \n",
       "19                     128.0      37.001164  \n",
       "20                     512.0      36.988574  \n",
       "20                     512.0      37.422635  \n",
       "22                       1.0      36.848091  \n",
       "23                    1024.0      36.907207  \n",
       "23                     512.0      36.826546  \n",
       "25                       1.0      36.822932  \n",
       "26                      0.25      35.736834  \n",
       "27                       8.0      37.178445  \n",
       "28                    0.0625      37.227526  \n",
       "29                      64.0      37.065445  \n",
       "30                    1024.0      37.316617  \n",
       "31                       4.0      37.569452  \n",
       "32                       0.5      36.791865  \n",
       "33                      32.0      37.920168  \n",
       "33                       2.0      37.087922  \n",
       "33                      64.0      33.434939  \n",
       "36                      64.0      37.006232  \n",
       "37                       1.0      36.711419  \n",
       "38                    8192.0      36.938557  \n",
       "38                    2048.0      38.150451  \n",
       "38                       2.0      37.407530  \n",
       "41                   0.03125      37.004845  \n",
       "41                     0.125      38.501286  \n",
       "41                     0.125      37.535631  \n",
       "41                   0.03125      37.902738  \n",
       "41                       4.0      37.000349  \n",
       "41                   0.03125      37.303306  \n",
       "41                       0.5      37.200239  \n",
       "41                       0.5      37.051337  \n",
       "41                       1.0      36.808744  \n",
       "41                   0.03125      36.878524  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\n",
    "        'mean_test_score',\n",
    "        'mean_train_score',\n",
    "        'param_svc__gamma',\n",
    "        'param_svc__C',\n",
    "        'mean_fit_time',\n",
    "        'rank_test_score',\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4050f62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWDgj66jU1Ts",
    "outputId": "3b8062dc-d736-4868-9432-dd4280fab555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search best hyperparameters: {'svc__gamma': 0.000244140625, 'svc__C': 8192.0}\n",
      "Random Search best model score: 0.870\n",
      "Train score on the full train set: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Search best hyperparameters: %s\" % (random_search.best_params_))\n",
    "print(\"Random Search best model score: %0.3f\" % (random_search.best_score_))\n",
    "print(\n",
    "    \"Train score on the full train set: %0.3f\" % (random_search.score(X_train_feat, y_train_feat))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6d649",
   "metadata": {},
   "source": [
    "## Fine-grained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d657f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM baseline</th>\n",
       "      <th>SVM + all feats</th>\n",
       "      <th>SVM_fine + all feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>22.103144</td>\n",
       "      <td>17.394472</td>\n",
       "      <td>17.687780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>5.216887</td>\n",
       "      <td>4.266932</td>\n",
       "      <td>4.212239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.834091</td>\n",
       "      <td>0.581234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.827651</td>\n",
       "      <td>0.925087</td>\n",
       "      <td>0.812311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SVM baseline  SVM + all feats  SVM_fine + all feats\n",
       "fit_time           22.103144        17.394472             17.687780\n",
       "score_time          5.216887         4.266932              4.212239\n",
       "test_accuracy       0.804805         0.834091              0.581234\n",
       "train_accuracy      0.827651         0.925087              0.812311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_and_display(preprocessor, all_feat_model, 'SVM_fine + all feats', X_train_feat, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7ff6c92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zP9jfTWTkaM",
    "outputId": "02691f47-d448-4518-a73e-ef0dd9856faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ecc798f7cccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                    \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                    verbose=10) # default n_iter=10\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlp/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# gamma and C value range taken from https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "param_grid = {\n",
    "    \"svc__gamma\": 2.0 ** np.arange(-15, 3),\n",
    "    \"svc__C\": 2.0 ** np.arange(-5, 15)\n",
    "}\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature),\n",
    ")\n",
    "\n",
    "best_model = make_pipeline(\n",
    "        preprocessor, SVC(random_state=123)\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(best_model, \n",
    "                                   scoring='accuracy', \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_jobs=-1, \n",
    "                                   n_iter=20, \n",
    "                                   cv=5,\n",
    "                                   return_train_score=True,\n",
    "                                   verbose=10) # default n_iter=10\n",
    "random_search.fit(X_train_feat, y_train_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e1a60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "BT1DKXKEZ2SZ",
    "outputId": "7f8c491d-b685-42ec-f3d5-ab46996c667d"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\n",
    "        'mean_test_score',\n",
    "        'mean_train_score',\n",
    "        'param_svc__gamma',\n",
    "        'param_svc__C',\n",
    "        'mean_fit_time',\n",
    "        'rank_test_score',\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfceb973",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWDgj66jU1Ts",
    "outputId": "3b8062dc-d736-4868-9432-dd4280fab555"
   },
   "outputs": [],
   "source": [
    "print(\"Random Search best hyperparameters: %s\" % (random_search.best_params_))\n",
    "print(\"Random Search best model score: %0.3f\" % (random_search.best_score_))\n",
    "print(\n",
    "    \"Train score on the full train set: %0.3f\" % (random_search.score(X_train_feat, y_train_feat))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588cf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
