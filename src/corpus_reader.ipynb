{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vietnamese-dealer",
   "metadata": {},
   "source": [
    "## Read all files from `../corpus/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handled-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "enhanced-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sporting-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_reader(path):\n",
    "    \"\"\"\n",
    "    Given a path to a directory containing JSON files of the scraped corpus\n",
    "    documents and their metadata, load them all into a dict{list[dicts]}\n",
    "    such that:\n",
    "    {\n",
    "        \"A1\": [{\"source\": \"...\", \"content\": \"...\", ...}, {...}],\n",
    "        \"A2\": [...],\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    path: (str) the path of the directory containing the JSON files\n",
    "    \n",
    "    corpus: (dict{list[dicts]}) a dictionary of texts arranged by reading level\n",
    "    (a text is a single cohesive piece of reading material, be it a short\n",
    "    story, a poem, song lyrics, a book chapter, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = defaultdict(list)\n",
    "    for file in os.listdir(path):\n",
    "        with open(os.path.join(path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            doc_list = json.load(f)\n",
    "            for d in doc_list:\n",
    "                corpus[d[\"level\"]].append(d)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "commercial-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus_reader(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "educated-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['A1', 'A2', 'B', 'B1/B2', 'A2/B1'])\n",
      "\n",
      "Number of A1-level texts: 51\n",
      "Number of A2-level texts: 51\n",
      "Number of B-level texts: 21\n",
      "Number of B1/B2-level texts: 89\n",
      "Number of A2/B1-level texts: 31\n"
     ]
    }
   ],
   "source": [
    "print(corpus.keys())\n",
    "print()\n",
    "for k, v in corpus.items():\n",
    "    print(f\"Number of {k}-level texts: {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-somerset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
