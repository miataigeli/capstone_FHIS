{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eda647ee2a264777af43c470e7093278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a420f6f9d3c4edcb887fde656045e88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_22fce0eaa7aa49e3b041fc13bc88ff5a",
              "IPY_MODEL_bb58b9fb37f04c75b8775f997754d063"
            ]
          }
        },
        "0a420f6f9d3c4edcb887fde656045e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22fce0eaa7aa49e3b041fc13bc88ff5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79abac01b0f647ee96eebe1b4b9d3f91",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1acf8acc93d44fcd84c95bad7ed65f36"
          }
        },
        "bb58b9fb37f04c75b8775f997754d063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f7215e95a47415ebb07c15839f89734",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [26:27&lt;00:00, 627B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35c088bca38f494c8003f65ce033e76a"
          }
        },
        "79abac01b0f647ee96eebe1b4b9d3f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1acf8acc93d44fcd84c95bad7ed65f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f7215e95a47415ebb07c15839f89734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35c088bca38f494c8003f65ce033e76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edd5261cc111458eaf197f6a5709f27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2133ac381c9b41b5a6dda34ae2ec1fd8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1bdb4b2df614282a8c489232087da7c",
              "IPY_MODEL_de917d0547dc42fb940f4fd1d02ac534"
            ]
          }
        },
        "2133ac381c9b41b5a6dda34ae2ec1fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1bdb4b2df614282a8c489232087da7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eaf3238fc20c4ac29e1a68e63cc1e6e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1961828,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1961828,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfbb7c2be04d4efcbfa1ee9f4f86f6e9"
          }
        },
        "de917d0547dc42fb940f4fd1d02ac534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35d5764cb6454acea9e15ff773c9d738",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.96M/1.96M [00:13&lt;00:00, 147kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0300bfa969e64dedbcfb4e363feb189b"
          }
        },
        "eaf3238fc20c4ac29e1a68e63cc1e6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfbb7c2be04d4efcbfa1ee9f4f86f6e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35d5764cb6454acea9e15ff773c9d738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0300bfa969e64dedbcfb4e363feb189b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8b443ceb3b14287bbe22221daffa2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab4528b4407142fbab6461310950ae38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ddc0b2fb8d9c48dfa5def20dc4c9d13a",
              "IPY_MODEL_6ec5a78648d94930a48c1ac4cb27866b"
            ]
          }
        },
        "ab4528b4407142fbab6461310950ae38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddc0b2fb8d9c48dfa5def20dc4c9d13a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89cf3a5e3576453096725ef6699c2661",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cf8feb0c4ae4a18966921c3b766c91c"
          }
        },
        "6ec5a78648d94930a48c1ac4cb27866b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6bc89dd06b346a2bcb318f843965f2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:11&lt;00:00, 2.55B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b17e38382fc4ecfa963bdaca4f4e91d"
          }
        },
        "89cf3a5e3576453096725ef6699c2661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cf8feb0c4ae4a18966921c3b766c91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6bc89dd06b346a2bcb318f843965f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b17e38382fc4ecfa963bdaca4f4e91d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96dc677f9954459cb7743cbbea2233c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7c87696955446ac834e5a23d57c7819",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9235290f66bd4793a51b9ab74e044d28",
              "IPY_MODEL_8bc40f57bde54b7483abeee2bf360e17"
            ]
          }
        },
        "e7c87696955446ac834e5a23d57c7819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9235290f66bd4793a51b9ab74e044d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35c390c13cf64f7d9d3c4e589cb49112",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce433c6ff479443fb36492a80860034c"
          }
        },
        "8bc40f57bde54b7483abeee2bf360e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02a2897e954241ee8719b8c004d70fe1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 20.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f0eef3fdb564bc4afe3c33490ef0897"
          }
        },
        "35c390c13cf64f7d9d3c4e589cb49112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce433c6ff479443fb36492a80860034c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02a2897e954241ee8719b8c004d70fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f0eef3fdb564bc4afe3c33490ef0897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ec9553d0eca452f84c04958bd8607c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_698811ee936146a1a09095bfaf3c15d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75404f00e59c4565a7afc5e9d51672b6",
              "IPY_MODEL_497d27a1b7234a58920762f6fb10ac41"
            ]
          }
        },
        "698811ee936146a1a09095bfaf3c15d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75404f00e59c4565a7afc5e9d51672b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_178308f996834323b2965358e48e6721",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f5fd080c99141d88bf78129f33cfa4d"
          }
        },
        "497d27a1b7234a58920762f6fb10ac41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5aa77091c94c4b18bfb1cd0df01d687e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:14&lt;00:00, 50.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e6b55212a2d48c3ad0f85137ea751e1"
          }
        },
        "178308f996834323b2965358e48e6721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f5fd080c99141d88bf78129f33cfa4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5aa77091c94c4b18bfb1cd0df01d687e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e6b55212a2d48c3ad0f85137ea751e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miataigeli/capstone_FHIS/blob/darya/src/bert_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xKLzIOjIkBE"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM1b2qIR2caa"
      },
      "source": [
        "In this notebook, we create a BERT pipeline to load the Multiligual BERT model and use it along with two linear layers to do a text classification task - to determine whether the text passed in is 'A1', 'A2' or 'B' level according to the European CERF framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-um0cGSk2X"
      },
      "source": [
        "Based on tutorial here: https://www.youtube.com/watch?v=mw7ay38--ak as well as the BERT tutorial from COLX585: https://github.ubc.ca/MDS-CL-2020-21/COLX_585_trends_students/blob/master/tutorials/BPE-BERT/bert_pytorch.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "injEHSVkWE1X"
      },
      "source": [
        "#### Imports and Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj0W0YOdIPi1",
        "outputId": "2f976913-2570-4d1d-f10d-0d40d1c3db81"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/92/6153f4912b84ee1ab53ab45663d23e7cf3704161cb5ef18b0c07e207cef2/transformers-4.7.0-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 57.6MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 28.0MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak550KxaIpl1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IInqOgwdI5lb"
      },
      "source": [
        "#specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS80BGDmKUIS",
        "outputId": "e342b5dc-4947-4403-b13b-ed4bce05731b"
      },
      "source": [
        "#connect to my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m7XORvdJGiw"
      },
      "source": [
        "### Load and Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMVVAVwdncO_"
      },
      "source": [
        "We read in the corpus from JSON files created previously. For the classification, we will only need the text and its label, which are contained in the `content` and `level` columns, so those are the only ones we keep. The splits are already done, so the files we read in are `train.json`, `val.json` and `test.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VnN6jmTLkdJ",
        "outputId": "c3c1a905-e44e-4d30-865d-496939cce160"
      },
      "source": [
        "# Read in all json files into one pandas dataframe\n",
        "import os\n",
        "\n",
        "corpus_dir = \"/content/drive/MyDrive/capstone/corpus\"\n",
        "\n",
        "for filename in os.listdir(corpus_dir):\n",
        "    if filename.endswith(\"train.json\"): \n",
        "         file_path = os.path.join(corpus_dir, filename)\n",
        "         train_df = pd.read_json(file_path)\n",
        "         train_df = train_df.drop(columns=['source', 'author', 'title'])\n",
        "    elif filename.endswith(\"val.json\"):\n",
        "         file_path = os.path.join(corpus_dir, filename)\n",
        "         val_df = pd.read_json(file_path)\n",
        "         val_df = val_df.drop(columns=['source', 'author', 'title'])\n",
        "    elif filename.endswith(\"test.json\"):\n",
        "         file_path = os.path.join(corpus_dir, filename)\n",
        "         test_df = pd.read_json(file_path)\n",
        "         test_df = test_df.drop(columns=['source', 'author', 'title'])\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "print(\"Train: \\n\", train_df.describe(), \"\\n\")\n",
        "print(\"Val: \\n\", val_df.describe(), \"\\n\")\n",
        "print(\"Test: \\n\", test_df.describe(), \"\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: \n",
            "        level                                            content\n",
            "count    257                                                257\n",
            "unique     3                                                257\n",
            "top        B  Capítulo VI y VII     (RESUMEN) \\nDel donoso y...\n",
            "freq     122                                                  1 \n",
            "\n",
            "Val: \n",
            "        level                                            content\n",
            "count     32                                                 32\n",
            "unique     3                                                 32\n",
            "top        B  28. TRES PALABRAS\\nUn jornalero pobre llegó po...\n",
            "freq      15                                                  1 \n",
            "\n",
            "Test: \n",
            "        level                                            content\n",
            "count     32                                                 32\n",
            "unique     3                                                 32\n",
            "top        B  LOS DOS CONEJOS\\n\\nPor entre unas matas\\nSegui...\n",
            "freq      15                                                  1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYx2n0zMRHcc",
        "outputId": "5ced2df8-395d-4ec0-9db5-b2b30e434238"
      },
      "source": [
        "# View class splits\n",
        "train_df['level'].value_counts(normalize = True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B     0.474708\n",
              "A1    0.330739\n",
              "A2    0.194553\n",
              "Name: level, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o66HoaGRnnuX"
      },
      "source": [
        "As we can see, currently the text is classified into A1, A2, and B levels. Although the CEFR framework includes other levels, we will only use these for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vab74dGRXHR"
      },
      "source": [
        "### Split into text and level lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEBc1K0zXx-c"
      },
      "source": [
        "# Define label to number dictionary\n",
        "lab2ind = {'A1': 0,\n",
        "           'A2': 1,\n",
        "           'B': 2\n",
        "           }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sTwHvLFkqat"
      },
      "source": [
        "train_text, train_levels = list(train_df['content']), list(train_df['level'])\n",
        "val_text, val_levels = list(val_df['content']), list(val_df['level'])\n",
        "test_text, test_levels = list(test_df['content']), list(test_df['level'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5c0NQMV3V9p"
      },
      "source": [
        "We load the tokenizer from the pre-trained BERT model. We use the full-size multilingual BERT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "eda647ee2a264777af43c470e7093278",
            "0a420f6f9d3c4edcb887fde656045e88",
            "22fce0eaa7aa49e3b041fc13bc88ff5a",
            "bb58b9fb37f04c75b8775f997754d063",
            "79abac01b0f647ee96eebe1b4b9d3f91",
            "1acf8acc93d44fcd84c95bad7ed65f36",
            "8f7215e95a47415ebb07c15839f89734",
            "35c088bca38f494c8003f65ce033e76a",
            "edd5261cc111458eaf197f6a5709f27b",
            "2133ac381c9b41b5a6dda34ae2ec1fd8",
            "c1bdb4b2df614282a8c489232087da7c",
            "de917d0547dc42fb940f4fd1d02ac534",
            "eaf3238fc20c4ac29e1a68e63cc1e6e8",
            "dfbb7c2be04d4efcbfa1ee9f4f86f6e9",
            "35d5764cb6454acea9e15ff773c9d738",
            "0300bfa969e64dedbcfb4e363feb189b",
            "e8b443ceb3b14287bbe22221daffa2b7",
            "ab4528b4407142fbab6461310950ae38",
            "ddc0b2fb8d9c48dfa5def20dc4c9d13a",
            "6ec5a78648d94930a48c1ac4cb27866b",
            "89cf3a5e3576453096725ef6699c2661",
            "1cf8feb0c4ae4a18966921c3b766c91c",
            "d6bc89dd06b346a2bcb318f843965f2f",
            "1b17e38382fc4ecfa963bdaca4f4e91d"
          ]
        },
        "id": "9NeauiSJ33Rm",
        "outputId": "f873b8f1-ebd9-488b-82f9-8300d3e47e7f"
      },
      "source": [
        "model_path = 'bert-base-multilingual-cased' # multilingual model\n",
        "# tokenizer from pre-trained BERT model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path, return_tensors='pt')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eda647ee2a264777af43c470e7093278",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edd5261cc111458eaf197f6a5709f27b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8b443ceb3b14287bbe22221daffa2b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL8ElIF6w0Y4"
      },
      "source": [
        "### Prepare data for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WLkZ3i040Ah"
      },
      "source": [
        "# We made the chunk size 256 in case we wanted to append linguistic features after the text,\n",
        "# and stay within the 512-token limit for BERT.\n",
        "# We include options to return the original texts, as well as use only the first 256 tokens\n",
        "# for classification in the prepare_data function.\n",
        "CHUNK_SIZE = 256\n",
        "\n",
        "# Prepare data\n",
        "def prepare_data(texts, levels, return_texts=False, first_256_only=False):\n",
        "  ''' Preprocesses the data for classification. Tokenizes the texts, and splits them into chunks of \n",
        "      CHUNK_SIZE tokens in order to be below the limit for BERT.\n",
        "\n",
        "      Arguments:\n",
        "      ---------------------\n",
        "      texts: texts to prepare\n",
        "      levels: the labels for the texts\n",
        "      return_texts: whether to return the original texts or not. False by default.\n",
        "      first_256_only: option to use only the first 256 tokens in the text instead of splitting \n",
        "                      into 256-token strings (mostly for testing preliminary model). False by default.\n",
        "\n",
        "      Returns:\n",
        "      ---------------------\n",
        "      inputs: prepared chunked and tokenized texts\n",
        "      labels: the labels corresponding to the inputs\n",
        "      orig_texts: a list of the original texts\n",
        "\n",
        "    '''\n",
        "\n",
        "  # Tokenize texts\n",
        "  tokenized_texts = []\n",
        "  for text in texts:\n",
        "     tok_text = tokenizer.batch_encode_plus([text], padding=False, return_token_type_ids=False, return_tensors='pt')#, max_length=256)\n",
        "     tokenized_texts.append(tok_text)\n",
        "\n",
        "  # Convert levels to their corresponding number\n",
        "  levels = [lab2ind[i] for i in levels]\n",
        "  labels_orig = torch.tensor(levels)\n",
        "  \n",
        "  # Split texts into CHUNK_SIZE tokens per \n",
        "  orig_texts = []\n",
        "  input_ids_chunks = []\n",
        "  labels_chunks = []\n",
        "  mask_chunks = []\n",
        "  i = 0\n",
        "  for tok_text, label in zip(tokenized_texts, levels):\n",
        "      input_id = list(tok_text['input_ids'][0])\n",
        "      attention_mask = list(tok_text['attention_mask'][0])\n",
        "      if len(input_id) > CHUNK_SIZE:\n",
        "          # Chop up into smaller pieces\n",
        "          # in this case, we consider all chunks of 256\n",
        "          # and discard any tokens left outside of the last 256-token chunk\n",
        "          if first_256_only:\n",
        "            input_ids_chunks += [np.array(input_id[:CHUNK_SIZE])]\n",
        "            labels_chunks += [label]\n",
        "            attention = [1] * CHUNK_SIZE\n",
        "            mask_chunks += [attention]\n",
        "            orig_texts.append(texts[i][:CHUNK_SIZE])\n",
        "          else:\n",
        "            remainder = len(input_id) % CHUNK_SIZE\n",
        "            input_id = input_id[:-remainder]\n",
        "            attention_mask = attention_mask[:-remainder]\n",
        "            num_chunks = len(input_id) // CHUNK_SIZE\n",
        "            input_id_lst = np.array_split(np.array(input_id),num_chunks)\n",
        "            mask_lst = np.array_split(np.array(attention_mask),num_chunks)\n",
        "            labels_lst = [label] * len(input_id_lst)\n",
        "            for chunk in range(num_chunks):\n",
        "              orig_text = texts[i][CHUNK_SIZE*chunk:(CHUNK_SIZE*chunk)+CHUNK_SIZE]\n",
        "              orig_texts.append(orig_text)\n",
        "            input_ids_chunks += input_id_lst\n",
        "            labels_chunks += labels_lst\n",
        "            mask_chunks += mask_lst\n",
        "      else:\n",
        "          # In this case, we consider the entire string since this is a full text,\n",
        "          # pad the remaining 256-len(tokens) chars,\n",
        "          # and make an attention mask to distinguish content from padding\n",
        "          padding = [0] * (CHUNK_SIZE-len(input_id))\n",
        "          input_ids_chunks += [np.array(input_id + padding)]\n",
        "          labels_chunks += [label]\n",
        "          attention = [1] * len(input_id)\n",
        "          mask_chunks += [attention + padding]\n",
        "          orig_texts.append(texts[i])\n",
        "      i += 1\n",
        "  \n",
        "  # Test that all labels have length 256\n",
        "  for i, (input_id_chunk, mask_chunk) in enumerate(zip(input_ids_chunks, mask_chunks)):\n",
        "    assert len(input_id_chunk) == CHUNK_SIZE, f\"Length of text not {CHUNK_SIZE} at index {i}!\"\n",
        "    assert len(mask_chunk) == CHUNK_SIZE, f\"Length of mask not {CHUNK_SIZE} at index {i}!\"\n",
        "\n",
        "  # Convert all of our data into torch tensors, the required datatype for our model\n",
        "  inputs = torch.tensor(input_ids_chunks)\n",
        "  masks = torch.tensor(mask_chunks)\n",
        "  labels = torch.tensor(labels_chunks)\n",
        "\n",
        "  if return_texts:\n",
        "    return inputs, masks, labels, orig_texts\n",
        "  else:\n",
        "    return inputs, masks, labels"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuhSCUaTpObo"
      },
      "source": [
        "Prepare the training, validation and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cESkbgF8BQKo",
        "outputId": "ee4e72cc-b76a-4864-cb3c-2ed5e90445b0"
      },
      "source": [
        "# Training data\n",
        "train_inputs, train_masks, train_labels = prepare_data(train_text, train_levels)\n",
        "print(train_inputs.shape)\n",
        "print(train_masks.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1133, 256])\n",
            "torch.Size([1133, 256])\n",
            "torch.Size([1133])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLKAj5UHE7VQ",
        "outputId": "ec17e45b-bafd-400d-8c56-a441c028e4f3"
      },
      "source": [
        "# Validation data\n",
        "valid_inputs, valid_masks, valid_labels = prepare_data(val_text, val_levels)\n",
        "print(valid_inputs.shape)\n",
        "print(valid_masks.shape)\n",
        "print(valid_labels.shape)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([129, 256])\n",
            "torch.Size([129, 256])\n",
            "torch.Size([129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGSjlIj9FPfo",
        "outputId": "b432dfda-8b83-4599-c178-576f22cd2d94"
      },
      "source": [
        "# Test data\n",
        "test_inputs, test_masks, test_labels, test_texts = prepare_data(test_text, test_levels, return_texts=True) # we return the texts to do error analysis\n",
        "print(test_inputs.shape)\n",
        "print(test_masks.shape)\n",
        "print(test_labels.shape)\n",
        "print(len(test_texts))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([139, 256])\n",
            "torch.Size([139, 256])\n",
            "torch.Size([139])\n",
            "139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8FVx7lQe0vQ",
        "outputId": "edd46c3a-1a6d-4640-cb14-b3e91502b710"
      },
      "source": [
        "print(test_texts[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CAPÍtULO 7\n",
            "\n",
            "—¡Paren ya de pelearse! —el hombre alto llega delante de la \n",
            "choza. Está enfadado.\n",
            "\n",
            "El hombre de la trenza y el guardián de la choza paran al oír la voz.\n",
            "Junto al hombre alto hay otros dos huaqueros, que miran divertidos la escena.\n",
            "—¿Qué pasó..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfkp7szIqlKr"
      },
      "source": [
        "Although we started with an 80-10-10 split between training data, validation data and test data from the JSON files we imported, the variability of the lengths of the texts in the splits changed the split slightly. Splitting the texts into 256-character chunks gave us 1401 texts in total, with 1133 of those from the training data, 129 from the validation data and 139 from the test data. It is still roughly 80-10-10, but with a little bit more test data than validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbHcyc0F25rz"
      },
      "source": [
        "# Create an iterator for our data\n",
        "batch_size = 3\n",
        "# We'll take training samples in random order in each epoch. \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, \n",
        "                              sampler = RandomSampler(train_data), # Select batches randomly\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "# We'll just read validation set sequentially.\n",
        "validation_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
        "validation_dataloader = DataLoader(validation_data, \n",
        "                                   sampler = SequentialSampler(validation_data), # Pull out batches sequentially.\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjmsPllYMVX3",
        "outputId": "a04487ce-bca0-4567-8578-2971605e872e"
      },
      "source": [
        "# Make sure dataloaders are correct\n",
        "print(len(validation_dataloader))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y_r0nQbZC5Y"
      },
      "source": [
        "#### BERT Class\n",
        "\n",
        "We create a BERT class so that we have a pipeline to train the model. The class is initialized with the pretrained BERT model, a hidden layer size, two linear layers and a dropout. The `forward` method generates a BERT representation of the input using the pretrained model (contained in `pooler_output`), passes the representations into the first linear layer, then to a TanH activation function and dropout function, and then to the final linear layer, and returns the output.\n",
        "\n",
        "This way, two feed-forward layers are added on top of the BERT representation in order to provide a classification. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M67qPgDQZFCS"
      },
      "source": [
        "model_path = 'bert-base-multilingual-cased'\n",
        "class Bert_cls(nn.Module):\n",
        "\n",
        "    def __init__(self, lab2ind, model_path, hidden_size):\n",
        "        ''' Initializes the class. \n",
        "\n",
        "        Arguments: label to index dictionary, path to pretrained model, hidden layer size.\n",
        "\n",
        "        Returns: None\n",
        "\n",
        "        '''\n",
        "        super(Bert_cls, self).__init__()\n",
        "        self.model_path = model_path\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bert_model = BertModel.from_pretrained(model_path)\n",
        "        \n",
        "        self.label_num = len(lab2ind)\n",
        "        \n",
        "        self.dense = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.label_num)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, input_masks):\n",
        "        ''' Generates a BERT representation of the input using the pretrained model, \n",
        "        passes the representations into the first linear layer, then to a TanH activation function and dropout function,\n",
        "        and then to the final linear layer, followed by a softmax function to get the final class probabilities.\n",
        "        \n",
        "        Arguments: input_ids, attention masks\n",
        "\n",
        "        Returns: outputs of neural network and attention mask.\n",
        "        '''\n",
        "        outputs = self.bert_model(input_ids, input_masks)\n",
        "        pooler_output = outputs['pooler_output']\n",
        "        #attentions = outputs['attentions'] #this is need in case padding is used\n",
        "        \n",
        "        x = self.dense(pooler_output)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        fc_output = self.fc(x)\n",
        "        output = self.softmax(fc_output)\n",
        "\n",
        "        return output#, attentions"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AQdDqRSZVw7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "96dc677f9954459cb7743cbbea2233c0",
            "e7c87696955446ac834e5a23d57c7819",
            "9235290f66bd4793a51b9ab74e044d28",
            "8bc40f57bde54b7483abeee2bf360e17",
            "35c390c13cf64f7d9d3c4e589cb49112",
            "ce433c6ff479443fb36492a80860034c",
            "02a2897e954241ee8719b8c004d70fe1",
            "1f0eef3fdb564bc4afe3c33490ef0897",
            "8ec9553d0eca452f84c04958bd8607c5",
            "698811ee936146a1a09095bfaf3c15d2",
            "75404f00e59c4565a7afc5e9d51672b6",
            "497d27a1b7234a58920762f6fb10ac41",
            "178308f996834323b2965358e48e6721",
            "1f5fd080c99141d88bf78129f33cfa4d",
            "5aa77091c94c4b18bfb1cd0df01d687e",
            "4e6b55212a2d48c3ad0f85137ea751e1"
          ]
        },
        "outputId": "cba50742-b4bd-4c3a-bc41-87e6f5986cbf"
      },
      "source": [
        "# Instantiate model\n",
        "bert_model = Bert_cls(lab2ind, model_path, 768).to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96dc677f9954459cb7743cbbea2233c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ec9553d0eca452f84c04958bd8607c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVnosKCWZi_t",
        "outputId": "7526f013-3b01-4b52-e1a7-f44325eebeb6"
      },
      "source": [
        "# Count number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(bert_model):,} trainable parameters')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 178,446,339 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf39H5euZpGc"
      },
      "source": [
        "#### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XkeKGhcZsPM"
      },
      "source": [
        "# Parameters:\n",
        "lr = 5e-6 # 2e-5\n",
        "max_grad_norm = 1.0\n",
        "epochs = 30\n",
        "warmup_proportion = 0.1\n",
        "num_training_steps  = len(train_dataloader) * epochs\n",
        "num_warmup_steps = num_training_steps * warmup_proportion\n",
        "\n",
        "### Instantiate optimizer and scheduler\n",
        "optimizer = AdamW(bert_model.parameters(), lr=lr, correct_bias=False)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n",
        "\n",
        "# Use Cross-Entropy loss as our loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOoQVKArZ0Fe"
      },
      "source": [
        "# Training the model\n",
        "def train(model, iterator, optimizer, scheduler, criterion, max_grad_norm=1.0):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        input_ids, input_masks, labels = batch\n",
        "\n",
        "        # outputs,_ = model(input_ids, input_mask)\n",
        "        outputs = model(input_ids, input_masks)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        # delete used variables to free GPU memory\n",
        "        del batch, input_ids, input_masks, labels\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss += loss.cpu().item()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    # free GPU memory\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifWFXwEzZ335"
      },
      "source": [
        "# Evaluate function\n",
        "def evaluate(model, iterator, criterion, return_preds=False):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            input_ids, input_masks, labels = batch\n",
        "\n",
        "            outputs = model(input_ids, input_masks)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # delete used variables to free GPU memory\n",
        "            del batch, input_ids, input_masks\n",
        "            epoch_loss += loss.cpu().item()\n",
        "\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    if return_preds:\n",
        "      return epoch_loss / len(iterator), accuracy, f1score, all_pred\n",
        "    else:\n",
        "      return epoch_loss / len(iterator), accuracy, f1score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X993LzWmaBym"
      },
      "source": [
        "# create checkpoint directory\n",
        "import os\n",
        "save_path = './drive/My Drive/Colab Notebooks/ckpt_BERT/'\n",
        "if os.path.exists(save_path) == False:\n",
        "    os.makedirs(save_path)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6RJ3UreaCWp",
        "outputId": "ac9cf1bd-f075-44fb-af44-6af757d56dc3"
      },
      "source": [
        "from tqdm import trange\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "# Train the model\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = train(bert_model, train_dataloader, optimizer, scheduler, criterion)  \n",
        "    train_loss, train_acc, train_f1 = evaluate(bert_model, train_dataloader, criterion)\n",
        "    val_loss, val_acc, val_f1 = evaluate(bert_model, validation_dataloader, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': bert_model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt_BERT/BERT_\"+str(epoch+1)+\".pt\")\n",
        "    print(f'epoch: {epoch}, Train Loss: {epoch_loss:.3f}, Train Acc: {train_acc:.3f}, Train f1: {train_f1:.3f}, Dev Acc: {val_acc:.3f}, Dev f1: {val_f1:.3f}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, Train Loss: 0.471, Train Acc: 0.903, Train f1: 0.883, Dev Acc: 0.829, Dev f1: 0.757\n",
            "epoch: 0, Train Loss: 0.398, Train Acc: 0.945, Train f1: 0.927, Dev Acc: 0.860, Dev f1: 0.653\n",
            "epoch: 0, Train Loss: 0.230, Train Acc: 0.966, Train f1: 0.958, Dev Acc: 0.876, Dev f1: 0.715\n",
            "epoch: 0, Train Loss: 0.149, Train Acc: 0.981, Train f1: 0.976, Dev Acc: 0.868, Dev f1: 0.768\n",
            "epoch: 0, Train Loss: 0.102, Train Acc: 0.995, Train f1: 0.993, Dev Acc: 0.884, Dev f1: 0.805\n",
            "epoch: 0, Train Loss: 0.032, Train Acc: 0.998, Train f1: 0.998, Dev Acc: 0.868, Dev f1: 0.760\n",
            "epoch: 0, Train Loss: 0.027, Train Acc: 0.995, Train f1: 0.993, Dev Acc: 0.876, Dev f1: 0.797\n",
            "epoch: 0, Train Loss: 0.011, Train Acc: 0.999, Train f1: 0.999, Dev Acc: 0.876, Dev f1: 0.735\n",
            "epoch: 0, Train Loss: 0.009, Train Acc: 0.997, Train f1: 0.997, Dev Acc: 0.891, Dev f1: 0.809\n",
            "epoch: 0, Train Loss: 0.006, Train Acc: 0.992, Train f1: 0.989, Dev Acc: 0.868, Dev f1: 0.791\n",
            "epoch: 0, Train Loss: 0.009, Train Acc: 0.999, Train f1: 0.999, Dev Acc: 0.899, Dev f1: 0.796\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.891, Dev f1: 0.809\n",
            "epoch: 0, Train Loss: 0.005, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.922, Dev f1: 0.872\n",
            "epoch: 0, Train Loss: 0.002, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.001, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.915, Dev f1: 0.861\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.915, Dev f1: 0.861\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.845\n",
            "epoch: 0, Train Loss: 0.003, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.837\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.837\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.837\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.837\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.837\n",
            "epoch: 0, Train Loss: 0.000, Train Acc: 1.000, Train f1: 1.000, Dev Acc: 0.907, Dev f1: 0.837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3AvLzIoQKRQ"
      },
      "source": [
        "#### Evaluate on Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PFvafBLsP44"
      },
      "source": [
        "We create a DataLoader for the test data. Then, we write the test predictions to a file to do error analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggha2OemKUq6"
      },
      "source": [
        "# We'll just read test set sequentially.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_dataloader = DataLoader(test_data, \n",
        "                                   sampler = SequentialSampler(test_data), # Pull out batches sequentially.\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDv1QtoLQP5j"
      },
      "source": [
        "avg_epoch_loss_test, test_accuracy, test_fscore, test_preds = evaluate(bert_model, test_dataloader, criterion, return_preds=True)\n",
        "print(test_accuracy)\n",
        "print(test_fscore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RtEBgb0sKgV"
      },
      "source": [
        "# Convert predictions to strings\n",
        "ind2lab = {0: 'A1', 1: 'A2', 2: 'B'}\n",
        "test_preds = [ind2lab[int(x)] for x in test_preds]\n",
        "test_labels = [ind2lab[int(x)] for x in test_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2514xRvetXnd",
        "outputId": "9bfa54e7-2e73-461f-ddd0-0f3f70e3634e"
      },
      "source": [
        "len(test_texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX3_hmJE2cR2",
        "outputId": "69b5a096-e2cc-4f8f-d451-935705d65eb0"
      },
      "source": [
        "test_df = pd.DataFrame(np.vstack((test_texts, test_preds, test_labels))).astype(\"string\").T\n",
        "test_df.columns = ['test_text', 'test_pred', 'test_gold']\n",
        "print(test_df.shape)\n",
        "# Write to file\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IU8dUImkrPt5",
        "outputId": "9776e135-165a-4c28-875e-6e20ba18de5b"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_text</th>\n",
              "      <th>test_pred</th>\n",
              "      <th>test_gold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CAPÍtULO 7\n",
              "\n",
              "—¡Paren ya de pelearse! —el hombre...</td>\n",
              "      <td>A1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>¡Es con voz de la Biblia, o verso de Walt Whit...</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39. LOS CUATRO HERMANOS\n",
              "Un zapatero tenía cuat...</td>\n",
              "      <td>A2</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Una mañana entró un caballero en la tienda de ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Había un viejo que tenía una hija muy hermosa....</td>\n",
              "      <td>A1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           test_text test_pred test_gold\n",
              "0  CAPÍtULO 7\n",
              "\n",
              "—¡Paren ya de pelearse! —el hombre...        A1        A1\n",
              "1  ¡Es con voz de la Biblia, o verso de Walt Whit...         B         B\n",
              "2  39. LOS CUATRO HERMANOS\n",
              "Un zapatero tenía cuat...        A2        A2\n",
              "3  Una mañana entró un caballero en la tienda de ...        A1        A1\n",
              "4  Había un viejo que tenía una hija muy hermosa....        A1        A1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEOb2iCrucYm"
      },
      "source": [
        "# Write to JSON file\n",
        "test_json = test_df.to_json('/content/drive/MyDrive/capstone/BERT_test_pred_prelim.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "40vbdSSEvrto",
        "outputId": "a297bf25-483f-449b-8a10-90dd7a095998"
      },
      "source": [
        "# Test out reading the dataframe\n",
        "test_df_read = pd.read_json('/content/drive/MyDrive/capstone/BERT_test_pred_prelim.json')\n",
        "test_df_read.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_text</th>\n",
              "      <th>test_pred</th>\n",
              "      <th>test_gold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CAPÍtULO 7\\n\\n—¡Paren ya de pelearse! —el homb...</td>\n",
              "      <td>A1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>¡Es con voz de la Biblia, o verso de Walt Whit...</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39. LOS CUATRO HERMANOS\\nUn zapatero tenía cua...</td>\n",
              "      <td>A2</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Una mañana entró un caballero en la tienda de ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Había un viejo que tenía una hija muy hermosa....</td>\n",
              "      <td>A1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           test_text test_pred test_gold\n",
              "0  CAPÍtULO 7\\n\\n—¡Paren ya de pelearse! —el homb...        A1        A1\n",
              "1  ¡Es con voz de la Biblia, o verso de Walt Whit...         B         B\n",
              "2  39. LOS CUATRO HERMANOS\\nUn zapatero tenía cua...        A2        A2\n",
              "3  Una mañana entró un caballero en la tienda de ...        A1        A1\n",
              "4  Había un viejo que tenía una hija muy hermosa....        A1        A1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njly0BBgP2x6"
      },
      "source": [
        "#### Testing Model Manually\n",
        "\n",
        "Below, I test the model with a few examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtUSRj7sinvm"
      },
      "source": [
        "# Index to label dictionary\n",
        "ind2lab =  {0 :'A1', 1: 'A2', 2: 'B'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh25-GFNx_4r"
      },
      "source": [
        "The first example I took from the corpus manually, it is annotated as A2-level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGQ8DOfzgr7w",
        "outputId": "70900020-9b58-4dcf-fc8b-59f8f0dba59b"
      },
      "source": [
        "text = 'Un chico pelirrojo, un poco gordo, se les acerca sonriendo.\\n\\u2014Hola, M\\u00f3nica. Hola, Laura \\u2014dice.\\nEs Guillermo.\\n\\u2014Hola, Guille \\u2014contestan las chicas\\u2014. Llegas tarde.\\n\\u2014Es que me he dormido.\\n\\u2014S\\u00ed, ya lo veo.\\nGuillermo se sienta al lado de las chicas.\\n\\u2014\\u00bfC\\u00f3mo van? \\u2014pregunta.\\n\\u2014Perdemos por 3 a 1.\\n\\u2014\\u00bfDe verdad?\\n\\u2014S\\u00ed, es que...\\nUn grito interrumpe la conversaci\\u00f3n. \\u00ab\\u00a1Goool!\\u00bb.\\n\\u2014\\u00bfQui\\u00e9n ha marcado? \\u2014pregunta Laura.\\n\\u2014Nosotros.\\n\\u2014Ha marcado Ra\\u00fal, despu\\u00e9s de un pase de Sergio \\u2014explica M\\u00f3nica, contenta.\\n\\n\\ufffd\\n\\n4  f\\u00fatbol sala: modalidad del f\\u00fatbol que se juega en un recinto m\\u00e1s peque\\u00f1o, con \\ncinco jugadores por equipo.\\n\\n5  fase eliminatoria: fase de la competici\\u00f3n entre 16 equipos, anterior a los cuartos de final, entre los ocho mejores.'\n",
        "\n",
        "# Use the prepare_data function to prepare the text for classification\n",
        "inputs, masks, label = prepare_data([text], ['A1']) # we need to put the label as one of the arguments to the function\n",
        "inputs = inputs.to(device)\n",
        "masks = masks.to(device)\n",
        "outputs = bert_model(inputs, masks)\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-4.6848e-05, -1.0671e+01, -1.0655e+01]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C8M6VW2imWI",
        "outputId": "56ca8ae7-2dea-4da2-a0ee-00f39a59dac9"
      },
      "source": [
        "probabilities, predicted = torch.max(outputs[0].cpu().data,0)\n",
        "print(\"the prediction is: \", ind2lab[predicted.item()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the prediction is:  A1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHztNeaxyE_x"
      },
      "source": [
        "The prediction is correct! Now let's test with a random example from the Internet. This one I took from an article in El País, and it should be classified as B level (or above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxC3iB5_yahS",
        "outputId": "e50bda13-cc98-4080-9163-0f2df5b8b52b"
      },
      "source": [
        "text = \"Un estudio alerta de que hasta el 91% de la sabiduría tribal sobre plantas con potencial farmacológico y terapéutico desaparecerá con la muerte de sus lenguas.\"\n",
        "\n",
        "# Use the prepare_data function to prepare the text for classification\n",
        "inputs, masks, label = prepare_data([text], ['B']) # we need to put the label as one of the arguments to the function\n",
        "inputs = inputs.to(device)\n",
        "masks = masks.to(device)\n",
        "outputs = bert_model(inputs, masks)\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.0738e+01, -1.1960e+01, -2.8133e-05]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZo4kl2H0wBM",
        "outputId": "d31c3070-17da-4c42-8169-fcf1a4e9d47e"
      },
      "source": [
        "probabilities, predicted = torch.max(outputs[0].cpu().data,0)\n",
        "print(\"the prediction is: \", ind2lab[predicted.item()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the prediction is:  B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ak-OERKtkpg"
      },
      "source": [
        "### Cross-Validation and Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8LvRyqjU_7r"
      },
      "source": [
        "The code below can be used for cross-validation via GridSearch. We did not run it because it would take a really long time, and our results were already very good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06SQup8Y2rVm"
      },
      "source": [
        "lr_list = [1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4]\n",
        "max_grad_norms_list = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
        "num_epochs = [10, 20, 30, 40, 50]\n",
        "#chunk_sizes = #from 256 to 510"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwreQWEi3kko"
      },
      "source": [
        "num_epochs = 20\n",
        "def grid_search():\n",
        "\n",
        "  num_trials = len(lr_list) * len(max_grad_norms_list) # make sure that len(lr_list) and len(max_grad_norms_list) are coprime. \n",
        "  for i in range(num_trials):\n",
        "    lr_idx = i % len(lr_list)\n",
        "    norm_idx = i % len(max_grad_norms_list)\n",
        "    lr = lr_list[lr_idx]\n",
        "    max_grad_norm = max_grad_norms_list[norm_idx]\n",
        "\n",
        "    model = Bert_cls(lab2ind, model_path, 768)\n",
        "    model.to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_training_steps)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f'\\ni: {i}, lr: {lr}, max_grad:{max_grad_norm}')\n",
        "    for i in range(epochs):\n",
        "      epoch_loss = train(bert_model, train_dataloader, optimizer, scheduler, criterion)  \n",
        "      train_loss, train_acc, train_f1 = evaluate(bert_model, train_dataloader, criterion)\n",
        "      val_loss, val_acc, val_f1 = evaluate(bert_model, validation_dataloader, criterion)\n",
        "\n",
        "      print(f'epoch: {i}, Train Loss: {epoch_loss:.3f}, Train Acc: {train_acc:.3f}, Train f1: {train_f1:.3f}, Dev Acc: {val_acc:.3f}, Dev f1: {val_f1:.3f}')\n",
        "  \n",
        "    print('\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}