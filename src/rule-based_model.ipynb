{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d145ff1b",
   "metadata": {},
   "source": [
    "# Rule-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a434eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0458ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import json\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8bb67",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db60b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train val and test data\n",
    "with open('../data/train_features.json', 'r') as f:\n",
    "    train_feat = json.load(f)\n",
    "with open('../data/val_features.json', 'r') as f:\n",
    "    val_feat = json.load(f)\n",
    "with open('../data/test_features.json', 'r') as f:\n",
    "    test_feat = json.load(f)\n",
    "    \n",
    "train_feat_df = pd.DataFrame(train_feat)\n",
    "val_feat_df = pd.DataFrame(val_feat)\n",
    "test_feat_df = pd.DataFrame(test_feat)\n",
    "\n",
    "\n",
    "X_train = train_feat_df.drop(['level'], axis=1)\n",
    "X_val = val_feat_df.drop(['level'], axis=1)\n",
    "X_test = test_feat_df.drop(['level'], axis=1)\n",
    "\n",
    "y_train = train_feat_df['level'].tolist()\n",
    "y_val = val_feat_df['level'].tolist()\n",
    "y_test = test_feat_df['level'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf73395",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c58995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_average(feature_name):\n",
    "    '''\n",
    "    Given the name of a feature, return the average value of that feature for A1, A2, and B level texts respectively.\n",
    "    \n",
    "    Input:\n",
    "    feature_name: (str) A key in the feature matrix\n",
    "    \n",
    "    Return:\n",
    "    (None)\n",
    "    '''\n",
    "    feature_name_A1 = []\n",
    "    feature_name_A2 = []\n",
    "    feature_name_B = []\n",
    "    \n",
    "    for i, label in enumerate(train_feat['level']):\n",
    "        if label == 'A1':\n",
    "            feature_name_A1.append(train_feat[feature_name][i])\n",
    "        elif label == 'A2':\n",
    "            feature_name_A2.append(train_feat[feature_name][i])\n",
    "        elif label == 'B':\n",
    "            feature_name_B.append(train_feat[feature_name][i])\n",
    "        else:\n",
    "            print(f'Error at: {i}, label {label}')\n",
    "    \n",
    "    print(f'Average {feature_name} for A1 texts: {sum(feature_name_A1)/len(feature_name_A1)}')\n",
    "    print(f'Average {feature_name} for A2 texts: {sum(feature_name_A2)/len(feature_name_A2)}')\n",
    "    print(f'Average {feature_name} for B texts: {sum(feature_name_B)/len(feature_name_B)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4decbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(feat_dict, threshold_dict):\n",
    "    '''\n",
    "    Given a feature dictionary and thresholds for prediction, return a list of predicted values.\n",
    "    \n",
    "    Input:\n",
    "    feat_dict: (dict) A feature matrix of the format {feature1: [value1, value2, ...], feature2: [value1, value2, ...], ...}\n",
    "    threshold_dict: (dict) A dictionary containing thresholds for the rule-based prediction. The dictionary should be structured as follows:\n",
    "        {feature1: {A1_A2: 0.5, A2_B: 0.5}, feature2: {A1_A2: 0.3, A2_B: 0.3}, ...}, \n",
    "        where A1_A2 points to the threshold that differentiates A1 and A2 level.\n",
    "    \n",
    "    Return:\n",
    "    (list) A list of predictions\n",
    "    '''\n",
    "    preds = []\n",
    "    for i in range(len(feat_dict['preprocessed_text'])):\n",
    "        if feat_dict['proportion_of_A_level_types'][i] > threshold_dict['proportion_of_A_level_types']['A1_A2'] \\\n",
    "        and feat_dict['proportion_of_A_level_tokens'][i] > threshold_dict['proportion_of_A_level_tokens']['A1_A2']:\n",
    "            preds.append('A1')    \n",
    "        elif feat_dict['proportion_of_A_level_types'][i] < threshold_dict['proportion_of_A_level_types']['A2_B'] \\\n",
    "        and feat_dict['proportion_of_A_level_tokens'][i] < threshold_dict['proportion_of_A_level_tokens']['A2_B']:\n",
    "            preds.append('B')\n",
    "        else:\n",
    "            preds.append('A2')\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384bc19",
   "metadata": {},
   "source": [
    "## Proportion of A level types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9e37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average proportion_of_A_level_types for A1 texts: 0.3984681007030331\n",
      "Average proportion_of_A_level_types for A2 texts: 0.30988777298143\n",
      "Average proportion_of_A_level_types for B texts: 0.240087423883735\n"
     ]
    }
   ],
   "source": [
    "get_feature_average('proportion_of_A_level_types')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29de755",
   "metadata": {},
   "source": [
    "## Proportion of A level tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1fcd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average proportion_of_A_level_tokens for A1 texts: 0.4496423698117422\n",
      "Average proportion_of_A_level_tokens for A2 texts: 0.4053670055676591\n",
      "Average proportion_of_A_level_tokens for B texts: 0.3039061349513798\n"
     ]
    }
   ],
   "source": [
    "get_feature_average('proportion_of_A_level_tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c164dce",
   "metadata": {},
   "source": [
    "## Proportion of tenses (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77529546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fut for A1 texts: 0.018207738779754044\n",
      "Average Fut for A2 texts: 0.038297377547088694\n",
      "Average Fut for B texts: 0.03598815179880061\n"
     ]
    }
   ],
   "source": [
    "# future tense\n",
    "get_feature_average('Fut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5dfec2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Past for A1 texts: 0.11515991489032376\n",
      "Average Past for A2 texts: 0.2746258069339504\n",
      "Average Past for B texts: 0.22553401711675003\n"
     ]
    }
   ],
   "source": [
    "# past tense\n",
    "get_feature_average('Past')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66cc8ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Pres for A1 texts: 0.825997669319173\n",
      "Average Pres for A2 texts: 0.5621140348279573\n",
      "Average Pres for B texts: 0.5883038516116565\n"
     ]
    }
   ],
   "source": [
    "# present tense\n",
    "get_feature_average('Pres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3f0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Imp for A1 texts: 0.04063467701074908\n",
      "Average Imp for A2 texts: 0.12496278069100375\n",
      "Average Imp for B texts: 0.14197725816131687\n"
     ]
    }
   ],
   "source": [
    "# imperative tense\n",
    "get_feature_average('Imp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ecca8e",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966f66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try all combinations of thresholds\n",
    "a = [0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39]\n",
    "b = [0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30]\n",
    "c = [0.40, 0.41, 0.42, 0.43, 0.44]\n",
    "d = [0.30, 0.32, 0.34, 0.36, 0.38, 0.40]\n",
    "\n",
    "best_score = 0\n",
    "best_comb = []\n",
    "\n",
    "for a_ in a:\n",
    "    for b_ in b:\n",
    "        for c_ in c:\n",
    "            for d_ in d:\n",
    "                threshold_dict = {'proportion_of_A_level_types': {'A1_A2':a_, 'A2_B':b_}, \n",
    "                                  'proportion_of_A_level_tokens': {'A1_A2':c_, 'A2_B':d_}}\n",
    "                train_preds = predict(train_feat, threshold_dict)\n",
    "                score = accuracy_score(train_preds, y_train)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_comb = [a_, b_, c_, d_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c246852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.622568093385214\n",
      "Best combination of thresholds: [0.3, 0.3, 0.4, 0.4]\n"
     ]
    }
   ],
   "source": [
    "print(f'Best score: {best_score}')\n",
    "print(f'Best combination of thresholds: {best_comb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a32f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_dict = {'proportion_of_A_level_types': {'A1_A2':0.3, 'A2_B':0.3}, \n",
    "                  'proportion_of_A_level_tokens': {'A1_A2':0.4, 'A2_B':0.4}}\n",
    "train_preds = predict(train_feat, threshold_dict)\n",
    "val_preds = predict(val_feat, threshold_dict)\n",
    "test_preds = predict(test_feat, threshold_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "009a5533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.622568093385214\n",
      "Validation accuracy: 0.59375\n",
      "Test accuracy: 0.53125\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy:', accuracy_score(train_preds, y_train))\n",
    "print('Validation accuracy:', accuracy_score(val_preds, y_val))\n",
    "print('Test accuracy:', accuracy_score(test_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df2144",
   "metadata": {},
   "source": [
    "## Save test prediction to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "743f76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_preds) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45bb9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {'test_text':[], 'prediction':[], 'gold':[]}\n",
    "for i in range(len(y_test)):\n",
    "    output_dict['test_text'].append(test_feat['preprocessed_text'][i])\n",
    "    output_dict['prediction'].append(test_preds[i])\n",
    "    output_dict['gold'].append(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5218cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capítulo —¡paren ya de pelearse! —el hombre al...</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¡es con voz de la biblia, o verso de walt whit...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>los cuatro hermanos un zapatero tenía cuatro h...</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una mañana entró un caballero en la tienda de ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>había un viejo que tenía una hija muy hermosa....</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           test_text prediction gold\n",
       "0  capítulo —¡paren ya de pelearse! —el hombre al...         A1   A1\n",
       "1  ¡es con voz de la biblia, o verso de walt whit...          B    B\n",
       "2  los cuatro hermanos un zapatero tenía cuatro h...         A2   A2\n",
       "3  una mañana entró un caballero en la tienda de ...         A1   A1\n",
       "4  había un viejo que tenía una hija muy hermosa....         A1   A1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output_dict).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8adabdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../predictions/rule_test_pred.json\", \"w\", encoding=\"utf-8\") as fout:\n",
    "    json.dump(output_dict, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383296e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
