{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-opinion",
   "metadata": {},
   "source": [
    "Please note that this notebook is to explain and correct the bug present in flesch_score.ipynb. \n",
    "When the function, Fernandez_huerta_score function was implemented earlier, I copied and pasted wrong lines of codes. Therefore, while the distribution graph of the score presented to the partners was not incorrect, the code submitted to the repository was incorrect.\n",
    "\n",
    "I am making an attempt to explain and correct the bug in the previous code in this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grand-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pylabeador\n",
    "from utils import read_corpus\n",
    "from features import feature_pipeline\n",
    "import pylabeador\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-imaging",
   "metadata": {},
   "source": [
    "### Load texts into a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "precious-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading text\n",
    "\n",
    "def file_to_dict_list(filename):\n",
    "    ''' This function takes in a json filename and returns a list of dictionaries.\n",
    "    ------------------------------------------\n",
    "    Argument: \n",
    "       filename: (str) filename of a json file\n",
    "    Returns:\n",
    "        a list of dictionaries where each dictionary contains a paragraph / chapter of a Spanish text\n",
    "    '''\n",
    "    \n",
    "    with open(filename, encoding = 'utf-8') as json_file:\n",
    "        dict_list = json.load(json_file)\n",
    "    \n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-discretion",
   "metadata": {},
   "source": [
    "### For testing, set up directory and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ranking-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = '/Users/eun-youngchristinapark/MDS-CAPSTONE/capstone_FHIS/corpus/'\n",
    "file_list = os.listdir(text_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bizarre-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = read_corpus(text_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cooked-group",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary list type: <class 'list'> \n",
      "\n",
      "length of the dictionary list: 56 \n",
      "\n",
      "type of dictionary list element: <class 'dict'> \n",
      "\n",
      "keys in the dictionary list element: dict_keys(['source', 'author', 'title', 'level', 'content']) \n",
      "\n",
      "source of the first element in the list: https://www.gutenberg.org/files/15353/15353-h/15353-h.htm \n",
      "\n",
      "author: ERWIN W. ROESSLER, PH.D. \n",
      "\n",
      "title: A First Spanish Reader \n",
      "\n",
      "level: A1 \n",
      "\n",
      "content: 1. LA ESCUELA\n",
      "Voy a la escuela. Voy a la escuela el lunes,\n",
      "el martes, el miércoles, el jueves y el viernes.\n",
      "El sábado y el domingo no voy a la escuela.\n",
      "El sábado y el domingo estoy en casa. Soy un\n",
      "discípulo y estoy en la escuela. El discípulo\n",
      "aprende. Aprendo la aritmética, a leer y a\n",
      "escribir. Vd. aprende el español. Todos nosotros\n",
      "aprendemos diligentemente. Algunos discípulos\n",
      "no son diligentes. Algunos son perezosos.\n",
      "El maestro elogia a los discípulos diligentes y a\n",
      "los discípulos obedientes. Él no elogia a los\n",
      "alumnos perezosos.\n",
      "El maestro enseña. Mi maestro enseña el\n",
      "español. Este maestro enseña las matemáticas\n",
      "y aquel maestro el inglés. El señor Blanco enseña\n",
      "la biología y la química. La señorita\n",
      "Herrera enseña la geografía y la historia. ¿Qué\n",
      "aprende Vd. en la escuela? Aprendo el español,\n",
      "el francés, el álgebra, la biología y la estenografía.\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_spanish_reader_corpus = file_list[-3]\n",
    "first_spanish = file_to_dict_list(text_dir + first_spanish_reader_corpus)\n",
    "\n",
    "print(f'dictionary list type: {type(first_spanish)}', '\\n')\n",
    "print(f'length of the dictionary list: {len(first_spanish)}', '\\n')\n",
    "print(f'type of dictionary list element: {type(first_spanish[0])}', '\\n')\n",
    "print(f'keys in the dictionary list element: {first_spanish[0].keys()}', '\\n')\n",
    "print(f\"source of the first element in the list: {first_spanish[0]['source']}\", '\\n')\n",
    "print(f\"author: {first_spanish[0]['author']}\", '\\n')\n",
    "print(f\"title: {first_spanish[0]['title']}\", '\\n')\n",
    "print(f\"level: {first_spanish[0]['level']}\", '\\n')\n",
    "print(f\"content: {first_spanish[0]['content']}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-mistake",
   "metadata": {},
   "source": [
    "### Fernandez-Huerta Score calculation: Correction made\n",
    "\n",
    "The equivalent readability measure of Flesch score for Spanish is Fernandez-Huerta score.\n",
    "Please see the original paper (Spanish) *Medidas sencillas de lecturabilidad. Consigna, 214, 29–32,* and\n",
    "the mention of this metric in [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5831059/#:~:text=The%20Fernandez%2DHuerta%20Formula%20(Fern%C3%A1ndez,formulae%20(Flesch%2C%201948).&text=The%20output%20is%20an%20index,representing%20a%20more%20difficult%20text).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "silent-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove titles\n",
    "regex = r'[0-9]+\\.[^\\n]+\\n'\n",
    "def remove_titles(text):\n",
    "    \n",
    "    for match in re.finditer(regex, text):\n",
    "        match_span = match.span()\n",
    "        text_bf = text[:match_span[0]]\n",
    "        text_af = text[match_span[1]:]\n",
    "        text = text_bf + text_af\n",
    "    \n",
    "    return text\n",
    "\n",
    "def fernandez_huerta_score(text):\n",
    "    '''This function calculates flesch_score of the given text. \n",
    "    \n",
    "       Note: Please note that the previous version of this function had a bug. We found this bug late in the project.\n",
    "       We are making corrections in this notebook for the future students. \n",
    "       \n",
    "       Please see the comments below for where the bugs are present in the previous code and how they are corrected in this version. \n",
    "    ---------------------------------------\n",
    "    Argument: \n",
    "        text (str): a string which is a piece of Spanish text\n",
    "    Returns:\n",
    "        fh score (float)\n",
    "        num_alpha_tokens: The number of tokens used in the calculation of the score (does not include numeric, puncutation marks)\n",
    "    '''\n",
    "    text = remove_titles(text)\n",
    "    tp = feature_pipeline(text, full_spacy=True)\n",
    "    tp.get_sentences(text)\n",
    "    tp.get_tokens(text)\n",
    "    \n",
    "    num_sents = len(tp.sentences)\n",
    "    num_tokens = sum(len(tk) for tk in tp.tokens)\n",
    "    \n",
    "    \n",
    "    ############################ The code below (num_alpha_tokens = ...) in flesch_score.ipynb is incorrect. ###################################################################################\n",
    "    #num_alpha_tokens = len([tk for tkl in tp.tokens for tk in tkl if any(t.isalpha() for t in tk)])      ### count as tokens only if the token contains at least one letter. ex) 'Vd.'' is a token. \n",
    "    \n",
    "    ###### The correct code is shown below ######\n",
    "    num_alpha_tokens = len([''.join([t for t in tkl]) for tkl in tp.tokens if any(t.isalpha() for t in [t for t in tkl])]) ####################################################################\n",
    "    \n",
    "    if text == '' or num_alpha_tokens == 0 or num_sents == 0:           ### if text contains nothing, \n",
    "        return 206, num_tokens                                               ###    set the score as very very easy to read \n",
    "    \n",
    "    tokens = tp.tokens\n",
    "    num_syl = 0\n",
    "    \n",
    "    ########################### The for loop below is incorrect: This is the wrong code in flesch_score.ipynb ###################################\n",
    "    #for tl in tokens:\n",
    "    #    for token in tl:\n",
    "    #        if any(t.isalpha() for t in token):                          ### if the token contains at least one letter\n",
    "    #            try: \n",
    "    #                token_ = ''.join([t for t in token if t.isalpha()])      ###     get rid of non-alphabets in the token\n",
    "    #                num_syl += len(pylabeador.syllabify(token_))             ###     and get syllables \n",
    "    #            except:\n",
    "    #                num_alpha_tokens -= 1                                ### There are alphabets such as ª which cannot be processed\n",
    "                    \n",
    "    ########################### The for loop below is correct #####################################################################################\n",
    "    for tl in tokens:\n",
    "        if any(t.isalpha() for t in tl):                          ### if the token contains at least one letter\n",
    "            try: \n",
    "                token_ = ''.join([t for t in tl if t.isalpha()])      ###     get rid of non-alphabets in the token\n",
    "                num_syl += len(pylabeador.syllabify(token_))             ###     and get syllables \n",
    "            except:\n",
    "                num_alpha_tokens -= 1                                ### There are alphabets such as ª which cannot be processed\n",
    "    \n",
    "    \n",
    "    # see https://support.rankmath.com/ticket/flesch-readability-works-for-other-languages/ and \n",
    "    #     https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5831059/#:~:text=The%20Fernandez%2DHuerta%20Formula%20(Fern%C3%A1ndez,formulae%20(Flesch%2C%201948).&text=The%20output%20is%20an%20index,representing%20a%20more%20difficult%20text.\n",
    "    # for Spanish flesch score. \n",
    "    \n",
    "    fh_score = 206.835 - 102 * (num_sents/num_alpha_tokens) - 60 * (num_syl / num_alpha_tokens)    # use num_alpha_tokens instead of num_tokens \n",
    "    #fh_score = 206.835 - 102 * (num_sents/num_tokens) - 60 * (num_syl / num_tokens)\n",
    "    \n",
    "    return fh_score, num_alpha_tokens#, num_sents, num_syl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-insulin",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-disclosure",
   "metadata": {},
   "source": [
    "#### 1. Edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "studied-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fernandez_huerta_score('')[0] == 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surrounded-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fernandez_huerta_score('?')[0] == 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "special-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fernandez_huerta_score('1.')[0] == 206"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-survivor",
   "metadata": {},
   "source": [
    "#### 2. Brute-force calculations vs. Fernandez_huerta_score implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alternative-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Voy']\n",
      "['a']\n",
      "['la']\n",
      "['es', 'cue', 'la']\n",
      "['el']\n",
      "['lu', 'nes']\n",
      "['el']\n",
      "['mar', 'tes']\n",
      "['el']\n",
      "['miér', 'co', 'les']\n",
      "['el']\n",
      "['jue', 'ves']\n",
      "['y']\n",
      "['el']\n",
      "['vier', 'nes']\n",
      "108.035\n"
     ]
    }
   ],
   "source": [
    "text = 'Voy a la escuela el lunes, el martes, el miércoles, el jueves y el viernes.'\n",
    "text = [c for c in text if c not in {'?',',','.','0','1','2','3','4','5','6','7','8','9'}]\n",
    "text = ''.join(text)\n",
    "tokens = text.split()\n",
    "num_syl = 0\n",
    "for token in tokens:\n",
    "    syl_list = pylabeador.syllabify(token)\n",
    "    print(syl_list)\n",
    "    num_syl += len(syl_list)\n",
    "num_sents = 1\n",
    "num_tokens = len(tokens)\n",
    "manual_score = 206.835 - 102 * (num_sents/num_tokens) - 60 * (num_syl / num_tokens)\n",
    "print(manual_score)\n",
    "assert fernandez_huerta_score(text)[0] == manual_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "instrumental-melissa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Es', 'te']\n",
      "['ma', 'es', 'tro']\n",
      "['en', 'se', 'ña']\n",
      "['las']\n",
      "['ma', 'te', 'má', 'ti', 'cas']\n",
      "['y']\n",
      "['a', 'quel']\n",
      "['ma', 'es', 'tro']\n",
      "['el']\n",
      "['in', 'glés']\n",
      "58.63500000000002\n"
     ]
    }
   ],
   "source": [
    "text = 'Este maestro enseña las matemáticas y aquel maestro el inglés.'\n",
    "text = [c for c in text if c not in {'?',',','.','0','1','2','3','4','5','6','7','8','9'}]\n",
    "text = ''.join(text)\n",
    "tokens = text.split()\n",
    "num_syl = 0\n",
    "for token in tokens:\n",
    "    syl_list = pylabeador.syllabify(token)\n",
    "    print(syl_list)\n",
    "    num_syl += len(syl_list)\n",
    "num_sents = 1\n",
    "num_tokens = len(tokens)\n",
    "manual_score = 206.835 - 102 * (num_sents/num_tokens) - 60 * (num_syl / num_tokens)\n",
    "print(manual_score)\n",
    "assert fernandez_huerta_score(text)[0] == manual_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "connected-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vd']\n",
      "['a', 'pren', 'de']\n",
      "['el']\n",
      "['es', 'pa', 'ñol']\n",
      "['To', 'dos']\n",
      "['no', 'so', 'tros']\n",
      "['a', 'pren', 'de', 'mos']\n",
      "['di', 'li', 'gen', 'te', 'men', 'te']\n",
      "['Al', 'gu', 'nos']\n",
      "['dis', 'cí', 'pu', 'los']\n",
      "['no']\n",
      "['son']\n",
      "['di', 'li', 'gen', 'tes']\n",
      "['Al', 'gu', 'nos']\n",
      "['son']\n",
      "['pe', 're', 'zo', 'sos']\n",
      "9.960000000000008\n"
     ]
    }
   ],
   "source": [
    "text_orig = 'Vd. aprende el español. Todos nosotros aprendemos diligentemente. Algunos discípulos no son diligentes. Algunos son perezosos.'\n",
    "text = [c for c in text_orig if c not in {'?',',','.','0','1','2','3','4','5','6','7','8','9'}]\n",
    "text = ''.join(text)\n",
    "tokens = text.split()\n",
    "num_syl = 0\n",
    "for token in tokens:\n",
    "    syl_list = pylabeador.syllabify(token)\n",
    "    print(syl_list)\n",
    "    num_syl += len(syl_list)\n",
    "num_sents = 5   # the correct number of sentences is 4 but preprocessing does not recognize Vd. properly \n",
    "num_tokens = len(tokens)\n",
    "manual_score = 206.835 - 102 * (num_sents/num_tokens) - 60 * (num_syl / num_tokens)\n",
    "print(manual_score)\n",
    "assert fernandez_huerta_score(text_orig)[0] == manual_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
