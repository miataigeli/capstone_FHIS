{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silver-thomas",
   "metadata": {},
   "source": [
    "## Tutorial for the Intended Usage of the Feature Extraction Pipeline API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-graph",
   "metadata": {},
   "source": [
    "##### Please ensure that you have spaCy and the \"es_core_news_md\" pipeline installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dirty-secondary",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monthly-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from utils import read_corpus\n",
    "from features import feature_pipeline\n",
    "\n",
    "# Setup pretty printer\n",
    "p = pprint.PrettyPrinter(indent=4, width=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-allocation",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook is intended to illustrate and explain the main workflows possible when using the feature extraction pipeline API for computing statistical/numerical features from a raw text in our collected corpus of Spanish texts. This notebook should be treated as a secondary resource for understanding the API, the primary resource being the file `features.py` containing the source code.\n",
    "\n",
    "Let's begin by broadly describing the stages of the feature extraction pipeline. To calculate any statistical feature from a raw, unprocessed text, the following steps must occur in sequence:\n",
    "1. Initialize the pipeline object\n",
    "2. Pre-process (clean up) the text to remove stray whitespaces, numerals, characters, etc.\n",
    "3. Extract fundamental attributes of the text (eg., tokens, POS tags, lemmas, etc.) using spaCy\n",
    "4. Use the extracted attributes to calculate statistical features of the text (eg., total number of tokens, type-token ratio, pronoun density, etc.)\n",
    "\n",
    "It is not possible to calculate a statistical feature without first extracting the fundamental attributes necessary for calculating that feature. In other words, we cannot reach stage 4 without completing stages 1, 2 and 3. However, the API is written with some shortcuts in place, allowing us to almost never need to explicitly call the `.preprocess()` method in our code. Depending on our usage we can even sometimes skip writing the spaCy step. It is most crucial to remember that the unprocessed text must be passed as an argument at some stage within the pipeline, but it is quite flexible as to which stage that should be.\n",
    "\n",
    "Through this tutorial we will understand these shortcuts and learn how to best apply them in workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-metallic",
   "metadata": {},
   "source": [
    "### Corpus Reading\n",
    "Let's begin by loading the corpus and seeing a broad view of what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sorted-language",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1: 94\n",
      "A2: 62\n",
      "B: 152\n",
      "B2: 95\n"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus()\n",
    "\n",
    "for k, v in corpus.items():\n",
    "    print(f\"{k}: {len(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-bookmark",
   "metadata": {},
   "source": [
    "Let's pick a text from the corpus for the purposes of this demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entitled-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16. LA PRIMAVERA\n",
      "La primavera principia el veintiuno de marzo\n",
      "y dura hasta el veintiuno de junio. La primavera\n",
      "es muy agradable y hermosa. Las flores\n",
      "crecen. Los árboles y los campos se cubren de\n",
      "verdura y los pájaros cantan en ellos. Todos\n",
      "los hombres, las mujeres y los niños están\n",
      "alegres.\n",
      "Algunas veces hace frío en abril y aún en\n",
      "mayo. Algunas veces, pero no frecuentemente,\n",
      "hay nieve y hielo en abril, y entonces muchas\n",
      "flores y plantas se mueren.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unprocessed_text = corpus[\"A1\"][81][\"content\"]\n",
    "print(unprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-stereo",
   "metadata": {},
   "source": [
    "We can see that this piece of text is formatted somewhat \"irregularly\". It is a poem, so it has line breaks in the middle of grammatical sentences. It also has a title at the top, which is not a necessary component of the content of the text. In order to derive syntactic attributes like POS tags and dependency parses we will need to convert this text into a more standard form that can be interpreted by spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-bracelet",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "Let's create a pipeline for cleaning up this text and extracting important attributes and features from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legal-baking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capítulo hoy es sábado. el día tan esperado de la final. ha venido mucho público a ver el partido. laura y mónica saludan con la mano a su tutor roberto, a ángela y a carmen que están unas gradas más atrás con otros profesores de otros colegios. guillermo hoy está convocado por el entrenador, como suplente. laura y mónica están en la entrada de los vestuarios dando ánimos a sus compañeros. —¡guille! —dice mónica a su amigo —¡a ver si marcas un gol! —no sé si jugaré. estoy de suplente. —yo creo que sí que jugarás... —dice martín. —bueno, tenemos que ir a cambiarnos —dice sergio. —oye, laura —dice mónica—. ¿aquella chica no es...? —¿quién? —allá... —no, no la veo. —ahora no se ve... quizás me he equivocado. martín mira hacia donde señalan sus amigas. él sí la ve. o no. no, no puede ser ella. martín se pone nervioso. el árbitro señala el principio del partido. el equipo del peralta tiene suerte y a los pocos minutos marca un gol. al equipo de barcelona le cuesta organizar su juego. además, un defensa se lesiona. guillermo sale a jugar. � estar convocado: llamar a una persona para que participe en algo. lesionarse: hacerse daño practicando un deporte. poco a poco el equipo de barcelona empieza a recuperarse. por suerte el equipo contrario también falla. gustavo, el número de los rojos juega muy duro y el árbitro le saca tarjeta amarilla. de repente martín vuelve a ver a la chica. «¿es ella? no, no es ella. ¿o sí?» en aquel momento la pelota le pasa por el lado y él no la ve. el entrenador le grita. martín corre detrás de la pelota y se la pasa a sergio, pero mira otra vez hacia la chica. ahora está más cerca de ella. sí, es mita, pero lleva el pelo corto y desordenado. tiene una expresión muy rara en la mirada. algunas imágenes empiezan a pasar por la mente de martín. recuerda a la chica la primera vez que la vio, con su gorro rojo. y después en la playa. recuerda a la chica en el partido de la semifinal. había jugadores de su colegio, el peralta ramos, viendo el partido, pero ella no estaba con ellos. estaba con mónica y laura. y luego en el bar, la chica parecía tan tranquila y de repente, se puso tan nerviosa. ¿por qué? recuerda que él saludó a chicos de otros equipos que entraban en el bar. también los del peralta ramos. recuerda las palabras del coronel: «un chico le hacía bullying». recuerda las palabras de la chica: «ahora no voy al cole». —martín, ¿qué te pasa? —grita sergio al pasar por su lado. un jugador contrario avanza con la pelota. martín le cierra el paso. pero vuelve a mirar al público. la chica ha abierto su bolso y mete la mano dentro. —martín, tío, ¿qué haces? —grita raúl sorprendido. él recuerda al padre de la chica, en su casa. estaba muy preocupado. buscaba algo... un militar, ¿qué puede buscar un militar? en este momento la chica salta al campo. martín ve que saca algo del bolso. «un militar»... � tarjeta amarilla: esta tarjeta significa un primer aviso, al siguiente tiene que abandonar el terreno de juego. tío: (coloquial) chico, hombre. —¡ostras, no! —exclama martín, comprendiendo todo de repente. empieza a correr. la chica se mueve entre los jugadores. lleva en la mano una pistola. se acerca a gustavo. este se vuelve y de repente la ve. retrocede asustado. —¡mita! ¡no! —grita martín. martín se acerca corriendo. la chica apunta hacia gustavo, pero martín le coge la mano y le dice: —mita ¿qué haces? —¡martín! no está cargada... solo quiero que me deje tranquila. los entrenadores de los dos equipos sacan a la chica del campo. el partido se para. mita gira la cabeza y dice con voz triste: —solo quiero que me deje tranquila... ahora el partido está parado. el público no entiende bien lo que ha visto. pero martín sí lo entiende todo: gustavo es el chico que hacía bullying a mita hasta volverla loca. y ahora ella quería asustarlo. martín mira a gustavo que está pálido. este ve la mirada de rabia de martín y se da cuenta de que lo sabe todo. —bueno, no sé si vamos a continuar el partido —dice gómez después de reunir a sus jugadores. —¿qué ha pasado? —pregunta raúl. en aquel momento se acercan el árbitro y el entrenador del otro equipo. —¿qué hacemos? —pregunta el árbitro. —¡continuar, vamos a continuar! —dice martín. el entrenador del equipo argentino mira a sus jugadores. ellos no dicen nada. —¿qué pasa? —le pregunta guille a martín. —¡gustavo es el que le está haciendo bullying a mita! el árbitro habla con los entrenadores de los dos equipos y deciden continuar el partido. tiene la pelota el equipo de barcelona. sergio organiza el ataque. pasa la pelota a martín que juega entre los defensas contrarios. un defensa lo empuja y cae al suelo. el árbitro señala falta. los jugadores juegan cada vez más fuerte y el árbitro tiene que parar muchas veces el partido. en la segunda parte, gustavo recupera la pelota y llega delante del portero contrario que sale a pararlo. gustavo lo regatea y, solo, delante de la portería, chuta. —¡oh, no! —exclama mónica. ella y laura siguen el partido nerviosas desde las gradas. pero guillermo llega corriendo y salva el gol. —¡uy! —exclama el público. ahora guillermo marca de cerca a gustavo. no le deja jugar. gustavo está enfadado. en un momento, empuja a raúl, que cae al suelo en medio de varios jugadores. gustavo avanza hacia la portería contraria, pero guillermo llega corriendo y le da una patada. gustavo cae al suelo. — ¡vamos, levantate! —dice el árbitro que no ha visto la patada. el partido continúa. ahora martín y sus compañeros dominan el partido. llegan con frecuencia a la portería contraria. martín chuta y la pelota toca al palo de la portería. —¡¡uuuy!! —grita el público. falta poco para el final del partido. continúan a . martín y gustavo corren detrás de la pelota. están en el medio del terreno de juego. martín llega primero a la pelota, pero gustavo choca con él y los dos caen al suelo. martín se levanta y recupera la pelota. la pasa a guillermo. este la pasa a sergio que corre por la banda. martín avanza por el centro entre los jugadores contrarios y llega al área. marcar (de cerca): en el fútbol y algunos otros deportes, situarse cerca de un contrario para dificultar su juego. banda: parte más exterior del campo de fútbol. sergio centra y martín chuta a puerta. —¡¡¡goool!!! —gritan laura y mónica. el público argentino ve que su equipo va a perder el partido. los seguidores del instituto gaudí empiezan a animar: «¡gaudí! ¡gaudí!» los jugadores del equipo de barcelona se abrazan, contentos. poco después, el árbitro señala el final del partido. los jugadores de ambos equipos se saludan deportivamente. martín no saluda a gustavo y se va a hablar con sus amigas. el entrenador del equipo argentino se dirige a gustavo, que está pálido y enfadado: —gustavo —le dice serio— vos y yo vamos a hablar. y no de fútbol. se oye una voz por los altavoces: «ya ha acabado la final del campeonato internacional entre colegios de habla hispana. el ganador de la gran final ha sido el instituto gaudí de barcelona, españa». el público aplaude. mónica y laura de pie sobre las gradas gritan: «gaudí, gaudí». los profesores de los chicos ríen y aplauden contentos. los jugadores del equipo español se acercan a la tribuna. allí el alcalde de mar del plata les entrega el trofeo. hay una cámara de la televisión filmando. centrar: en fútbol, lanzar el balón desde un lado del terreno hacia la parte central próxima a la portería contraria. saludarse deportivamente: darse la mano cuando acaba un partido, costumbre entre deportistas. tribuna: lugar preferente en un campo de deporte. trofeo: objeto que se entrega al ganador de un campeonato. martín se acerca a gómez: —¿y la chica? —han avisado a su padre. —se la llevaron en una ambulancia, ha tenido una crisis nerviosa —añade el entrenador del otro equipo que se ha acercado a felicitarles. martín está muy preocupado. —se pondrá bien —lo anima mónica. —¿tú crees? —dice martín. —martín, ya verás que sí. ¿sabes?, gustavo se ha llevado un buen susto. ¿has visto lo pálido que estaba? —sí, es verdad. —¡y vaya patada que le ha dado guille! —añade sergio.\n"
     ]
    }
   ],
   "source": [
    "# This step passes the un-processed text to the pipeline and automatically cleans it up using the .preprocess() method\n",
    "pipe = feature_pipeline(unprocessed_text)\n",
    "print(pipe.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-finance",
   "metadata": {},
   "source": [
    "The text looks much more standardized now, which makes it easier for downstream functions to extract things from it in a consistent manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-individual",
   "metadata": {},
   "source": [
    "In the above cell we only called the pipeline object constructor but it automatically gave us a cleaned text. That is because the constructor already contains a call for the `.preprocess()` method if a text has been supplied to the object. This behaviour is functionally equivalent to the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defensive-ecuador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la primavera la primavera principia el veintiuno de marzo y dura hasta el veintiuno de junio. la primavera es muy agradable y hermosa. las flores crecen. los árboles y los campos se cubren de verdura y los pájaros cantan en ellos. todos los hombres, las mujeres y los niños están alegres. algunas veces hace frío en abril y aún en mayo. algunas veces, pero no frecuentemente, hay nieve y hielo en abril, y entonces muchas flores y plantas se mueren.\n"
     ]
    }
   ],
   "source": [
    "pipe = feature_pipeline()\n",
    "cleaned_text = pipe.preprocess(unprocessed_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-freeze",
   "metadata": {},
   "source": [
    "\\\n",
    "As a rule of thumb, it is easiest to pass the unprocessed text to the pipeline at initialization, since the constructor has the effect of resetting all of the attributes to empty lists, giving the pipeline a blank slate for processing a new text that may come its way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-above",
   "metadata": {},
   "source": [
    "### Extracting Attributes of the Text using SpaCy\n",
    "Now that we have cleaned up the text into a standard form, spaCy will be able to derive some fundamental syntactic attributes from the text. Some attributes of the text that we might be interested in are the sentences, tokens and POS tags. We can try accessing them, but they won't be accessible at this stage since by default the pipeline constructor does not execute any of the spaCy methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minor-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# The below calls to access class attributes will just return empty lists since those items have not been extracted yet\n",
    "print(pipe.sentences)\n",
    "print(pipe.tokens)\n",
    "print(pipe.pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-realtor",
   "metadata": {},
   "source": [
    "These attributes must be extracted from the text using spaCy's Spanish pipeline. It is recommended that we generate the attribute lists as and when we need them, since extracting all of the attributes for every text can be a bit slow (although the pre-processing of the text is typically the slowest step in the pipeline). We can extract some attributes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunset-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'la primavera la primavera principia el veintiuno de marzo y dura hasta el veintiuno de junio.',\n",
      "    'la primavera es muy agradable y hermosa.',\n",
      "    'las flores crecen.',\n",
      "    'los árboles y los campos se cubren de verdura y los pájaros cantan en ellos.',\n",
      "    'todos los hombres, las mujeres y los niños están alegres.',\n",
      "    'algunas veces hace frío en abril y aún en mayo.',\n",
      "    'algunas veces, pero no frecuentemente, hay nieve y hielo en abril, y entonces muchas flores y plantas se mueren.']\n",
      "\n",
      "['la', 'primavera', 'la', 'primavera', 'principia', 'el', 'veintiuno', 'de', 'marzo', 'y', 'dura', 'hasta', 'el', 'veintiuno', 'de', 'junio', '.', 'la', 'primavera', 'es', 'muy', 'agradable', 'y', 'hermosa', '.', 'las', 'flores', 'crecen', '.', 'los', 'árboles', 'y', 'los', 'campos', 'se', 'cubren', 'de', 'verdura', 'y', 'los', 'pájaros', 'cantan', 'en', 'ellos', '.', 'todos', 'los', 'hombres', ',', 'las', 'mujeres', 'y', 'los', 'niños', 'están', 'alegres', '.', 'algunas', 'veces', 'hace', 'frío', 'en', 'abril', 'y', 'aún', 'en', 'mayo', '.', 'algunas', 'veces', ',', 'pero', 'no', 'frecuentemente', ',', 'hay', 'nieve', 'y', 'hielo', 'en', 'abril', ',', 'y', 'entonces', 'muchas', 'flores', 'y', 'plantas', 'se', 'mueren', '.']\n"
     ]
    }
   ],
   "source": [
    "pipe.get_sentences()  # populates the pipe.sentences attribute\n",
    "pipe.get_tokens()  # populates the pipe.tokens attribute\n",
    "\n",
    "# Print out the attributes that were populated\n",
    "p.pprint(pipe.sentences)\n",
    "print()\n",
    "print(pipe.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-dimension",
   "metadata": {},
   "source": [
    "\\\n",
    "Calling the methods above will populate the respective attributes with lists, but they also return the lists as outputs. We can assign the output to a variable and access it that way as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flexible-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['DET', 'NOUN', 'DET', 'NOUN', 'ADJ', 'DET', 'NUM', 'ADP', 'INTJ', 'CCONJ', 'ADJ', 'ADP', 'DET', 'NUM', 'ADP', 'INTJ', 'PUNCT', 'DET', 'NOUN', 'AUX', 'ADV', 'ADJ', 'CCONJ', 'ADJ', 'PUNCT', 'DET', 'NOUN', 'AUX', 'PUNCT', 'DET', 'NOUN', 'CCONJ', 'DET', 'NOUN', 'PRON', 'AUX', 'ADP', 'NOUN', 'CCONJ', 'DET', 'NOUN', 'AUX', 'ADP', 'PRON', 'PUNCT', 'DET', 'DET', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'CCONJ', 'DET', 'NOUN', 'VERB', 'ADJ', 'PUNCT', 'DET', 'NOUN', 'VERB', 'NOUN', 'ADP', 'NOUN', 'CCONJ', 'ADV', 'ADP', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'PUNCT', 'CCONJ', 'ADV', 'ADV', 'PUNCT', 'AUX', 'NOUN', 'CCONJ', 'NOUN', 'ADP', 'NOUN', 'PUNCT', 'CCONJ', 'ADV', 'DET', 'NOUN', 'CCONJ', 'NOUN', 'PRON', 'AUX', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "tags = pipe.get_pos_tags()\n",
    "print(tags == pipe.pos_tags)  # check if they are the same\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-comedy",
   "metadata": {},
   "source": [
    "Putting it all together, let's create a new pipeline object and give it the text to automatically pre-process. We can then just call a `.get_*` method to access the attribute using spaCy, completely eliminating the explicit writing of the pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-balloon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la primavera', 'la primavera', 'la primavera', 'las flores', 'los árboles', 'los campos', 'se', 'verdura', 'los pájaros', 'ellos', 'los hombres', 'las mujeres', 'los niños', 'algunas veces', 'frío', 'abril', 'mayo', 'algunas veces', 'nieve', 'hielo', 'abril', 'muchas flores', 'plantas', 'se']\n"
     ]
    }
   ],
   "source": [
    "pipe = feature_pipeline(unprocessed_text)\n",
    "print(pipe.get_noun_chunks())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-mainland",
   "metadata": {},
   "source": [
    "Alternatively, we could also create a blank pipeline object and pass in the text through the `.get_*` method. This is functionally the same as the above. The only difference is that the text pre-processing will occur at the spaCy stage instead of the constructor stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electoral-jimmy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la primavera', 'la primavera', 'la primavera', 'las flores', 'los árboles', 'los campos', 'se', 'verdura', 'los pájaros', 'ellos', 'los hombres', 'las mujeres', 'los niños', 'algunas veces', 'frío', 'abril', 'mayo', 'algunas veces', 'nieve', 'hielo', 'abril', 'muchas flores', 'plantas', 'se']\n"
     ]
    }
   ],
   "source": [
    "pipe = feature_pipeline()\n",
    "print(pipe.get_noun_chunks(unprocessed_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-forum",
   "metadata": {},
   "source": [
    "\\\n",
    "Here is a list of all of the spaCy features supported by our pipeline so far:\n",
    "* sentences: \\\n",
    "    extraction function - `pipe.get_sentences()`, \\\n",
    "    attribute - `pipe.sentences`\n",
    "* tokens: \\\n",
    "    extraction function - `pipe.get_tokens()`, \\\n",
    "    attribute - `pipe.tokens`\n",
    "* lemmas: \\\n",
    "    extraction function - `pipe.get_lemmas()`, attribute - `pipe.lemmas`\n",
    "* POS tags: \\\n",
    "    extraction function - `pipe.get_pos_tags()`, \\\n",
    "    attribute - `pipe.pos_tags`\n",
    "* morphology tags: \\\n",
    "    extraction function - `pipe.get_morphology()`, \\\n",
    "    attribute - `pipe.morphs`\n",
    "* dependency parses: \\\n",
    "    extraction function - `pipe.get_dependency_parses()`, \\\n",
    "    attribute - `pipe.parses`\n",
    "* noun phrase chunks: \\\n",
    "    extraction function - `pipe.get_noun_chunks()`, \\\n",
    "    attribute - `pipe.noun_chunks`\n",
    "\n",
    "What if we want to extract all of the spaCy features in one go, instead of calling each of the `.get_*` methods one by one? We can do that by calling the method `.full_spacy()` which will extract all of these features, OR we could initialize the pipeline object with the flag `full_spacy=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "urban-petroleum",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la primavera la primavera principia el veintiuno de marzo y dura hasta el veintiuno de junio. la primavera es muy agradable y hermosa. las flores crecen. los árboles y los campos se cubren de verdura y los pájaros cantan en ellos. todos los hombres, las mujeres y los niños están alegres. algunas veces hace frío en abril y aún en mayo. algunas veces, pero no frecuentemente, hay nieve y hielo en abril, y entonces muchas flores y plantas se mueren.\n",
      "\n",
      "['det', 'iobj', 'det', 'ROOT', 'amod', 'det', 'nsubj', 'case', 'compound', 'cc', 'conj', 'case', 'det', 'obl', 'case', 'compound', 'punct', 'det', 'nsubj', 'cop', 'advmod', 'ROOT', 'cc', 'conj', 'punct', 'det', 'nsubj', 'ROOT', 'punct', 'det', 'nsubj', 'cc', 'det', 'nsubj', 'obj', 'ROOT', 'case', 'obj', 'cc', 'det', 'nsubj', 'conj', 'case', 'obl', 'punct', 'det', 'det', 'nsubj', 'punct', 'det', 'appos', 'cc', 'det', 'conj', 'cop', 'ROOT', 'punct', 'det', 'obl', 'ROOT', 'obj', 'case', 'obl', 'cc', 'conj', 'case', 'nmod', 'punct', 'det', 'obl', 'punct', 'cc', 'advmod', 'advmod', 'punct', 'ROOT', 'obj', 'cc', 'conj', 'case', 'obl', 'punct', 'cc', 'advmod', 'det', 'nsubj', 'cc', 'conj', 'obj', 'conj', 'punct']\n"
     ]
    }
   ],
   "source": [
    "pipe = feature_pipeline(unprocessed_text, full_spacy=True)\n",
    "# Equivalent to:\n",
    "# pipe = feature_pipeline()\n",
    "# pipe.full_spacy(unprocessed_text)  # does not return any outputs, saves directly to attributes\n",
    "\n",
    "# All of the following items will automatically be extracted as part of the spaCy pipeline:\n",
    "print(pipe.text)\n",
    "print()\n",
    "print(pipe.parses)\n",
    "\n",
    "# Commented out for brevity\n",
    "# p.pprint(pipe.sentences)\n",
    "# print(pipe.tokens)\n",
    "# print(pipe.lemmas)\n",
    "# print(pipe.pos_tags)\n",
    "# print(pipe.morphs)\n",
    "# print(pipe.noun_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-kenya",
   "metadata": {},
   "source": [
    "### Numerical/Statistical Feature Extraction\n",
    "The most important aspect of the feature extraction pipeline is the ability to derive statistical/numerical features from the text given to it. For a comprehensive guide of all of the features that this pipeline is capable of computing please see the project report (TODO: LINK TO PROJECT REPORT). \\\n",
    "\\\n",
    "Using the pipeline that we created and the attributes that we extracted in the previous cell, here is how we can derive some features from a text using the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "planned-asthma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "0.12345679012345678\n",
      "86.16\n",
      "21.285714285714285\n"
     ]
    }
   ],
   "source": [
    "num_tokens = pipe.num_tokens()  # internally accesses pipe.tokens\n",
    "log_op_density = pipe.logical_operators()  # internally accesses pipe.tokens\n",
    "fh_score, syls_per_sent = pipe.fernandez_huerta_score()  # internally accesses pipe.tokens and pipe.sentences\n",
    "\n",
    "print(num_tokens)\n",
    "print(log_op_density)\n",
    "print(fh_score)\n",
    "print(syls_per_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-today",
   "metadata": {},
   "source": [
    "It is important to note that any of the statistical feature functions can be called directly without needing to run any of the spaCy extractors first. As long as a feature pipeline object has been created, calling any of the feature functions will automatically extract the spaCy features necessary for computing the desired statistical feature. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overhead-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "0.12345679012345678\n",
      "86.16\n",
      "21.285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Explicitly specifying full_spacy=False for demonstration purposes (default behaviour)\n",
    "pipe = feature_pipeline(unprocessed_text, full_spacy=False)\n",
    "# The above step simply cleans up the text. No spaCy features are extracted\n",
    "\n",
    "# All of these methods try to access their required spaCy attributes, and if\n",
    "# they find that the attribute does not yet exist the necessary method will\n",
    "# be called interally to generate those attributes.\n",
    "\n",
    "num_tokens = pipe.num_tokens()  # internally accesses pipe.tokens\n",
    "log_op_density = pipe.logical_operators()  # internally accesses pipe.tokens\n",
    "fh_score, syls_per_sent = pipe.fernandez_huerta_score()  # internally accesses pipe.tokens and pipe.sentences\n",
    "\n",
    "print(num_tokens)\n",
    "print(log_op_density)\n",
    "print(fh_score)\n",
    "print(syls_per_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-casting",
   "metadata": {},
   "source": [
    "Alternatively, please note that the order of where the text is provided to the pipeline may also be switched. That is, the unprocessed text does not have to be provided to the pipeline at the initialization stage; it can be provided directly to the feature function as well. The text will automatically be cleaned up and the necessary attributes will be extracted using spaCy, following which the statistic will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stuck-jordan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la primavera la primavera principia el veintiuno de marzo y dura hasta el veintiuno de junio. la primavera es muy agradable y hermosa. las flores crecen. los árboles y los campos se cubren de verdura y los pájaros cantan en ellos. todos los hombres, las mujeres y los niños están alegres. algunas veces hace frío en abril y aún en mayo. algunas veces, pero no frecuentemente, hay nieve y hielo en abril, y entonces muchas flores y plantas se mueren.\n",
      "\n",
      "['la', 'primavera', 'la', 'primavera', 'principia', 'el', 'veintiuno', 'de', 'marzo', 'y', 'dura', 'hasta', 'el', 'veintiuno', 'de', 'junio', '.', 'la', 'primavera', 'es', 'muy', 'agradable', 'y', 'hermosa', '.', 'las', 'flores', 'crecen', '.', 'los', 'árboles', 'y', 'los', 'campos', 'se', 'cubren', 'de', 'verdura', 'y', 'los', 'pájaros', 'cantan', 'en', 'ellos', '.', 'todos', 'los', 'hombres', ',', 'las', 'mujeres', 'y', 'los', 'niños', 'están', 'alegres', '.', 'algunas', 'veces', 'hace', 'frío', 'en', 'abril', 'y', 'aún', 'en', 'mayo', '.', 'algunas', 'veces', ',', 'pero', 'no', 'frecuentemente', ',', 'hay', 'nieve', 'y', 'hielo', 'en', 'abril', ',', 'y', 'entonces', 'muchas', 'flores', 'y', 'plantas', 'se', 'mueren', '.']\n",
      "\n",
      "91\n",
      "0.12345679012345678\n",
      "86.16\n",
      "21.285714285714285\n"
     ]
    }
   ],
   "source": [
    "pipe = feature_pipeline()\n",
    "\n",
    "# Saves the cleaned text to pipe.text and the extracted list of tokens to pipe.tokens\n",
    "num_tokens = pipe.num_tokens(text=unprocessed_text)\n",
    "print(pipe.text)\n",
    "print()\n",
    "print(pipe.tokens)\n",
    "print()\n",
    "\n",
    "# No need to pass any arguments, it internally accesses pipe.tokens\n",
    "log_op_density = pipe.logical_operators()\n",
    "\n",
    "# No need to pass any arguments, it internally accesses pipe.tokens\n",
    "# and extracts pipe.sentences from the cleaned up pipe.text\n",
    "fh_score, syls_per_sent = pipe.fernandez_huerta_score()\n",
    "\n",
    "print(num_tokens)\n",
    "print(log_op_density)\n",
    "print(fh_score)\n",
    "print(syls_per_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-scale",
   "metadata": {},
   "source": [
    "Finally, let's extract all of the available statistical features in one go. Accomplishing this is as simple as creating a pipeline object and calling the `.feature_extractor()` method. We explicitly only write two lines, and the unprocessed text can be supplied to the pipeline at either line, but under the hood all 4 stages of processing the text will take place. \\\n",
    "(If the object is initialized with a text, `.feature_extractor()` does not require any arguments. Otherwise, if the object is initialized *without* a text, `.feature_extractor()` must be given a text in order to perform pre-processing and spaCy attribute extraction.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "english-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-07 18:36:50 INFO: Using CoreNLP default properties for: spanish.  Make sure to have spanish models jar (available for download here: https://stanfordnlp.github.io/CoreNLP/) in CLASSPATH\n",
      "2021-06-07 18:37:00 INFO: Starting server with command: java -Xmx5G -cp /Users/eun-youngchristinapark/Documents/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties spanish -annotators depparse -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "pipe = feature_pipeline(dep_parse_flag = True, dep_parse_classpath = \"/Users/eun-youngchristinapark/Documents/stanza_corenlp/*\", \n",
    "                       result_root = \"/Users/eun-youngchristinapark/MDS-CAPSTONE/wn-mcr-transform/wordnet_spa\")\n",
    "pipe.corenlp_client.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "agricultural-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'ADJ': 0.054945054945054944,\n",
      "    'ADP': 0.08791208791208792,\n",
      "    'ADV': 0.054945054945054944,\n",
      "    'AUX': 0.06593406593406594,\n",
      "    'CCONJ': 0.10989010989010989,\n",
      "    'CONJ': 0.0,\n",
      "    'CONTENT': 0.5125,\n",
      "    'DET': 0.17582417582417584,\n",
      "    'EOL': 0.0,\n",
      "    'FUNCTION': 0.4875,\n",
      "    'INTJ': 0.02197802197802198,\n",
      "    'NOUN': 0.23076923076923078,\n",
      "    'NUM': 0.02197802197802198,\n",
      "    'PART': 0.0,\n",
      "    'PRON': 0.03296703296703297,\n",
      "    'PROPN': 0.0,\n",
      "    'PUNCT': 0.12087912087912088,\n",
      "    'SCONJ': 0.0,\n",
      "    'SPACE': 0.0,\n",
      "    'SYM': 0.0,\n",
      "    'VERB': 0.02197802197802198,\n",
      "    'X': 0.0,\n",
      "    'avg_ambiguation_all_words': 2.4782608695652173,\n",
      "    'avg_ambiguation_content_words': 3.392857142857143,\n",
      "    'avg_degree_of_abstraction': 7.918376068376068,\n",
      "    'avg_dep_tree_depth': 3.0,\n",
      "    'avg_rank_of_lemmas_in_freq_list': 786.2637362637363,\n",
      "    'avg_sent_length': 13,\n",
      "    'fernandez_huerta_score': 86.16,\n",
      "    'logical_operator_density': 0.12345679012345678,\n",
      "    'min_degree_of_abstraction': 6.0,\n",
      "    'noun_phrase_density': 0.5416666666666667,\n",
      "    'num_connectives': 7,\n",
      "    'pronoun_density': 0.03409090909090909,\n",
      "    'proportion_of_A_level_tokens': 0.5476190476190477,\n",
      "    'proportion_of_A_level_types': 0.4482758620689655,\n",
      "    'syllables_per_sentence': 21.285714285714285,\n",
      "    'total_tokens': 91,\n",
      "    'total_tokens_w/o_stopwords': 42,\n",
      "    'type_token_ratio': 0.5824175824175825}\n"
     ]
    }
   ],
   "source": [
    "p.pprint(pipe.feature_extractor(unprocessed_text))\n",
    "\n",
    "# ALTERNATIVELY:\n",
    "# pipe = feature_pipeline(unprocessed_text)\n",
    "# pipe.feature_extractor()\n",
    "pipe.corenlp_client.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-consideration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
