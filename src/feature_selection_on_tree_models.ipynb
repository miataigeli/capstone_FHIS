{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conventional-audio",
   "metadata": {},
   "source": [
    "# WARNING: THIS NOTEBOOK TAKES HOURS TO COMPLETELY RUN. DO NOT RUN UNLESS YOU ABSOLUTELY NECESSARY!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-signature",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Feature Selection for Tree-Based Models\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcfde79-f45d-4779-a8a8-318409c42fcf",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "requested-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from itertools import compress\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import (\n",
    "    SequentialFeatureSelector,\n",
    ")  # requires sklearn 0.24 and above\n",
    "from features import feature_pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-brake",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "progressive-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_features.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train = pd.DataFrame(json.load(f))\n",
    "with open(\"../data/val_features.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    val = pd.DataFrame(json.load(f))\n",
    "with open(\"../data/test_features.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test = pd.DataFrame(json.load(f))\n",
    "\n",
    "# load X and y DataFrames\n",
    "X_train = train.drop([\"preprocessed_text\", \"level\"], axis=1)\n",
    "y_train = train[\"level\"].tolist()\n",
    "X_val = val.drop([\"preprocessed_text\", \"level\"], axis=1)\n",
    "y_val = val[\"level\"].tolist()\n",
    "X_test = test.drop([\"preprocessed_text\", \"level\"], axis=1)\n",
    "y_test = test[\"level\"].tolist()\n",
    "\n",
    "# Convert 3-class labels to binary labels\n",
    "y_train_binary = []\n",
    "for lvl in train[\"level\"].tolist():\n",
    "    y_train_binary.append(lvl[0])\n",
    "y_val_binary = []\n",
    "for lvl in val[\"level\"].tolist():\n",
    "    y_val_binary.append(lvl[0])\n",
    "y_test_binary = []\n",
    "for lvl in test[\"level\"].tolist():\n",
    "    y_test_binary.append(lvl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unavailable-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'A1', 'B', 'A2', 'A2', 'A1', 'A1', 'A1', 'B', 'A2', 'B', 'B', 'B', 'B', 'A2', 'A1', 'B', 'B', 'A1', 'A1', 'B', 'B', 'B', 'A1', 'A2', 'A2', 'A1', 'A1', 'B', 'A1', 'B', 'B']\n"
     ]
    }
   ],
   "source": [
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "breeding-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'B', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'B']\n"
     ]
    }
   ],
   "source": [
    "print(y_val_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "serious-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:\n",
      "['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_tokens', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Fut', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "\n",
      "Number of features: 44\n"
     ]
    }
   ],
   "source": [
    "feat_names = list(X_train.columns)\n",
    "print(f\"All features:\\n{feat_names}\\n\\nNumber of features: {len(feat_names)}\")\n",
    "\n",
    "scoring = accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polished-studio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_tokens_w/o_stopwords</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>proportion_of_A_level_tokens</th>\n",
       "      <th>proportion_of_A_level_types</th>\n",
       "      <th>num_connectives</th>\n",
       "      <th>logical_operator_density</th>\n",
       "      <th>pronoun_density</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>avg_rank_of_lemmas_in_freq_list</th>\n",
       "      <th>...</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>EOL</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>FUNCTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2585</td>\n",
       "      <td>1118</td>\n",
       "      <td>35.410959</td>\n",
       "      <td>0.339893</td>\n",
       "      <td>0.182550</td>\n",
       "      <td>18</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>0.047407</td>\n",
       "      <td>0.360155</td>\n",
       "      <td>684.322631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.109865</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635376</td>\n",
       "      <td>0.364624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1539</td>\n",
       "      <td>622</td>\n",
       "      <td>14.941748</td>\n",
       "      <td>0.326367</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>18</td>\n",
       "      <td>0.034970</td>\n",
       "      <td>0.067268</td>\n",
       "      <td>0.388564</td>\n",
       "      <td>629.897336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.107862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621914</td>\n",
       "      <td>0.378086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159</td>\n",
       "      <td>70</td>\n",
       "      <td>22.714286</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>7</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>0.578616</td>\n",
       "      <td>611.383648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291</td>\n",
       "      <td>117</td>\n",
       "      <td>22.384615</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>547.487973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.189003</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.629787</td>\n",
       "      <td>0.370213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>193</td>\n",
       "      <td>21.105263</td>\n",
       "      <td>0.295337</td>\n",
       "      <td>0.231250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.551122</td>\n",
       "      <td>528.177057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.164589</td>\n",
       "      <td>0.022444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.654655</td>\n",
       "      <td>0.345345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_tokens  total_tokens_w/o_stopwords  avg_sent_length  \\\n",
       "0          2585                        1118        35.410959   \n",
       "1          1539                         622        14.941748   \n",
       "2           159                          70        22.714286   \n",
       "3           291                         117        22.384615   \n",
       "4           401                         193        21.105263   \n",
       "\n",
       "   proportion_of_A_level_tokens  proportion_of_A_level_types  num_connectives  \\\n",
       "0                      0.339893                     0.182550               18   \n",
       "1                      0.326367                     0.214612               18   \n",
       "2                      0.557143                     0.395833                7   \n",
       "3                      0.307692                     0.250000                9   \n",
       "4                      0.295337                     0.231250                5   \n",
       "\n",
       "   logical_operator_density  pronoun_density  type_token_ratio  \\\n",
       "0                  0.050386         0.047407          0.360155   \n",
       "1                  0.034970         0.067268          0.388564   \n",
       "2                  0.039216         0.143885          0.578616   \n",
       "3                  0.043011         0.024648          0.580756   \n",
       "4                  0.046997         0.028205          0.551122   \n",
       "\n",
       "   avg_rank_of_lemmas_in_freq_list  ...     PROPN     PUNCT     SCONJ  \\\n",
       "0                       684.322631  ...  0.011605  0.109865  0.032882   \n",
       "1                       629.897336  ...  0.010396  0.152697  0.038337   \n",
       "2                       611.383648  ...  0.012579  0.075472  0.025157   \n",
       "3                       547.487973  ...  0.013746  0.189003  0.034364   \n",
       "4                       528.177057  ...  0.019950  0.164589  0.022444   \n",
       "\n",
       "        SYM      VERB    X  EOL     SPACE   CONTENT  FUNCTION  \n",
       "0  0.000000  0.078530  0.0  0.0  0.000000  0.635376  0.364624  \n",
       "1  0.005198  0.107862  0.0  0.0  0.000000  0.621914  0.378086  \n",
       "2  0.000000  0.169811  0.0  0.0  0.000000  0.673469  0.326531  \n",
       "3  0.000000  0.089347  0.0  0.0  0.003436  0.629787  0.370213  \n",
       "4  0.000000  0.109726  0.0  0.0  0.004988  0.654655  0.345345  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-mexico",
   "metadata": {},
   "source": [
    "### Set up Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rental-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(pipeline, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Fit a pipeline object on training data, and report training score,\n",
    "    validation score, train time and prediction time.\n",
    "\n",
    "    pipeline: (sklearn.Pipeline) Pipeline object\n",
    "    X_train: (pandas.DataFrame) Training feature matrix\n",
    "    y_train: (list) Training labels\n",
    "    X_val: (pandas.DataFrame) Validation feature matrix\n",
    "    y_val: (list) Validation labels\n",
    "\n",
    "    return: (dict{float}) Dictionary of output results\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    train_score = pipeline.score(X_train, y=y_train)\n",
    "\n",
    "    start = time.time()\n",
    "    val_score = pipeline.score(X_val, y=y_val)\n",
    "    val_pred_time = time.time() - start\n",
    "\n",
    "    return {\n",
    "        \"Training_score\": train_score,\n",
    "        \"Validation_score\": val_score,\n",
    "        \"Training_time\": train_time,\n",
    "        \"Prediction_time\": val_pred_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interracial-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_and_display(preprocessor, model, name, results_df, fine_grained=False):\n",
    "    \"\"\"\n",
    "    Train a model pipeline and return the cross validation results.\n",
    "\n",
    "    preprocessor: (sklearn.ColumnTransformer) sklearn object for feature transformation\n",
    "    model: (sklearn.Classifier) Initialized sklearn classifier\n",
    "    name: (str) Name that is shown when the result is displayed\n",
    "    results_df: (dict) Dictionary to store cross-validation results\n",
    "    fine_grained: (bool) If True, model trains with 3-class classification instead of 2. Default is False\n",
    "\n",
    "    return: (dict) Dictionary of cross-validation results\n",
    "    \"\"\"\n",
    "    # Create pipeline\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "\n",
    "    # Binary or 3-class classification\n",
    "    if fine_grained:\n",
    "        y_t = y_train\n",
    "        y_v = y_val\n",
    "    else:\n",
    "        y_t = y_train_binary\n",
    "        y_v = y_val_binary\n",
    "\n",
    "    # Run cross-validation\n",
    "    scores = cross_validate(pipeline, X_train, y_t, X_val, y_v)\n",
    "\n",
    "    # Store to results dictionary\n",
    "    results_df[name] = scores\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-secondary",
   "metadata": {},
   "source": [
    "### Forward feature selection\n",
    "Forward feature selection (greedy) is the feature selection process accomplished through sklearn's `SequentialFeatureSelector` function. It determines the top _k_ features (_k_ is a variable) using feature importance determined by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "corporate-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sfs_cv_and_display(\n",
    "    preprocessor,\n",
    "    model,\n",
    "    name,\n",
    "    results_df,\n",
    "    n_features,\n",
    "    direction,\n",
    "    fine_grained=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a forward feature selection pipeline for the given model and\n",
    "    return the cross validation results.\n",
    "\n",
    "    preprocessor: (sklearn.ColumnTransformer) sklearn object for feature transformation\n",
    "    model: (sklearn.Classifier) Initialized sklearn classifier\n",
    "    name: (str) Name that is shown when the result is displayed\n",
    "    results_df: (dict) Dictionary to store cross-validation results\n",
    "    n_features: (int) Number of features to select with SequentialFeatureSelector\n",
    "    direction: (str) {'forward', 'backward'} Forward or backward feature selection\n",
    "    fine_grained: (bool) If True, model trains with 3-class classification instead of 2. Default is False\n",
    "\n",
    "    return:\n",
    "        (dict) Dictionary of cross-validation results\n",
    "        (list) List of selected best features\n",
    "    \"\"\"\n",
    "    # Initialize feature selector\n",
    "    sfs = SequentialFeatureSelector(\n",
    "        model,\n",
    "        n_features_to_select=n_features,\n",
    "        scoring=\"accuracy\",\n",
    "        direction=direction,\n",
    "        cv=2,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Create feature selection pipeline with preprocessor and model\n",
    "    sfs_pipeline = make_pipeline(preprocessor, sfs, model)\n",
    "\n",
    "    # Binary or 3-class classification\n",
    "    if fine_grained:\n",
    "        y_t = y_train\n",
    "        y_v = y_val\n",
    "    else:\n",
    "        y_t = y_train_binary\n",
    "        y_v = y_val_binary\n",
    "\n",
    "    # Fit pipeline\n",
    "    sfs_pipeline.fit(X_train, y_t)\n",
    "\n",
    "    # Features selected\n",
    "    feats_selected = list(compress(X_train.columns, sfs_pipeline[1].get_support()))\n",
    "\n",
    "    # Subset data for selected features\n",
    "    cv_X_train = X_train[feats_selected]\n",
    "    cv_X_val = X_val[feats_selected]\n",
    "\n",
    "    # Create CV pipeline with selected features\n",
    "    cv_preprocessor = make_column_transformer((StandardScaler(), feats_selected))\n",
    "    pipeline = make_pipeline(cv_preprocessor, model)\n",
    "\n",
    "    # Run cross-validation\n",
    "    scores = cross_validate(pipeline, cv_X_train, y_t, cv_X_val, y_v)\n",
    "\n",
    "    # Store to results dictionary\n",
    "    results_df[f\"{name} + {n_features} features\"] = scores\n",
    "\n",
    "    return results_df, feats_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b321083-e610-4bd1-beda-49492e38d950",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-pillow",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Train 5 baseline tree models for binary classification using the full set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blessed-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsss9\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:23:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTree + depth 1</th>\n",
       "      <th>DecisionTree + depth 2</th>\n",
       "      <th>DecisionTree + depth 3</th>\n",
       "      <th>DecisionTree + depth 4</th>\n",
       "      <th>DecisionTree + depth 5</th>\n",
       "      <th>DecisionTree + depth 6</th>\n",
       "      <th>DecisionTree + depth 7</th>\n",
       "      <th>DecisionTree + depth 8</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training_score</th>\n",
       "      <td>0.836576</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.887160</td>\n",
       "      <td>0.922179</td>\n",
       "      <td>0.953307</td>\n",
       "      <td>0.984436</td>\n",
       "      <td>0.992218</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation_score</th>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training_time</th>\n",
       "      <td>0.202458</td>\n",
       "      <td>0.082780</td>\n",
       "      <td>0.076802</td>\n",
       "      <td>0.098733</td>\n",
       "      <td>0.077797</td>\n",
       "      <td>0.061816</td>\n",
       "      <td>0.082778</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>0.543545</td>\n",
       "      <td>0.782898</td>\n",
       "      <td>1.742374</td>\n",
       "      <td>13.195710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction_time</th>\n",
       "      <td>0.023942</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.021931</td>\n",
       "      <td>0.027924</td>\n",
       "      <td>0.023925</td>\n",
       "      <td>0.102721</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.034905</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DecisionTree + depth 1  DecisionTree + depth 2  \\\n",
       "Training_score                  0.836576                0.863813   \n",
       "Validation_score                0.843750                0.875000   \n",
       "Training_time                   0.202458                0.082780   \n",
       "Prediction_time                 0.023942                0.021940   \n",
       "\n",
       "                  DecisionTree + depth 3  DecisionTree + depth 4  \\\n",
       "Training_score                  0.887160                0.922179   \n",
       "Validation_score                0.875000                0.750000   \n",
       "Training_time                   0.076802                0.098733   \n",
       "Prediction_time                 0.024920                0.032917   \n",
       "\n",
       "                  DecisionTree + depth 5  DecisionTree + depth 6  \\\n",
       "Training_score                  0.953307                0.984436   \n",
       "Validation_score                0.750000                0.812500   \n",
       "Training_time                   0.077797                0.061816   \n",
       "Prediction_time                 0.021973                0.021931   \n",
       "\n",
       "                  DecisionTree + depth 7  DecisionTree + depth 8  \\\n",
       "Training_score                  0.992218                0.996109   \n",
       "Validation_score                0.812500                0.750000   \n",
       "Training_time                   0.082778                0.095753   \n",
       "Prediction_time                 0.027924                0.023925   \n",
       "\n",
       "                  RandomForest  LightGBM   XGBoost   CatBoost  \n",
       "Training_score        1.000000  1.000000  1.000000   1.000000  \n",
       "Validation_score      0.812500  0.843750  0.812500   0.843750  \n",
       "Training_time         0.543545  0.782898  1.742374  13.195710  \n",
       "Prediction_time       0.102721  0.033911  0.034905   0.008976  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dictionary for storing CV results\n",
    "binary_results = {}\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = make_column_transformer((StandardScaler(), feat_names))\n",
    "\n",
    "# Dictionary of all classifiers\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "    \"XGBoost\": XGBClassifier(random_state=123),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=123),\n",
    "}\n",
    "\n",
    "for (name, model) in classifiers.items():\n",
    "    # Iterate over 8 depths if classifier is DecisionTree\n",
    "    if name == \"DecisionTree\":\n",
    "        for d in range(1, 9):\n",
    "            model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "            _name = f\"{name} + depth {d}\"\n",
    "\n",
    "            results_df = cv_and_display(\n",
    "                preprocessor, model, _name, binary_results, fine_grained=False\n",
    "            )\n",
    "    else:\n",
    "        results_df = cv_and_display(\n",
    "            preprocessor, model, name, binary_results, fine_grained=False\n",
    "        )\n",
    "\n",
    "display(pd.DataFrame(binary_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b842c8e-71f7-471a-895d-01f8dac3d171",
   "metadata": {},
   "source": [
    "### Loop through the 3 fastest models and the entire set of features to find the best combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "protected-undergraduate",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTree Feature Selection: 100%|██████████████████████████████████████| 43/43 [30:22<00:00, 42.38s/it]\n",
      "RandomForest Feature Selection: 100%|███████████████████████████████████| 43/43 [2:08:04<00:00, 178.70s/it]\n",
      "LightGBM Feature Selection: 100%|██████████████████████████████████████████| 43/43 [15:03<00:00, 21.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of classifiers to run feature selection on\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "}\n",
    "\n",
    "# Dictionary of best selected features\n",
    "binary_feats = defaultdict(list)\n",
    "\n",
    "for (name, model) in classifiers.items():\n",
    "    # Iterate over all features\n",
    "    for i in tqdm(\n",
    "        range(1, len(feat_names)), desc=f\"{name} Feature Selection\", dynamic_ncols=True\n",
    "    ):\n",
    "        # Iterate over 8 depths if classifier is DecisionTree\n",
    "        if name == \"DecisionTree\":\n",
    "            for d in range(1, 9):\n",
    "                model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "                _name = f\"{name} + depth {d}\"\n",
    "\n",
    "                # Run feature selection and CV\n",
    "                results_df, feats = perform_sfs_cv_and_display(\n",
    "                    preprocessor,\n",
    "                    model,\n",
    "                    _name,\n",
    "                    binary_results,\n",
    "                    n_features=i,\n",
    "                    direction=\"forward\",\n",
    "                    fine_grained=False,\n",
    "                )\n",
    "\n",
    "                # Store best features to dictionary\n",
    "                binary_feats[name].append(feats)\n",
    "        else:\n",
    "            results_df, feats = perform_sfs_cv_and_display(\n",
    "                preprocessor,\n",
    "                model,\n",
    "                name,\n",
    "                binary_results,\n",
    "                n_features=i,\n",
    "                direction=\"forward\",\n",
    "                fine_grained=False,\n",
    "            )\n",
    "\n",
    "            binary_feats[name].append(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "saving-format",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTree + depth 8 + 4 features</th>\n",
       "      <th>DecisionTree + depth 8 + 3 features</th>\n",
       "      <th>DecisionTree + depth 4 + 2 features</th>\n",
       "      <th>DecisionTree + depth 4 + 4 features</th>\n",
       "      <th>DecisionTree + depth 8 + 30 features</th>\n",
       "      <th>DecisionTree + depth 4 + 3 features</th>\n",
       "      <th>DecisionTree + depth 8 + 37 features</th>\n",
       "      <th>DecisionTree + depth 7 + 24 features</th>\n",
       "      <th>RandomForest + 10 features</th>\n",
       "      <th>DecisionTree + depth 2 + 39 features</th>\n",
       "      <th>...</th>\n",
       "      <th>DecisionTree + depth 8 + 20 features</th>\n",
       "      <th>DecisionTree + depth 6 + 13 features</th>\n",
       "      <th>DecisionTree + depth 7 + 35 features</th>\n",
       "      <th>DecisionTree + depth 8 + 18 features</th>\n",
       "      <th>DecisionTree + depth 5 + 15 features</th>\n",
       "      <th>DecisionTree + depth 8 + 17 features</th>\n",
       "      <th>DecisionTree + depth 5 + 17 features</th>\n",
       "      <th>DecisionTree + depth 5 + 19 features</th>\n",
       "      <th>DecisionTree + depth 6 + 14 features</th>\n",
       "      <th>DecisionTree + depth 5 + 40 features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training_score</th>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.887160</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.976654</td>\n",
       "      <td>0.891051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992218</td>\n",
       "      <td>0.976654</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>0.949416</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>0.949416</td>\n",
       "      <td>0.953307</td>\n",
       "      <td>0.976654</td>\n",
       "      <td>0.957198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation_score</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training_time</th>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.186503</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.009973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction_time</th>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.006980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DecisionTree + depth 8 + 4 features  \\\n",
       "Training_score                               0.972763   \n",
       "Validation_score                             0.937500   \n",
       "Training_time                                0.009972   \n",
       "Prediction_time                              0.005985   \n",
       "\n",
       "                  DecisionTree + depth 8 + 3 features  \\\n",
       "Training_score                               0.937743   \n",
       "Validation_score                             0.937500   \n",
       "Training_time                                0.011968   \n",
       "Prediction_time                              0.004987   \n",
       "\n",
       "                  DecisionTree + depth 4 + 2 features  \\\n",
       "Training_score                               0.887160   \n",
       "Validation_score                             0.906250   \n",
       "Training_time                                0.010971   \n",
       "Prediction_time                              0.005984   \n",
       "\n",
       "                  DecisionTree + depth 4 + 4 features  \\\n",
       "Training_score                               0.898833   \n",
       "Validation_score                             0.906250   \n",
       "Training_time                                0.005985   \n",
       "Prediction_time                              0.002995   \n",
       "\n",
       "                  DecisionTree + depth 8 + 30 features  \\\n",
       "Training_score                                0.976654   \n",
       "Validation_score                              0.906250   \n",
       "Training_time                                 0.009974   \n",
       "Prediction_time                               0.002990   \n",
       "\n",
       "                  DecisionTree + depth 4 + 3 features  \\\n",
       "Training_score                               0.891051   \n",
       "Validation_score                             0.906250   \n",
       "Training_time                                0.007977   \n",
       "Prediction_time                              0.005983   \n",
       "\n",
       "                  DecisionTree + depth 8 + 37 features  \\\n",
       "Training_score                                1.000000   \n",
       "Validation_score                              0.906250   \n",
       "Training_time                                 0.011966   \n",
       "Prediction_time                               0.002990   \n",
       "\n",
       "                  DecisionTree + depth 7 + 24 features  \\\n",
       "Training_score                                0.992218   \n",
       "Validation_score                              0.906250   \n",
       "Training_time                                 0.008975   \n",
       "Prediction_time                               0.002992   \n",
       "\n",
       "                  RandomForest + 10 features  \\\n",
       "Training_score                      1.000000   \n",
       "Validation_score                    0.906250   \n",
       "Training_time                       0.186503   \n",
       "Prediction_time                     0.013962   \n",
       "\n",
       "                  DecisionTree + depth 2 + 39 features  ...  \\\n",
       "Training_score                                0.863813  ...   \n",
       "Validation_score                              0.875000  ...   \n",
       "Training_time                                 0.008974  ...   \n",
       "Prediction_time                               0.003989  ...   \n",
       "\n",
       "                  DecisionTree + depth 8 + 20 features  \\\n",
       "Training_score                                0.992218   \n",
       "Validation_score                              0.718750   \n",
       "Training_time                                 0.012964   \n",
       "Prediction_time                               0.003987   \n",
       "\n",
       "                  DecisionTree + depth 6 + 13 features  \\\n",
       "Training_score                                0.976654   \n",
       "Validation_score                              0.718750   \n",
       "Training_time                                 0.008975   \n",
       "Prediction_time                               0.003989   \n",
       "\n",
       "                  DecisionTree + depth 7 + 35 features  \\\n",
       "Training_score                                0.996109   \n",
       "Validation_score                              0.718750   \n",
       "Training_time                                 0.016954   \n",
       "Prediction_time                               0.003990   \n",
       "\n",
       "                  DecisionTree + depth 8 + 18 features  \\\n",
       "Training_score                                0.996109   \n",
       "Validation_score                              0.718750   \n",
       "Training_time                                 0.009973   \n",
       "Prediction_time                               0.004985   \n",
       "\n",
       "                  DecisionTree + depth 5 + 15 features  \\\n",
       "Training_score                                0.949416   \n",
       "Validation_score                              0.718750   \n",
       "Training_time                                 0.007977   \n",
       "Prediction_time                               0.004987   \n",
       "\n",
       "                  DecisionTree + depth 8 + 17 features  \\\n",
       "Training_score                                0.996109   \n",
       "Validation_score                              0.718750   \n",
       "Training_time                                 0.006981   \n",
       "Prediction_time                               0.003991   \n",
       "\n",
       "                  DecisionTree + depth 5 + 17 features  \\\n",
       "Training_score                                0.949416   \n",
       "Validation_score                              0.687500   \n",
       "Training_time                                 0.010971   \n",
       "Prediction_time                               0.002991   \n",
       "\n",
       "                  DecisionTree + depth 5 + 19 features  \\\n",
       "Training_score                                0.953307   \n",
       "Validation_score                              0.687500   \n",
       "Training_time                                 0.010969   \n",
       "Prediction_time                               0.003991   \n",
       "\n",
       "                  DecisionTree + depth 6 + 14 features  \\\n",
       "Training_score                                0.976654   \n",
       "Validation_score                              0.687500   \n",
       "Training_time                                 0.007978   \n",
       "Prediction_time                               0.004988   \n",
       "\n",
       "                  DecisionTree + depth 5 + 40 features  \n",
       "Training_score                                0.957198  \n",
       "Validation_score                              0.687500  \n",
       "Training_time                                 0.009973  \n",
       "Prediction_time                               0.006980  \n",
       "\n",
       "[4 rows x 442 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort by Validation_score and display\n",
    "display(\n",
    "    pd.DataFrame(binary_results).sort_values(\"Validation_score\", 1, ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d15a6-742a-4feb-b87e-1ddd47365d91",
   "metadata": {},
   "source": [
    "### Best model and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "medium-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Decision Tree of depth 8 with 4 features\n",
      "Selected features:\n",
      "['avg_sent_length', 'syllables_per_sentence', 'avg_parse_tree_depth', 'SYM']\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: Decision Tree of depth 8 with 4 features\")\n",
    "print(f\"Selected features:\\n{binary_feats['DecisionTree'][4*8-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-vault",
   "metadata": {},
   "source": [
    "### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "available-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.844\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.93      0.76      0.84        17\n",
      "           B       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.85      0.85      0.84        32\n",
      "weighted avg       0.86      0.84      0.84        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_features = [\n",
    "    \"avg_sent_length\",\n",
    "    \"syllables_per_sentence\",\n",
    "    \"avg_parse_tree_depth\",\n",
    "    \"SYM\",\n",
    "]\n",
    "best_model = DecisionTreeClassifier(random_state=123, max_depth=8)\n",
    "X_train_selected = X_train[selected_features]  # Select train data\n",
    "X_test_selected = X_test[selected_features]  # Select test data\n",
    "# cv with selected features\n",
    "preprocessor = make_column_transformer((StandardScaler(), selected_features))\n",
    "pipeline = make_pipeline(preprocessor, best_model)\n",
    "# Train the model\n",
    "pipeline.fit(X_train_selected, y_train_binary)\n",
    "\n",
    "predicted_y_test_binary = pipeline.predict(X_test_selected)\n",
    "print(\"Test accuracy %0.3f\" % (accuracy_score(y_test_binary, predicted_y_test_binary)))\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(y_test_binary, predicted_y_test_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fe4fc-fa7c-46ca-8cc7-3bb51e0156fe",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6da641-85ad-4bde-bb6b-84f36919ef6b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Train 5 baseline tree models for 3-class classification using the full set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elect-turtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsss9\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTree + depth 1</th>\n",
       "      <th>DecisionTree + depth 2</th>\n",
       "      <th>DecisionTree + depth 3</th>\n",
       "      <th>DecisionTree + depth 4</th>\n",
       "      <th>DecisionTree + depth 5</th>\n",
       "      <th>DecisionTree + depth 6</th>\n",
       "      <th>DecisionTree + depth 7</th>\n",
       "      <th>DecisionTree + depth 8</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training_score</th>\n",
       "      <td>0.715953</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.859922</td>\n",
       "      <td>0.906615</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training_time</th>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>0.037897</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.271260</td>\n",
       "      <td>0.291236</td>\n",
       "      <td>0.854683</td>\n",
       "      <td>26.447140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction_time</th>\n",
       "      <td>0.006978</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DecisionTree + depth 1  DecisionTree + depth 2  \\\n",
       "Training_score                  0.715953                0.754864   \n",
       "Validation_score                0.750000                0.750000   \n",
       "Training_time                   0.023933                0.014962   \n",
       "Prediction_time                 0.006978                0.006984   \n",
       "\n",
       "                  DecisionTree + depth 3  DecisionTree + depth 4  \\\n",
       "Training_score                  0.785992                0.859922   \n",
       "Validation_score                0.750000                0.718750   \n",
       "Training_time                   0.010967                0.023936   \n",
       "Prediction_time                 0.015957                0.013963   \n",
       "\n",
       "                  DecisionTree + depth 5  DecisionTree + depth 6  \\\n",
       "Training_score                  0.906615                0.964981   \n",
       "Validation_score                0.656250                0.687500   \n",
       "Training_time                   0.021340                0.037897   \n",
       "Prediction_time                 0.017633                0.008932   \n",
       "\n",
       "                  DecisionTree + depth 7  DecisionTree + depth 8  \\\n",
       "Training_score                  0.988327                1.000000   \n",
       "Validation_score                0.656250                0.656250   \n",
       "Training_time                   0.010868                0.015623   \n",
       "Prediction_time                 0.000000                0.015622   \n",
       "\n",
       "                  RandomForest  LightGBM   XGBoost   CatBoost  \n",
       "Training_score        1.000000  1.000000  1.000000   1.000000  \n",
       "Validation_score      0.750000  0.687500  0.625000   0.750000  \n",
       "Training_time         0.271260  0.291236  0.854683  26.447140  \n",
       "Prediction_time       0.015621  0.000000  0.015622   0.015621  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dictionary for storing CV results\n",
    "multiclass_results = {}\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = make_column_transformer((StandardScaler(), feat_names))\n",
    "\n",
    "# Dictionary of all classifiers\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "    \"XGBoost\": XGBClassifier(random_state=123),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=123),\n",
    "}\n",
    "\n",
    "for (name, model) in classifiers.items():\n",
    "    # Iterate over 8 depths if classifier is DecisionTree\n",
    "    if name == \"DecisionTree\":\n",
    "        for d in range(1, 9):\n",
    "            model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "            _name = f\"{name} + depth {d}\"\n",
    "\n",
    "            results_df = cv_and_display(\n",
    "                preprocessor, model, _name, multiclass_results, fine_grained=True\n",
    "            )\n",
    "    else:\n",
    "        results_df = cv_and_display(\n",
    "            preprocessor, model, name, multiclass_results, fine_grained=True\n",
    "        )\n",
    "\n",
    "display(pd.DataFrame(multiclass_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738d203-ce28-4335-a66b-acedec85d7a1",
   "metadata": {},
   "source": [
    "### Loop through the 3 fastest models and the entire set of features to find the best combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "average-potential",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTree Feature Selection: 100%|██████████████████████████████████████| 43/43 [37:14<00:00, 51.95s/it]\n",
      "RandomForest Feature Selection: 100%|███████████████████████████████████| 43/43 [2:11:37<00:00, 183.65s/it]\n",
      "LightGBM Feature Selection: 100%|██████████████████████████████████████████| 43/43 [34:51<00:00, 48.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of classifiers to run feature selection on\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "}\n",
    "\n",
    "# Dictionary of best selected features\n",
    "multiclass_feats = defaultdict(list)\n",
    "\n",
    "for (name, model) in classifiers.items():\n",
    "    # Iterate over all features\n",
    "    for i in tqdm(\n",
    "        range(1, len(feat_names)), desc=f\"{name} Feature Selection\", dynamic_ncols=True\n",
    "    ):\n",
    "        # Iterate over 8 depths if classifier is DecisionTree\n",
    "        if name == \"DecisionTree\":\n",
    "            for d in range(1, 9):\n",
    "                model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "                _name = f\"{name} + depth {d}\"\n",
    "\n",
    "                # Run feature selection and CV\n",
    "                results_df, feats = perform_sfs_cv_and_display(\n",
    "                    preprocessor,\n",
    "                    model,\n",
    "                    _name,\n",
    "                    multiclass_results,\n",
    "                    n_features=i,\n",
    "                    direction=\"forward\",\n",
    "                    fine_grained=True,\n",
    "                )\n",
    "\n",
    "                # Store best features to dictionary\n",
    "                multiclass_feats[name].append(feats)\n",
    "        else:\n",
    "            results_df, feats = perform_sfs_cv_and_display(\n",
    "                preprocessor,\n",
    "                model,\n",
    "                name,\n",
    "                multiclass_results,\n",
    "                n_features=i,\n",
    "                direction=\"forward\",\n",
    "                fine_grained=True,\n",
    "            )\n",
    "\n",
    "            multiclass_feats[name].append(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "facial-calgary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM + 33 features</th>\n",
       "      <th>LightGBM + 38 features</th>\n",
       "      <th>LightGBM + 37 features</th>\n",
       "      <th>LightGBM + 35 features</th>\n",
       "      <th>LightGBM + 24 features</th>\n",
       "      <th>LightGBM + 29 features</th>\n",
       "      <th>DecisionTree + depth 4 + 5 features</th>\n",
       "      <th>DecisionTree + depth 5 + 26 features</th>\n",
       "      <th>DecisionTree + depth 4 + 6 features</th>\n",
       "      <th>DecisionTree + depth 4 + 13 features</th>\n",
       "      <th>...</th>\n",
       "      <th>DecisionTree + depth 8 + 14 features</th>\n",
       "      <th>DecisionTree + depth 7 + 17 features</th>\n",
       "      <th>DecisionTree + depth 7 + 11 features</th>\n",
       "      <th>DecisionTree + depth 8 + 26 features</th>\n",
       "      <th>DecisionTree + depth 8 + 27 features</th>\n",
       "      <th>DecisionTree + depth 6 + 3 features</th>\n",
       "      <th>DecisionTree + depth 7 + 18 features</th>\n",
       "      <th>DecisionTree + depth 7 + 10 features</th>\n",
       "      <th>DecisionTree + depth 7 + 9 features</th>\n",
       "      <th>DecisionTree + depth 8 + 23 features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832685</td>\n",
       "      <td>0.875486</td>\n",
       "      <td>0.832685</td>\n",
       "      <td>0.832685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968872</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.968872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883268</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.968872</td>\n",
       "      <td>0.968872</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation_score</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training_time</th>\n",
       "      <td>0.243261</td>\n",
       "      <td>0.269657</td>\n",
       "      <td>0.258646</td>\n",
       "      <td>0.253862</td>\n",
       "      <td>0.225428</td>\n",
       "      <td>0.236346</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.016853</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction_time</th>\n",
       "      <td>0.007247</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.009271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016940</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LightGBM + 33 features  LightGBM + 38 features  \\\n",
       "Training_score                  1.000000                1.000000   \n",
       "Validation_score                0.812500                0.812500   \n",
       "Training_time                   0.243261                0.269657   \n",
       "Prediction_time                 0.007247                0.008123   \n",
       "\n",
       "                  LightGBM + 37 features  LightGBM + 35 features  \\\n",
       "Training_score                  1.000000                1.000000   \n",
       "Validation_score                0.812500                0.812500   \n",
       "Training_time                   0.258646                0.253862   \n",
       "Prediction_time                 0.008116                0.008235   \n",
       "\n",
       "                  LightGBM + 24 features  LightGBM + 29 features  \\\n",
       "Training_score                  1.000000                1.000000   \n",
       "Validation_score                0.812500                0.812500   \n",
       "Training_time                   0.225428                0.236346   \n",
       "Prediction_time                 0.008207                0.009271   \n",
       "\n",
       "                  DecisionTree + depth 4 + 5 features  \\\n",
       "Training_score                               0.832685   \n",
       "Validation_score                             0.781250   \n",
       "Training_time                                0.015661   \n",
       "Prediction_time                              0.000000   \n",
       "\n",
       "                  DecisionTree + depth 5 + 26 features  \\\n",
       "Training_score                                0.875486   \n",
       "Validation_score                              0.781250   \n",
       "Training_time                                 0.000000   \n",
       "Prediction_time                               0.015619   \n",
       "\n",
       "                  DecisionTree + depth 4 + 6 features  \\\n",
       "Training_score                               0.832685   \n",
       "Validation_score                             0.781250   \n",
       "Training_time                                0.015624   \n",
       "Prediction_time                              0.000000   \n",
       "\n",
       "                  DecisionTree + depth 4 + 13 features  ...  \\\n",
       "Training_score                                0.832685  ...   \n",
       "Validation_score                              0.781250  ...   \n",
       "Training_time                                 0.000000  ...   \n",
       "Prediction_time                               0.007421  ...   \n",
       "\n",
       "                  DecisionTree + depth 8 + 14 features  \\\n",
       "Training_score                                0.968872   \n",
       "Validation_score                              0.500000   \n",
       "Training_time                                 0.004046   \n",
       "Prediction_time                               0.000000   \n",
       "\n",
       "                  DecisionTree + depth 7 + 17 features  \\\n",
       "Training_score                                0.972763   \n",
       "Validation_score                              0.500000   \n",
       "Training_time                                 0.016853   \n",
       "Prediction_time                               0.015655   \n",
       "\n",
       "                  DecisionTree + depth 7 + 11 features  \\\n",
       "Training_score                                0.968872   \n",
       "Validation_score                              0.500000   \n",
       "Training_time                                 0.007352   \n",
       "Prediction_time                               0.002295   \n",
       "\n",
       "                  DecisionTree + depth 8 + 26 features  \\\n",
       "Training_score                                1.000000   \n",
       "Validation_score                              0.500000   \n",
       "Training_time                                 0.007978   \n",
       "Prediction_time                               0.002992   \n",
       "\n",
       "                  DecisionTree + depth 8 + 27 features  \\\n",
       "Training_score                                1.000000   \n",
       "Validation_score                              0.500000   \n",
       "Training_time                                 0.000000   \n",
       "Prediction_time                               0.015622   \n",
       "\n",
       "                  DecisionTree + depth 6 + 3 features  \\\n",
       "Training_score                               0.883268   \n",
       "Validation_score                             0.500000   \n",
       "Training_time                                0.015656   \n",
       "Prediction_time                              0.000000   \n",
       "\n",
       "                  DecisionTree + depth 7 + 18 features  \\\n",
       "Training_score                                0.972763   \n",
       "Validation_score                              0.500000   \n",
       "Training_time                                 0.015697   \n",
       "Prediction_time                               0.016940   \n",
       "\n",
       "                  DecisionTree + depth 7 + 10 features  \\\n",
       "Training_score                                0.968872   \n",
       "Validation_score                              0.500000   \n",
       "Training_time                                 0.027638   \n",
       "Prediction_time                               0.015692   \n",
       "\n",
       "                  DecisionTree + depth 7 + 9 features  \\\n",
       "Training_score                               0.968872   \n",
       "Validation_score                             0.500000   \n",
       "Training_time                                0.006652   \n",
       "Prediction_time                              0.001997   \n",
       "\n",
       "                  DecisionTree + depth 8 + 23 features  \n",
       "Training_score                                1.000000  \n",
       "Validation_score                              0.468750  \n",
       "Training_time                                 0.015622  \n",
       "Prediction_time                               0.000000  \n",
       "\n",
       "[4 rows x 442 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort by Validation_score and display\n",
    "display(\n",
    "    pd.DataFrame(multiclass_results).sort_values(\"Validation_score\", 1, ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f8836d-4576-4b7f-9986-501985818c78",
   "metadata": {},
   "source": [
    "### Best model and best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wrapped-inflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LightGBM with 24 features\n",
      "Selected features:\n",
      "['avg_sent_length', 'pronoun_density', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'avg_parse_tree_depth', 'Past', 'AUX', 'CONJ', 'DET', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SYM', 'VERB', 'X', 'EOL', 'SPACE', 'FUNCTION']\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: LightGBM with 24 features\")\n",
    "print(f\"Selected features:\\n{multiclass_feats['LightGBM'][24-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a1b76-e277-4945-84d4-4a6cc820c55b",
   "metadata": {},
   "source": [
    "### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sitting-burner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.625\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.62      0.45      0.53        11\n",
      "          A2       0.29      0.33      0.31         6\n",
      "           B       0.76      0.87      0.81        15\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.56      0.55      0.55        32\n",
      "weighted avg       0.63      0.62      0.62        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_features = [\n",
    "    \"avg_sent_length\",\n",
    "    \"pronoun_density\",\n",
    "    \"fernandez_huerta_score\",\n",
    "    \"syllables_per_sentence\",\n",
    "    \"avg_degree_of_abstraction\",\n",
    "    \"min_degree_of_abstraction\",\n",
    "    \"avg_ambiguation_all_words\",\n",
    "    \"avg_ambiguation_content_words\",\n",
    "    \"avg_parse_tree_depth\",\n",
    "    \"Past\",\n",
    "    \"AUX\",\n",
    "    \"CONJ\",\n",
    "    \"DET\",\n",
    "    \"NOUN\",\n",
    "    \"NUM\",\n",
    "    \"PART\",\n",
    "    \"PRON\",\n",
    "    \"PUNCT\",\n",
    "    \"SYM\",\n",
    "    \"VERB\",\n",
    "    \"X\",\n",
    "    \"EOL\",\n",
    "    \"SPACE\",\n",
    "    \"FUNCTION\",\n",
    "]\n",
    "best_model = LGBMClassifier(random_state=123)\n",
    "X_train_selected = X_train[selected_features]  # Select train data\n",
    "X_test_selected = X_test[selected_features]  # Select test data\n",
    "# cv with selected features\n",
    "preprocessor = make_column_transformer((StandardScaler(), selected_features))\n",
    "pipeline = make_pipeline(preprocessor, best_model)\n",
    "# Train the model\n",
    "pipeline.fit(X_train_selected, y_train)\n",
    "\n",
    "predicted_y_test = pipeline.predict(X_test_selected)\n",
    "print(\"Test accuracy %0.3f\" % (accuracy_score(y_test, predicted_y_test)))\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a977193-5851-44a9-9b07-619fc19b44e4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611a3ea-da79-4e55-bebb-55306b2926f4",
   "metadata": {},
   "source": [
    "## Save the predictions of the best model to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "consecutive-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\"test_text\": [], \"prediction\": [], \"gold\": []}\n",
    "for i in range(len(y_test)):\n",
    "    output_dict[\"test_text\"].append(test[\"preprocessed_text\"][i])\n",
    "    output_dict[\"prediction\"].append(predicted_y_test[i])\n",
    "    output_dict[\"gold\"].append(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intermediate-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capítulo —¡paren ya de pelearse! —el hombre al...</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¡es con voz de la biblia, o verso de walt whit...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>los cuatro hermanos un zapatero tenía cuatro h...</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una mañana entró un caballero en la tienda de ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>había un viejo que tenía una hija muy hermosa....</td>\n",
       "      <td>A2</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           test_text prediction gold\n",
       "0  capítulo —¡paren ya de pelearse! —el hombre al...         A1   A1\n",
       "1  ¡es con voz de la biblia, o verso de walt whit...          B    B\n",
       "2  los cuatro hermanos un zapatero tenía cuatro h...         A2   A2\n",
       "3  una mañana entró un caballero en la tienda de ...         A1   A1\n",
       "4  había un viejo que tenía una hija muy hermosa....         A2   A1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output_dict).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mobile-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../predictions/lightgbm_test_pred.json\", \"w\", encoding=\"utf-8\") as fout:\n",
    "    json.dump(output_dict, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
