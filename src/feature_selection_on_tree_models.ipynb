{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assigned-strength",
   "metadata": {},
   "source": [
    "## Feature Selection on Tree-Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from itertools import compress\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SequentialFeatureSelector # requires sklearn 0.24 and above\n",
    "from features import feature_pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-trademark",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_features.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train = pd.DataFrame(json.load(f))\n",
    "with open(\"../data/val_features.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    val = pd.DataFrame(json.load(f))\n",
    "with open(\"../data/test_features.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test = pd.DataFrame(json.load(f))\n",
    "\n",
    "X_train = train.drop([\"preprocessed_text\", \"level\"], axis=1)\n",
    "y_train = train[\"level\"].tolist()\n",
    "X_val = val.drop([\"preprocessed_text\", \"level\"], axis=1)\n",
    "y_val = val[\"level\"].tolist()\n",
    "X_test = test.drop([\"preprocessed_text\", \"level\"], axis=1)\n",
    "y_test = test[\"level\"].tolist()\n",
    "\n",
    "y_train_binary = []\n",
    "for lvl in train[\"level\"].tolist():\n",
    "    y_train_binary.append(lvl[0])\n",
    "y_val_binary = []\n",
    "for lvl in val[\"level\"].tolist():\n",
    "    y_val_binary.append(lvl[0])\n",
    "y_test_binary = []\n",
    "for lvl in test[\"level\"].tolist():\n",
    "    y_test_binary.append(lvl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_val_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = list(X_train.columns)\n",
    "print(f\"All features:\\n{feat_names}\\n\\nNumber of features: {len(feat_names)}\")\n",
    "\n",
    "scoring = accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-result",
   "metadata": {},
   "source": [
    "### Set up Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(pipeline, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\"\"\"\n",
    "    start = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    train_score = pipeline.score(X_train, y=y_train)\n",
    "\n",
    "    start = time.time()\n",
    "    val_score = pipeline.score(X_val, y=y_val)\n",
    "    val_pred_time = time.time() - start\n",
    "\n",
    "    return {\n",
    "        \"Training_score\": train_score,\n",
    "        \"Validation_score\": val_score,\n",
    "        \"Training_time\": train_time,\n",
    "        \"Prediction_time\": val_pred_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_and_display(preprocessor, model, name, results_df, fine_grained=False):\n",
    "    \"\"\"\n",
    "    train model and return the cross validation results\n",
    "\n",
    "    preprocessor: (sklearn ColumnTransformer) sklearn object for feature transformation\n",
    "    model: (sklearn Classifier) initialized sklearn classifier\n",
    "    name: (str) a name that is shown when the result is displayed\n",
    "    results_df: (dict) the dictionary to store cross validation results\n",
    "    fine_grained: (str) {True, False} True: model trains with 3 class classification instead of 2. Default is False\n",
    "\n",
    "    return: (dict) results_df\n",
    "    \"\"\"\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "    if fine_grained:\n",
    "        y_t = y_train\n",
    "        y_v = y_val\n",
    "    else:\n",
    "        y_t = y_train_binary\n",
    "        y_v = y_val_binary\n",
    "\n",
    "    scores = cross_validate(pipeline, X_train, y_t, X_val, y_v)\n",
    "\n",
    "    results_df[name] = scores\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-entertainment",
   "metadata": {},
   "source": [
    "## Forward feature selection - Greedy\n",
    "Forward feature selection (greedy) is the feature selection process accomplished through sklearn's `SequentialFeatureSelector` function. It determines the top k features (k is a variable) using feature importance determined by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sfs_cv_and_display(\n",
    "    preprocessor,\n",
    "    model,\n",
    "    name,\n",
    "    results_df,\n",
    "    n_features,\n",
    "    direction,\n",
    "    fine_grained=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    generate a feature selection pipeline for svm models and perform cross validation\n",
    "\n",
    "    preprocessor: (sklearn ColumnTransformer) sklearn object for feature transformation\n",
    "    model: (sklearn Classifier) initialized sklearn classifier\n",
    "    name: (str) a name that is shown when the result is displayed\n",
    "    results_df: (dict) the dictionary to store cross validation results\n",
    "    n_features: (int) argument passed into the `n_features_to_select` argument in SequentialFeatureSelector\n",
    "    direction: (str) {'forward', 'backward'}, argument passe dinto the direction argument in SequentialFeatureSelector\n",
    "    fine_grained: (str) {True, False} True: model trains with 3 class classification instead of 2. Default is False\n",
    "\n",
    "    return: (dict) results_df\n",
    "    \"\"\"\n",
    "    # initialize selector\n",
    "    sfs = SequentialFeatureSelector(\n",
    "        model,\n",
    "        n_features_to_select=n_features,\n",
    "        scoring=\"accuracy\",\n",
    "        direction=direction,\n",
    "        cv=2,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    sfs_pipeline = make_pipeline(preprocessor, sfs, model)\n",
    "\n",
    "    if fine_grained:\n",
    "        y_t = y_train\n",
    "        y_v = y_val\n",
    "    else:\n",
    "        y_t = y_train_binary\n",
    "        y_v = y_val_binary\n",
    "\n",
    "    # fit\n",
    "    sfs_pipeline.fit(X_train, y_t)\n",
    "\n",
    "    # features selected\n",
    "    feats_selected = list(compress(X_train.columns, sfs_pipeline[1].get_support()))\n",
    "#     print(f\"features selected:\\n{feats_selected}\")\n",
    "\n",
    "    # subset data\n",
    "    cv_X_train = X_train[feats_selected]\n",
    "    cv_X_val = X_val[feats_selected]\n",
    "\n",
    "    # cv with selected features\n",
    "    cv_preprocessor = make_column_transformer((StandardScaler(), feats_selected))\n",
    "    pipeline = make_pipeline(cv_preprocessor, model)\n",
    "\n",
    "    scores = cross_validate(pipeline, cv_X_train, y_t, cv_X_val, y_v)\n",
    "\n",
    "    results_df[f\"{name} + {n_features} features\"] = scores\n",
    "\n",
    "    return results_df, feats_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-revolution",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_results = {}\n",
    "\n",
    "preprocessor = make_column_transformer((StandardScaler(), feat_names))\n",
    "\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "    \"XGBoost\": XGBClassifier(random_state=123),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=123),\n",
    "}\n",
    "\n",
    "for (name, model) in classifiers.items():\n",
    "    if name == \"DecisionTree\":\n",
    "        for d in range(1, 9):\n",
    "            model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "            name = f\"{name} + depth {d}\"\n",
    "\n",
    "            results_df = cv_and_display(\n",
    "                preprocessor, model, name, binary_results, fine_grained=False\n",
    "            )\n",
    "    else:\n",
    "        results_df = cv_and_display(\n",
    "            preprocessor, model, name, binary_results, fine_grained=False\n",
    "        )\n",
    "\n",
    "display(pd.DataFrame(binary_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-reflection",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through models and number of features to find the best combination\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "}\n",
    "\n",
    "binary_feats = defaultdict(list)\n",
    "for (name, model) in classifiers.items():\n",
    "    for i in tqdm(\n",
    "        range(1, len(feat_names)), desc=f\"{name} Feature Selection\", dynamic_ncols=True\n",
    "    ):\n",
    "        if name == \"DecisionTree\":\n",
    "            for d in range(1, 9):\n",
    "                model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "                name = f\"{name} + depth {d}\"\n",
    "\n",
    "                results_df, feats = perform_sfs_cv_and_display(\n",
    "                    preprocessor,\n",
    "                    model,\n",
    "                    name,\n",
    "                    binary_results,\n",
    "                    n_features=i,\n",
    "                    direction=\"forward\",\n",
    "                    fine_grained=False,\n",
    "                )\n",
    "\n",
    "                binary_feats[name].append(feats)\n",
    "        else:\n",
    "            results_df, feats = perform_sfs_cv_and_display(\n",
    "                preprocessor,\n",
    "                model,\n",
    "                name,\n",
    "                binary_results,\n",
    "                n_features=i,\n",
    "                direction=\"forward\",\n",
    "                fine_grained=False,\n",
    "            )\n",
    "\n",
    "            binary_feats[name].append(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by Validation_score and display\n",
    "display(pd.DataFrame(binary_results).sort_values(\"Validation_score\", 1, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-judgment",
   "metadata": {},
   "source": [
    "### 3-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_results = {}\n",
    "\n",
    "preprocessor = make_column_transformer((StandardScaler(), feat_names))\n",
    "\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "    \"XGBoost\": XGBClassifier(random_state=123),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=123),\n",
    "}\n",
    "\n",
    "for (name, model) in classifiers.items():\n",
    "    if name == \"DecisionTree\":\n",
    "        for d in range(1, 9):\n",
    "            model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "            name = f\"{name} + depth {d}\"\n",
    "\n",
    "            results_df = cv_and_display(\n",
    "                preprocessor, model, name, multiclass_results, fine_grained=False\n",
    "            )\n",
    "    else:\n",
    "        results_df = cv_and_display(\n",
    "            preprocessor, model, name, multiclass_results, fine_grained=False\n",
    "        )\n",
    "\n",
    "display(pd.DataFrame(multiclass_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-darwin",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through models and number of features to find the best combination\n",
    "classifiers = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=123, max_depth=8),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "}\n",
    "\n",
    "multiclass_feats = defaultdict(list)\n",
    "for (name, model) in classifiers.items():\n",
    "    for i in tqdm(\n",
    "        range(1, len(feat_names)), desc=f\"{name} Feature Selection\", dynamic_ncols=True\n",
    "    ):\n",
    "        if name == \"DecisionTree\":\n",
    "            for d in range(1, 9):\n",
    "                model = DecisionTreeClassifier(random_state=123, max_depth=d)\n",
    "                name = f\"{name} + depth {d}\"\n",
    "\n",
    "                results_df, feats = perform_sfs_cv_and_display(\n",
    "                    preprocessor,\n",
    "                    model,\n",
    "                    name,\n",
    "                    multiclass_results,\n",
    "                    n_features=i,\n",
    "                    direction=\"forward\",\n",
    "                    fine_grained=False,\n",
    "                )\n",
    "\n",
    "                multiclass_feats[name].append(feats)\n",
    "        else:\n",
    "            results_df, feats = perform_sfs_cv_and_display(\n",
    "                preprocessor,\n",
    "                model,\n",
    "                name,\n",
    "                multiclass_results,\n",
    "                n_features=i,\n",
    "                direction=\"forward\",\n",
    "                fine_grained=False,\n",
    "            )\n",
    "\n",
    "            multiclass_feats[name].append(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by Validation_score and display\n",
    "display(pd.DataFrame(multiclass_results).sort_values(\"Validation_score\", 1, ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
