{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use es_core_news_md pipeline for POS tagging\n",
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density of Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density of pronouns - the proportion of pronouns in the text\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"\"Me llamo Darya y estoy una estudiante en la Universidad de Columbia Britanica.\n",
    "           Estudio ligüística computacional y ciencia de datos. \"\"\"\n",
    "\n",
    "# Extract POS tags\n",
    "# tokenize\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# types\n",
    "types = nltk.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me\n",
      "0.045454545454545456\n"
     ]
    }
   ],
   "source": [
    "# Pronoun proportion\n",
    "# Docstring:\n",
    "'''Returns the proportion of pronouns in the text, which is the number of pronouns divided \n",
    "   by the number of non pronouns in the text. '''\n",
    "doc = nlp(text)\n",
    "total_pron = 0\n",
    "\n",
    "\n",
    "for token in doc:\n",
    "    pos = token.pos_\n",
    "    if pos == 'PRON':\n",
    "        total_pron += 1\n",
    "    \n",
    "total_non_pron = len(tokens) - total_pron\n",
    "\n",
    "prop_pron = total_pron/total_non_pron\n",
    "\n",
    "print(prop_pron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of logical operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Docstring:\n",
    "'''Returns the percentage of logical operators from LOG_OPS in the text. '''\n",
    "\n",
    "LOG_OPS = {'si', 'y', 'o', 'u', 'no'} # if, and, or, not\n",
    "\n",
    "doc = nlp(text)\n",
    "total_log_ops = 0\n",
    "\n",
    "for token in doc:\n",
    "    if token.lower() in LOG_OPS:\n",
    "        total_log_ops += 1\n",
    "    \n",
    "total_non_log = len(tokens) - total_log_ops\n",
    "\n",
    "prop_log_ops = total_log_ops/total_non_log\n",
    "\n",
    "print(prop_log_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of connectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Docstring:\n",
    "''' Returns the percentage of connectives from CONNECTIVES in the text. Connectives are phrases that add clarifying, temporal or causal information. '''\n",
    "\n",
    "CONNECTIVES = {'por eso', 'a pesar de', 'además', 'y', 'también', 'incluso', \n",
    "              'pero', 'aunque', 'sin embargo', 'no obstante', 'porque', 'ya que',\n",
    "              'puesto que', 'debido a que', 'a causa de que', 'como', 'así',\n",
    "              'entonces', 'por lo tanto', 'en consecuencia', 'después', 'antes',\n",
    "              'al mismo tiempo', 'finalmente', 'al principio', 'por último', \n",
    "              'dado que', 'pese a', 'es decir', 'o sea', 'y luego', 'primero',\n",
    "              'todavía', 'aún', 'cuando', 'aunque', 'por consiguiente', 'consecuentemente',\n",
    "              'por otra parte', 'es decir', 'por lo visto', 'que yo sepa', 'de todas formas',\n",
    "              'de todas maneras', 'aparte de', 'tal como', 'a vez de', 'en concreto',\n",
    "              'en pocas palabras', 'tan pronto como', 'mientras tanto', 'hasta', 'por último',\n",
    "              'pues', 'en cuanto', 'por fin', 'al mismo tiempo', 'a la misma vez', 'inmediatamente',\n",
    "              'durante', 'eventualmente', 'frecuentemente', 'al rato', 'en primer lugar', \n",
    "              'anoche', 'luego', 'nunca', 'ahora', 'muchas veces', 'al otro día', 'desde entonces',\n",
    "              'raramente', 'algunas veces', 'pronto'}\n",
    "\n",
    "conn_count = 0\n",
    "\n",
    "for conn in CONNECTIVES:\n",
    "    if conn in text.lower():\n",
    "        conn_count += 1\n",
    "        \n",
    "print(conn_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
