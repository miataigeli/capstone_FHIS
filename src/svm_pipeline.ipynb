{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab929a5",
   "metadata": {},
   "source": [
    "# SVM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34605013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "import json\n",
    "from itertools import compress\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import SequentialFeatureSelector # requires sklearn 0.24 and above\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2b7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5778ca1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1fc1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and val data\n",
    "with open('../data/train_features.json', 'r') as f:\n",
    "    train_feat = json.load(f)\n",
    "with open('../data/val_features.json', 'r') as f:\n",
    "    val_feat = json.load(f)\n",
    "\n",
    "train_feat_df = pd.DataFrame(train_feat)\n",
    "val_feat_df = pd.DataFrame(val_feat)\n",
    "\n",
    "\n",
    "X_train = train_feat_df.drop(['level'], axis=1)\n",
    "X_val = val_feat_df.drop(['level'], axis=1)\n",
    "\n",
    "y_train = train_feat_df['level'].tolist()\n",
    "y_val = val_feat_df['level'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408c9d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_tokens_w/o_stopwords</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>proportion_of_A_level_tokens</th>\n",
       "      <th>proportion_of_A_level_types</th>\n",
       "      <th>num_connectives</th>\n",
       "      <th>logical_operator_density</th>\n",
       "      <th>pronoun_density</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>EOL</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>FUNCTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¡estoy encantada! desde esta mañana respiro el...</td>\n",
       "      <td>2585</td>\n",
       "      <td>1118</td>\n",
       "      <td>35.410959</td>\n",
       "      <td>0.339893</td>\n",
       "      <td>0.182550</td>\n",
       "      <td>18</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>0.047407</td>\n",
       "      <td>0.360155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.109865</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635376</td>\n",
       "      <td>0.364624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>era un mañana a fines del mes de abril. el bue...</td>\n",
       "      <td>1539</td>\n",
       "      <td>622</td>\n",
       "      <td>14.941748</td>\n",
       "      <td>0.326367</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>18</td>\n",
       "      <td>0.034970</td>\n",
       "      <td>0.067268</td>\n",
       "      <td>0.388564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.107862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621914</td>\n",
       "      <td>0.378086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a mi perro curro le gusta pasear por el parque...</td>\n",
       "      <td>159</td>\n",
       "      <td>70</td>\n",
       "      <td>22.714286</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>7</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>0.578616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en la ribera ven, sigue de la mano al que te a...</td>\n",
       "      <td>291</td>\n",
       "      <td>117</td>\n",
       "      <td>22.384615</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.189003</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.629787</td>\n",
       "      <td>0.370213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la vuelta a la patria mirad al peregrino10 ¡cu...</td>\n",
       "      <td>401</td>\n",
       "      <td>193</td>\n",
       "      <td>21.105263</td>\n",
       "      <td>0.295337</td>\n",
       "      <td>0.231250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.551122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.164589</td>\n",
       "      <td>0.022444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.654655</td>\n",
       "      <td>0.345345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   preprocessed_text  total_tokens  \\\n",
       "0  ¡estoy encantada! desde esta mañana respiro el...          2585   \n",
       "1  era un mañana a fines del mes de abril. el bue...          1539   \n",
       "2  a mi perro curro le gusta pasear por el parque...           159   \n",
       "3  en la ribera ven, sigue de la mano al que te a...           291   \n",
       "4  la vuelta a la patria mirad al peregrino10 ¡cu...           401   \n",
       "\n",
       "   total_tokens_w/o_stopwords  avg_sent_length  proportion_of_A_level_tokens  \\\n",
       "0                        1118        35.410959                      0.339893   \n",
       "1                         622        14.941748                      0.326367   \n",
       "2                          70        22.714286                      0.557143   \n",
       "3                         117        22.384615                      0.307692   \n",
       "4                         193        21.105263                      0.295337   \n",
       "\n",
       "   proportion_of_A_level_types  num_connectives  logical_operator_density  \\\n",
       "0                     0.182550               18                  0.050386   \n",
       "1                     0.214612               18                  0.034970   \n",
       "2                     0.395833                7                  0.039216   \n",
       "3                     0.250000                9                  0.043011   \n",
       "4                     0.231250                5                  0.046997   \n",
       "\n",
       "   pronoun_density  type_token_ratio  ...     PROPN     PUNCT     SCONJ  \\\n",
       "0         0.047407          0.360155  ...  0.011605  0.109865  0.032882   \n",
       "1         0.067268          0.388564  ...  0.010396  0.152697  0.038337   \n",
       "2         0.143885          0.578616  ...  0.012579  0.075472  0.025157   \n",
       "3         0.024648          0.580756  ...  0.013746  0.189003  0.034364   \n",
       "4         0.028205          0.551122  ...  0.019950  0.164589  0.022444   \n",
       "\n",
       "        SYM      VERB    X  EOL     SPACE   CONTENT  FUNCTION  \n",
       "0  0.000000  0.078530  0.0  0.0  0.000000  0.635376  0.364624  \n",
       "1  0.005198  0.107862  0.0  0.0  0.000000  0.621914  0.378086  \n",
       "2  0.000000  0.169811  0.0  0.0  0.000000  0.673469  0.326531  \n",
       "3  0.000000  0.089347  0.0  0.0  0.003436  0.629787  0.370213  \n",
       "4  0.000000  0.109726  0.0  0.0  0.004988  0.654655  0.345345  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Number of features: {len(X_train.columns)}')\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40733b8",
   "metadata": {},
   "source": [
    "## Model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183d30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = list(X_train.drop(['preprocessed_text'], axis=1).columns)\n",
    "\n",
    "scoring = ['accuracy']\n",
    "\n",
    "# dictionary to store results for comparison\n",
    "results_df = {}\n",
    "\n",
    "# tokenizer\n",
    "def tokenizer(text):\n",
    "    return [tok.text for tok in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfebc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_display(preprocessor, model, name, train_set, val_set, results_df):\n",
    "    '''\n",
    "    Construct a sklearn pipeline using the given preprocessor and model, then train the pipeline and return its validation results.\n",
    "    \n",
    "    preprocessor: (sklearn ColumnTransformer) sklearn object for feature transformation\n",
    "    model: (sklearn Classifier) initialized sklearn classifier\n",
    "    name: (str) a name that is shown when the result is displayed\n",
    "    train_set: (DataFrame) the input train set\n",
    "    val_set: (DataFrame) the input validation set\n",
    "    results_df: (dict) the dictionary to store validation results\n",
    "    \n",
    "    return: (dict) results_df\n",
    "    '''\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessor, model\n",
    "    )\n",
    "    \n",
    "    pipeline.fit(train_set, y_train)\n",
    "    y_pred_val = pipeline.predict(val_set)\n",
    "    \n",
    "    results_df[name] = {'train score': pipeline.score(train_set, y_train), 'validation score': accuracy_score(y_pred_val, y_val)}\n",
    "    \n",
    "    print('Classification report on validation:')\n",
    "    print(classification_report(y_pred_val, y_val))\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b1191",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "The baseline model only uses bag of word feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21dcaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.73      0.73        11\n",
      "          A2       0.00      0.00      0.00         0\n",
      "           B       1.00      0.71      0.83        21\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.58      0.48      0.52        32\n",
      "weighted avg       0.91      0.72      0.80        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train score</th>\n",
       "      <td>0.70428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation score</th>\n",
       "      <td>0.71875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SVM baseline\n",
       "train score            0.70428\n",
       "validation score       0.71875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_base = X_train['preprocessed_text']\n",
    "X_val_base = X_val['preprocessed_text']\n",
    "\n",
    "results_df = validate_and_display(CountVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), \n",
    "                                  SVC(random_state=123), \n",
    "                                  'SVM baseline', \n",
    "                                  X_train_base,\n",
    "                                  X_val_base,\n",
    "                                  results_df)\n",
    "display(pd.DataFrame(results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e2091",
   "metadata": {},
   "source": [
    "## Forward feature selection\n",
    "Use SequentialFeatureSelector from sklearn to perform forward and backward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8823f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the best validation score and the best train score to determine the current best model\n",
    "best_val_score = results_df['SVM baseline']['validation score']\n",
    "best_train_score = results_df['SVM baseline']['train score']\n",
    "best_feats = ['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9ee7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfs_and_validate(n_features, direction, results_df):\n",
    "    '''\n",
    "    Generate a feature selection pipeline for svm models, train the pipeline and store the validation results\n",
    "    \n",
    "    n_features: (int) argument passed into the `n_features_to_select` argument in SequentialFeatureSelector\n",
    "    direction: (str) {'forward', 'backward'}, argument passe dinto the direction argument in SequentialFeatureSelector\n",
    "    results_df: (dict) the dictionary to store validation results\n",
    "    \n",
    "    return: (dict) results_df\n",
    "    '''\n",
    "    numeric_features = feat_names\n",
    "    text_feature = 'preprocessed_text'\n",
    "    sfs_X_train = X_train.drop(['preprocessed_text'], axis=1)\n",
    "    \n",
    "    # initialize selector\n",
    "    sfs = SequentialFeatureSelector(SVC(random_state=123), n_features_to_select=n_features, scoring='accuracy', \n",
    "                                    direction=direction)\n",
    "    \n",
    "    sfs_preprocessor = make_column_transformer(\n",
    "        (StandardScaler(), numeric_features)\n",
    "    )\n",
    "    sfs_pipeline = make_pipeline(\n",
    "        sfs_preprocessor,\n",
    "        sfs,\n",
    "        SVC(random_state=123)\n",
    "    )\n",
    "    \n",
    "    # fit\n",
    "    sfs_pipeline.fit(sfs_X_train, y_train)\n",
    "    \n",
    "    # features selected\n",
    "    feats_selected = list(compress(sfs_X_train.columns, sfs_pipeline[1].get_support()))\n",
    "    print(f'features selected: {feats_selected}')\n",
    "    \n",
    "    # fit on selected features\n",
    "    val_preprocessor = make_column_transformer(\n",
    "        (StandardScaler(), feats_selected),\n",
    "        (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature)\n",
    "    )\n",
    "    \n",
    "    val_model = SVC(random_state=123)\n",
    "    \n",
    "    input_X_train = X_train[feats_selected+['preprocessed_text']]\n",
    "    input_X_val = X_val[feats_selected+['preprocessed_text']]\n",
    "    \n",
    "    results_df = validate_and_display(val_preprocessor, val_model, f'SVM + {n_features}', input_X_train, input_X_val, results_df)\n",
    "    return results_df, feats_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae1d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_sfs_and_pick(max_n_features, direction, results_df, best_val_score, best_train_score, best_feats, early_stop = 3):\n",
    "    '''\n",
    "    Loop and find best i features for all i <= max_n_features.\n",
    "    Append results and return the best scores along with the list of features selected.\n",
    "    \n",
    "    max_n_features: (int) the max number of features to select\n",
    "    direction: (str) {'forward', 'backward'}, argument passe dinto the direction argument in SequentialFeatureSelector\n",
    "    results_df: (dict) the dictionary to store validation results\n",
    "    best_val_score: (float) current best validation score obtained by a svm model\n",
    "    best_train_score: (float) current best train score obtained by a svm model\n",
    "    best_feats: (list) current list of features that the best model is trained on\n",
    "    early_stop: (int) should be < max_n_features. Break the loop if the performance does not improve for this many iterations. Default is 3\n",
    "    \n",
    "    return: (dict) results_df, (float) best_val_score, (float) best_train_score, (list) best_feats\n",
    "    '''\n",
    "    early_stop_count = 0\n",
    "    if direction == 'forward':\n",
    "        order = range(1, max_n_features+1)\n",
    "    else:\n",
    "        order = reversed(range(1, max_n_features))\n",
    "        \n",
    "    for i in order:\n",
    "        print(f'Picking the top {i} feature(s)')\n",
    "        results_df, feats = sfs_and_validate(i, direction, results_df)\n",
    "        \n",
    "        # update best scores if encounter a better model\n",
    "        print(f'Current best val score: {best_val_score}')\n",
    "        print(f'Current best train score: {best_train_score}')\n",
    "        \n",
    "        if results_df[f'SVM + {i}']['validation score'] > best_val_score: # better val score\n",
    "            early_stop_count = 0\n",
    "            \n",
    "            print('Found a better model, update best scores')\n",
    "            best_val_score = results_df[f'SVM + {i}']['validation score']\n",
    "            best_train_score = results_df[f'SVM + {i}']['train score']\n",
    "            best_feats = feats\n",
    "            print(f'Current best val score: {best_val_score}')\n",
    "            print(f'Current best train score: {best_train_score}')\n",
    "            \n",
    "        elif results_df[f'SVM + {i}']['validation score'] == best_val_score \\\n",
    "        and results_df[f'SVM + {i}']['train score'] < best_train_score: # same val score but less overfitting\n",
    "            early_stop_count = 0\n",
    "            \n",
    "            print('Found a better model, update best scores')\n",
    "            best_val_score = results_df[f'SVM + {i}']['validation score']\n",
    "            best_train_score = results_df[f'SVM + {i}']['train score']\n",
    "            best_feats = feats\n",
    "            print(f'Current best val score: {best_val_score}')\n",
    "            print(f'Current best train score: {best_train_score}')\n",
    "        else: # early stop mechanism\n",
    "            early_stop_count += 1\n",
    "            \n",
    "        print('--------------------')\n",
    "        if early_stop_count == early_stop:\n",
    "            break\n",
    "        \n",
    "    return results_df, best_val_score, best_train_score, best_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e944d3a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking the top 1 feature(s)\n",
      "features selected: ['syllables_per_sentence']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.75      0.78        12\n",
      "          A2       0.00      0.00      0.00         0\n",
      "           B       1.00      0.75      0.86        20\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.61      0.50      0.55        32\n",
      "weighted avg       0.93      0.75      0.83        32\n",
      "\n",
      "Current best val score: 0.71875\n",
      "Current best train score: 0.7042801556420234\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 2 feature(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features selected: ['proportion_of_A_level_types', 'syllables_per_sentence']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.64      0.64        11\n",
      "          A2       0.00      0.00      0.00         2\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.52      0.46      0.49        32\n",
      "weighted avg       0.77      0.66      0.71        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 3 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 4 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence', 'DET']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 5 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence', 'CONJ', 'DET']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 6 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence', 'CONJ', 'DET', 'X']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# forward search with early stop\n",
    "results_df, best_val_score_fwd, best_train_score_fwd, best_feats_fwd = loop_sfs_and_pick(len(feat_names), 'forward', results_df, \n",
    "                                                                             best_val_score, best_train_score, best_feats, early_stop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75564917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking the top 43 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_tokens', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.71875\n",
      "Current best train score: 0.7042801556420234\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8482490272373541\n",
      "--------------------\n",
      "Picking the top 42 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_tokens', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8482490272373541\n",
      "--------------------\n",
      "Picking the top 41 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8482490272373541\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 40 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 39 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 38 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 37 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 36 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 35 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 34 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 33 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 32 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 31 feature(s)\n",
      "features selected: ['total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# backward search with early stop\n",
    "results_df, best_val_score_bwd, best_train_score_bwd, best_feats_bwd = loop_sfs_and_pick(len(feat_names), 'backward', results_df, \n",
    "                                                                             best_val_score, best_train_score, best_feats, early_stop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "354fef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from forward search:\n",
      "Best validation score: 0.75\n",
      "Best train score: 0.8871595330739299\n",
      "Number of features selected: 1\n",
      "Features: ['syllables_per_sentence']\n",
      "--------------------\n",
      "Results from backward search:\n",
      "Best validation score: 0.75\n",
      "Best train score: 0.8404669260700389\n",
      "Number of features selected: 36\n",
      "Features: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n"
     ]
    }
   ],
   "source": [
    "# results from forward search\n",
    "print('Results from forward search:')\n",
    "print(f'Best validation score: {best_val_score_fwd}')\n",
    "print(f'Best train score: {best_train_score_fwd}')\n",
    "print(f'Number of features selected: {len(best_feats_fwd)}')\n",
    "print(f'Features: {best_feats_fwd}')\n",
    "\n",
    "print('--------------------')\n",
    "\n",
    "# results from backward search\n",
    "print('Results from backward search:')\n",
    "print(f'Best validation score: {best_val_score_bwd}')\n",
    "print(f'Best train score: {best_train_score_bwd}')\n",
    "print(f'Number of features selected: {len(best_feats_bwd)}')\n",
    "print(f'Features: {best_feats_bwd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f8b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two results and pick one from the two\n",
    "\n",
    "# if either one has better validation score than the other, then update best scores\n",
    "if best_val_score_fwd > best_val_score_bwd:\n",
    "    best_val_score = best_val_score_fwd\n",
    "    best_train_score = best_train_score_fwd\n",
    "    best_feats = best_feats_fwd\n",
    "elif best_val_score_fwd < best_val_score_bwd:\n",
    "    best_val_score = best_val_score_bwd\n",
    "    best_train_score = best_train_score_bwd\n",
    "    best_feats = best_feats_bwd\n",
    "else: # if they have equal val scores, store the less overfitting one\n",
    "    if best_train_score_fwd < best_train_score_bwd:\n",
    "        best_val_score = best_val_score_fwd\n",
    "        best_train_score = best_train_score_fwd\n",
    "        best_feats = best_feats_fwd\n",
    "    else:\n",
    "        best_val_score = best_val_score_bwd\n",
    "        best_train_score = best_train_score_bwd\n",
    "        best_feats = best_feats_bwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93aea9",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "004dd263",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = 'preprocessed_text'\n",
    "\n",
    "# best model input matrices\n",
    "best_X_train = X_train[best_feats+['preprocessed_text']]\n",
    "best_X_val = X_val[best_feats+['preprocessed_text']]\n",
    "\n",
    "# best model pipeline\n",
    "best_preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), best_feats),\n",
    "    (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature)\n",
    ")\n",
    "best_model = SVC(random_state=123)\n",
    "best_pipeline = make_pipeline(\n",
    "        best_preprocessor, best_model\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73944b97",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65c254ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test runability of hyperparameter tuning\n",
    "test_feats = ['syllables_per_sentence']\n",
    "\n",
    "test_X_train = X_train[test_feats+['preprocessed_text']]\n",
    "test_X_val = X_val[test_feats+['preprocessed_text']]\n",
    "\n",
    "\n",
    "test_preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), test_feats),\n",
    "    (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature)\n",
    ")\n",
    "test_model = SVC(random_state=123)\n",
    "test_pipeline = make_pipeline(\n",
    "        test_preprocessor, test_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8c206ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zP9jfTWTkaM",
    "outputId": "02691f47-d448-4518-a73e-ef0dd9856faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['syllables_per_sentence']),\n",
       "                                                                              ('tfidfvectorizer',\n",
       "                                                                               TfidfVectorizer(max_features=30000,\n",
       "                                                                                               ngram_range=(1,\n",
       "                                                                                                            2),\n",
       "                                                                                               tokenizer=<function tokenizer at 0x148d8f160>),\n",
       "                                                                               'preprocessed_text')])),\n",
       "                                             ('svc', SVC(random_state=123))]),\n",
       "                   n_iter=3, n_j...\n",
       "       1.0240e+03, 2.0480e+03, 4.0960e+03, 8.1920e+03, 1.6384e+04]),\n",
       "                                        'svc__gamma': array([3.05175781e-05, 6.10351562e-05, 1.22070312e-04, 2.44140625e-04,\n",
       "       4.88281250e-04, 9.76562500e-04, 1.95312500e-03, 3.90625000e-03,\n",
       "       7.81250000e-03, 1.56250000e-02, 3.12500000e-02, 6.25000000e-02,\n",
       "       1.25000000e-01, 2.50000000e-01, 5.00000000e-01, 1.00000000e+00,\n",
       "       2.00000000e+00, 4.00000000e+00])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gamma and C value range taken from https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "param_grid = {\n",
    "    \"svc__gamma\": 2.0 ** np.arange(-15, 3),\n",
    "    \"svc__C\": 2.0 ** np.arange(-5, 15)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(test_pipeline, ## best_pipeline\n",
    "                                   scoring='accuracy', \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_jobs=-1, \n",
    "                                   n_iter=3, \n",
    "                                   cv=2,\n",
    "                                   return_train_score=True,\n",
    "                                   verbose=10) # default n_iter=10\n",
    "random_search.fit(test_X_train, y_train) ## best_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "358b5bcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "BT1DKXKEZ2SZ",
    "outputId": "7f8c491d-b685-42ec-f3d5-ab46996c667d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.789971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>26.743917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.638233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>26.705437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.474715</td>\n",
       "      <td>0.474715</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.5</td>\n",
       "      <td>26.743209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score  mean_train_score param_svc__gamma  \\\n",
       "rank_test_score                                                       \n",
       "1                       0.789971          1.000000          0.03125   \n",
       "2                       0.638233          1.000000              4.0   \n",
       "3                       0.474715          0.474715         0.000488   \n",
       "\n",
       "                param_svc__C  mean_fit_time  \n",
       "rank_test_score                              \n",
       "1                     2048.0      26.743917  \n",
       "2                      128.0      26.705437  \n",
       "3                        0.5      26.743209  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\n",
    "        'mean_test_score',\n",
    "        'mean_train_score',\n",
    "        'param_svc__gamma',\n",
    "        'param_svc__C',\n",
    "        'mean_fit_time',\n",
    "        'rank_test_score',\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7b528",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWDgj66jU1Ts",
    "outputId": "3b8062dc-d736-4868-9432-dd4280fab555"
   },
   "outputs": [],
   "source": [
    "print(\"Random Search best hyperparameters: %s\" % (random_search.best_params_))\n",
    "print(\"Random Search best model score: %0.3f\" % (random_search.best_score_))\n",
    "print(\n",
    "    \"Train score on the full train set: %0.3f\" % (random_search.score(best_X_train, y_train))\n",
    ")\n",
    "print(\n",
    "    \"Validation score on the full validation set: %0.3f\" % (random_search.score(best_X_val, y_val))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb55226b",
   "metadata": {},
   "source": [
    "## Update best model, train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb9748b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train score         0.840467\n",
       "validation score    0.750000\n",
       "Name: SVM best, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if random_search.score(best_X_val, y_val) > best_val_score:\n",
    "    best_model = SVC(random_state=123, gamma=random_search.best_params_['svc__gamma'], C=random_search.best_params_['svc__C'])\n",
    "else:\n",
    "    best_model = SVC(random_state=123)\n",
    "results_df = validate_and_display(best_preprocessor, \n",
    "                                  best_model, \n",
    "                                  'SVM best', \n",
    "                                  best_X_train,\n",
    "                                  best_X_val,\n",
    "                                  results_df)\n",
    "display(pd.DataFrame(results_df)['SVM best'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2fc052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
