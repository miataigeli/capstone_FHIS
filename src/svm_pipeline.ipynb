{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d6c213",
   "metadata": {},
   "source": [
    "# SVM Pipeline\n",
    "This notebook is an end-to-end SVM pipeline that programmatically initializes a model, performs feature selection and hyperparameter tuning, and finally trains the best model and evaluate on the test set. Texts whose labels are wrongly predicted by the model are also extracted for output analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c6ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "import json\n",
    "from itertools import compress\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import SequentialFeatureSelector # requires sklearn 0.24 and above\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbce2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d939a3c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3750980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and val feature matrices\n",
    "with open('../data/train_features.json', 'r') as f:\n",
    "    train_feat = json.load(f)\n",
    "with open('../data/val_features.json', 'r') as f:\n",
    "    val_feat = json.load(f)\n",
    "\n",
    "train_feat_df = pd.DataFrame(train_feat)\n",
    "val_feat_df = pd.DataFrame(val_feat)\n",
    "\n",
    "\n",
    "X_train = train_feat_df.drop(['level'], axis=1)\n",
    "X_val = val_feat_df.drop(['level'], axis=1)\n",
    "\n",
    "y_train = train_feat_df['level'].tolist()\n",
    "y_val = val_feat_df['level'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11abc20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_tokens_w/o_stopwords</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>proportion_of_A_level_tokens</th>\n",
       "      <th>proportion_of_A_level_types</th>\n",
       "      <th>num_connectives</th>\n",
       "      <th>logical_operator_density</th>\n",
       "      <th>pronoun_density</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>EOL</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>FUNCTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¡estoy encantada! desde esta mañana respiro el...</td>\n",
       "      <td>2585</td>\n",
       "      <td>1118</td>\n",
       "      <td>35.410959</td>\n",
       "      <td>0.339893</td>\n",
       "      <td>0.182550</td>\n",
       "      <td>18</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>0.047407</td>\n",
       "      <td>0.360155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.109865</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635376</td>\n",
       "      <td>0.364624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>era un mañana a fines del mes de abril. el bue...</td>\n",
       "      <td>1539</td>\n",
       "      <td>622</td>\n",
       "      <td>14.941748</td>\n",
       "      <td>0.326367</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>18</td>\n",
       "      <td>0.034970</td>\n",
       "      <td>0.067268</td>\n",
       "      <td>0.388564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.107862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621914</td>\n",
       "      <td>0.378086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a mi perro curro le gusta pasear por el parque...</td>\n",
       "      <td>159</td>\n",
       "      <td>70</td>\n",
       "      <td>22.714286</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>7</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>0.578616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en la ribera ven, sigue de la mano al que te a...</td>\n",
       "      <td>291</td>\n",
       "      <td>117</td>\n",
       "      <td>22.384615</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.189003</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.629787</td>\n",
       "      <td>0.370213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la vuelta a la patria mirad al peregrino10 ¡cu...</td>\n",
       "      <td>401</td>\n",
       "      <td>193</td>\n",
       "      <td>21.105263</td>\n",
       "      <td>0.295337</td>\n",
       "      <td>0.231250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.551122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.164589</td>\n",
       "      <td>0.022444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.654655</td>\n",
       "      <td>0.345345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   preprocessed_text  total_tokens  \\\n",
       "0  ¡estoy encantada! desde esta mañana respiro el...          2585   \n",
       "1  era un mañana a fines del mes de abril. el bue...          1539   \n",
       "2  a mi perro curro le gusta pasear por el parque...           159   \n",
       "3  en la ribera ven, sigue de la mano al que te a...           291   \n",
       "4  la vuelta a la patria mirad al peregrino10 ¡cu...           401   \n",
       "\n",
       "   total_tokens_w/o_stopwords  avg_sent_length  proportion_of_A_level_tokens  \\\n",
       "0                        1118        35.410959                      0.339893   \n",
       "1                         622        14.941748                      0.326367   \n",
       "2                          70        22.714286                      0.557143   \n",
       "3                         117        22.384615                      0.307692   \n",
       "4                         193        21.105263                      0.295337   \n",
       "\n",
       "   proportion_of_A_level_types  num_connectives  logical_operator_density  \\\n",
       "0                     0.182550               18                  0.050386   \n",
       "1                     0.214612               18                  0.034970   \n",
       "2                     0.395833                7                  0.039216   \n",
       "3                     0.250000                9                  0.043011   \n",
       "4                     0.231250                5                  0.046997   \n",
       "\n",
       "   pronoun_density  type_token_ratio  ...     PROPN     PUNCT     SCONJ  \\\n",
       "0         0.047407          0.360155  ...  0.011605  0.109865  0.032882   \n",
       "1         0.067268          0.388564  ...  0.010396  0.152697  0.038337   \n",
       "2         0.143885          0.578616  ...  0.012579  0.075472  0.025157   \n",
       "3         0.024648          0.580756  ...  0.013746  0.189003  0.034364   \n",
       "4         0.028205          0.551122  ...  0.019950  0.164589  0.022444   \n",
       "\n",
       "        SYM      VERB    X  EOL     SPACE   CONTENT  FUNCTION  \n",
       "0  0.000000  0.078530  0.0  0.0  0.000000  0.635376  0.364624  \n",
       "1  0.005198  0.107862  0.0  0.0  0.000000  0.621914  0.378086  \n",
       "2  0.000000  0.169811  0.0  0.0  0.000000  0.673469  0.326531  \n",
       "3  0.000000  0.089347  0.0  0.0  0.003436  0.629787  0.370213  \n",
       "4  0.000000  0.109726  0.0  0.0  0.004988  0.654655  0.345345  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Number of features: {len(X_train.columns)}')\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68de178",
   "metadata": {},
   "source": [
    "## Model set up\n",
    "Define key variables for model set up. For this task, we consider accuracy as the main metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c54ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all linguistic features in the feature matrix\n",
    "feat_names = list(X_train.drop(['preprocessed_text'], axis=1).columns)\n",
    "\n",
    "scoring = ['accuracy']\n",
    "\n",
    "# dictionary to store results for comparison\n",
    "results_df = {}\n",
    "\n",
    "# tokenizer used by sklearn vectorizers\n",
    "def tokenizer(text):\n",
    "    return [tok.text for tok in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501e3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_display(preprocessor, model, name, train_set, val_set, results_df):\n",
    "    '''\n",
    "    Construct a sklearn pipeline using the given preprocessor and model, then train the pipeline and return its validation results.\n",
    "    \n",
    "    preprocessor: (sklearn ColumnTransformer) sklearn object for feature transformation\n",
    "    model: (sklearn Classifier) initialized sklearn classifier\n",
    "    name: (str) a name that is shown when the result is displayed\n",
    "    train_set: (DataFrame) the input train set\n",
    "    val_set: (DataFrame) the input validation set\n",
    "    results_df: (dict) the dictionary to store validation results\n",
    "    \n",
    "    return: (dict) results_df\n",
    "    '''\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessor, model\n",
    "    )\n",
    "    \n",
    "    pipeline.fit(train_set, y_train)\n",
    "    y_pred_val = pipeline.predict(val_set)\n",
    "    \n",
    "    results_df[name] = {'train score': pipeline.score(train_set, y_train), 'validation score': accuracy_score(y_pred_val, y_val)}\n",
    "    \n",
    "    print('Classification report on validation:')\n",
    "    print(classification_report(y_pred_val, y_val))\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d308f18",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "The baseline model only uses bag of word feature. We use the baseline model to obtain baseline accuracy for this classification task, so that when we encounter better performing model during the feature selection step, we would have something to compare to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0e9267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.73      0.73        11\n",
      "          A2       0.00      0.00      0.00         0\n",
      "           B       1.00      0.71      0.83        21\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.58      0.48      0.52        32\n",
      "weighted avg       0.91      0.72      0.80        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train score</th>\n",
       "      <td>0.70428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation score</th>\n",
       "      <td>0.71875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SVM baseline\n",
       "train score            0.70428\n",
       "validation score       0.71875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_base = X_train['preprocessed_text']\n",
    "X_val_base = X_val['preprocessed_text']\n",
    "\n",
    "results_df = validate_and_display(CountVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), \n",
    "                                  SVC(random_state=123), \n",
    "                                  'SVM baseline', \n",
    "                                  X_train_base,\n",
    "                                  X_val_base,\n",
    "                                  results_df)\n",
    "display(pd.DataFrame(results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726cadb",
   "metadata": {},
   "source": [
    "## Forward feature selection\n",
    "Use SequentialFeatureSelector from sklearn to perform forward and backward feature selection. Earlystopping is implemented to increase efficiency. Both forward and backward feature selection were executed so that we can get a sense of which features are the most useful and which are the least useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e20de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the best validation score and the best train score to determine the current best model\n",
    "# currently set to the baseline score\n",
    "best_val_score = results_df['SVM baseline']['validation score']\n",
    "best_train_score = results_df['SVM baseline']['train score']\n",
    "best_feats = ['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96ce2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfs_and_validate(n_features, direction, results_df):\n",
    "    '''\n",
    "    Generate a feature selection pipeline for a single svm model, train the pipeline and store the validation results\n",
    "    \n",
    "    n_features: (int) argument passed into the `n_features_to_select` argument in SequentialFeatureSelector\n",
    "    direction: (str) {'forward', 'backward'}, argument passe dinto the direction argument in SequentialFeatureSelector\n",
    "    results_df: (dict) the dictionary to store validation results\n",
    "    \n",
    "    return: (dict) results_df\n",
    "    '''\n",
    "    numeric_features = feat_names\n",
    "    text_feature = 'preprocessed_text'\n",
    "    sfs_X_train = X_train.drop(['preprocessed_text'], axis=1)\n",
    "    \n",
    "    # initialize selector\n",
    "    sfs = SequentialFeatureSelector(SVC(random_state=123), n_features_to_select=n_features, scoring='accuracy', \n",
    "                                    direction=direction)\n",
    "    \n",
    "    sfs_preprocessor = make_column_transformer(\n",
    "        (StandardScaler(), numeric_features)\n",
    "    )\n",
    "    sfs_pipeline = make_pipeline(\n",
    "        sfs_preprocessor,\n",
    "        sfs,\n",
    "        SVC(random_state=123)\n",
    "    )\n",
    "    \n",
    "    # fit\n",
    "    sfs_pipeline.fit(sfs_X_train, y_train)\n",
    "    \n",
    "    # features selected\n",
    "    feats_selected = list(compress(sfs_X_train.columns, sfs_pipeline[1].get_support()))\n",
    "    print(f'features selected: {feats_selected}')\n",
    "    \n",
    "    # fit on selected features\n",
    "    val_preprocessor = make_column_transformer(\n",
    "        (StandardScaler(), feats_selected),\n",
    "        (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature)\n",
    "    )\n",
    "    \n",
    "    val_model = SVC(random_state=123)\n",
    "    \n",
    "    input_X_train = X_train[feats_selected+['preprocessed_text']]\n",
    "    input_X_val = X_val[feats_selected+['preprocessed_text']]\n",
    "    \n",
    "    results_df = validate_and_display(val_preprocessor, val_model, f'SVM + {n_features}', input_X_train, input_X_val, results_df)\n",
    "    return results_df, feats_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abb10a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_sfs_and_pick(max_n_features, direction, results_df, best_val_score, best_train_score, best_feats, early_stop = 3):\n",
    "    '''\n",
    "    Loop and find best i features for all i <= max_n_features.\n",
    "    Append results and return the best scores along with the list of features selected.\n",
    "    \n",
    "    max_n_features: (int) the max number of features to select\n",
    "    direction: (str) {'forward', 'backward'}, argument passe dinto the direction argument in SequentialFeatureSelector\n",
    "    results_df: (dict) the dictionary to store validation results\n",
    "    best_val_score: (float) current best validation score obtained by a svm model\n",
    "    best_train_score: (float) current best train score obtained by a svm model\n",
    "    best_feats: (list) current list of features that the best model is trained on\n",
    "    early_stop: (int) should be < max_n_features. Break the loop if the performance does not improve for this many iterations. Default is 3\n",
    "    \n",
    "    return: (dict) results_df, (float) best_val_score, (float) best_train_score, (list) best_feats\n",
    "    '''\n",
    "    early_stop_count = 0\n",
    "    if direction == 'forward':\n",
    "        order = range(1, max_n_features+1)\n",
    "    else:\n",
    "        order = reversed(range(1, max_n_features))\n",
    "        \n",
    "    for i in order:\n",
    "        print(f'Picking the top {i} feature(s)')\n",
    "        results_df, feats = sfs_and_validate(i, direction, results_df)\n",
    "        \n",
    "        # update best scores if encounter a better model\n",
    "        print(f'Current best val score: {best_val_score}')\n",
    "        print(f'Current best train score: {best_train_score}')\n",
    "        \n",
    "        if results_df[f'SVM + {i}']['validation score'] > best_val_score: # better val score\n",
    "            early_stop_count = 0\n",
    "            \n",
    "            print('Found a better model, update best scores')\n",
    "            best_val_score = results_df[f'SVM + {i}']['validation score']\n",
    "            best_train_score = results_df[f'SVM + {i}']['train score']\n",
    "            best_feats = feats\n",
    "            print(f'Current best val score: {best_val_score}')\n",
    "            print(f'Current best train score: {best_train_score}')\n",
    "            \n",
    "        elif results_df[f'SVM + {i}']['validation score'] == best_val_score \\\n",
    "        and results_df[f'SVM + {i}']['train score'] < best_train_score: # same val score but less overfitting\n",
    "            early_stop_count = 0\n",
    "            \n",
    "            print('Found a better model, update best scores')\n",
    "            best_val_score = results_df[f'SVM + {i}']['validation score']\n",
    "            best_train_score = results_df[f'SVM + {i}']['train score']\n",
    "            best_feats = feats\n",
    "            print(f'Current best val score: {best_val_score}')\n",
    "            print(f'Current best train score: {best_train_score}')\n",
    "        else: # early stop mechanism\n",
    "            early_stop_count += 1\n",
    "            \n",
    "        print('--------------------')\n",
    "        if early_stop_count == early_stop:\n",
    "            break\n",
    "        \n",
    "    return results_df, best_val_score, best_train_score, best_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2872b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking the top 1 feature(s)\n",
      "features selected: ['syllables_per_sentence']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.75      0.78        12\n",
      "          A2       0.00      0.00      0.00         0\n",
      "           B       1.00      0.75      0.86        20\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.61      0.50      0.55        32\n",
      "weighted avg       0.93      0.75      0.83        32\n",
      "\n",
      "Current best val score: 0.71875\n",
      "Current best train score: 0.7042801556420234\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 2 feature(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features selected: ['proportion_of_A_level_types', 'syllables_per_sentence']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.64      0.64        11\n",
      "          A2       0.00      0.00      0.00         2\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.52      0.46      0.49        32\n",
      "weighted avg       0.77      0.66      0.71        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 3 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 4 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence', 'DET']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 5 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence', 'CONJ', 'DET']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n",
      "Picking the top 6 feature(s)\n",
      "features selected: ['proportion_of_A_level_types', 'num_connectives', 'syllables_per_sentence', 'CONJ', 'DET', 'X']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.64      0.70      0.67        10\n",
      "          A2       0.17      1.00      0.29         1\n",
      "           B       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.58      0.79      0.58        32\n",
      "weighted avg       0.82      0.69      0.73        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8871595330739299\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# forward search with early stop\n",
    "results_df, best_val_score_fwd, best_train_score_fwd, best_feats_fwd = loop_sfs_and_pick(len(feat_names), 'forward', results_df, \n",
    "                                                                             best_val_score, best_train_score, best_feats, early_stop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d36b7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking the top 43 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_tokens', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.71875\n",
      "Current best train score: 0.7042801556420234\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8482490272373541\n",
      "--------------------\n",
      "Picking the top 42 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_tokens', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8482490272373541\n",
      "--------------------\n",
      "Picking the top 41 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8482490272373541\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 40 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'pronoun_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 39 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'type_token_ratio', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 38 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'SPACE', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 37 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'avg_ambiguation_content_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "--------------------\n",
      "Picking the top 36 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8443579766536965\n",
      "Found a better model, update best scores\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 35 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 34 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 33 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'EOL', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 32 feature(s)\n",
      "features selected: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.73      0.80      0.76        10\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.74      0.82        19\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.61      0.62      0.60        32\n",
      "weighted avg       0.80      0.72      0.75        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n",
      "Picking the top 31 feature(s)\n",
      "features selected: ['total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'CONTENT', 'FUNCTION']\n",
      "Classification report on validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.82      0.82      0.82        11\n",
      "          A2       0.17      0.33      0.22         3\n",
      "           B       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.64      0.64      0.63        32\n",
      "weighted avg       0.82      0.75      0.78        32\n",
      "\n",
      "Current best val score: 0.75\n",
      "Current best train score: 0.8404669260700389\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# backward search with early stop\n",
    "results_df, best_val_score_bwd, best_train_score_bwd, best_feats_bwd = loop_sfs_and_pick(len(feat_names), 'backward', results_df, \n",
    "                                                                             best_val_score, best_train_score, best_feats, early_stop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fcec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from forward search:\n",
      "Best validation score: 0.75\n",
      "Best train score: 0.8871595330739299\n",
      "Number of features selected: 1\n",
      "Features: ['syllables_per_sentence']\n",
      "--------------------\n",
      "Results from backward search:\n",
      "Best validation score: 0.75\n",
      "Best train score: 0.8404669260700389\n",
      "Number of features selected: 36\n",
      "Features: ['total_tokens', 'total_tokens_w/o_stopwords', 'avg_sent_length', 'proportion_of_A_level_types', 'num_connectives', 'logical_operator_density', 'avg_rank_of_lemmas_in_freq_list', 'fernandez_huerta_score', 'syllables_per_sentence', 'avg_degree_of_abstraction', 'min_degree_of_abstraction', 'avg_ambiguation_all_words', 'noun_phrase_density', 'avg_parse_tree_depth', 'Imp', 'Past', 'Pres', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'VERB', 'X', 'EOL', 'CONTENT', 'FUNCTION']\n"
     ]
    }
   ],
   "source": [
    "# results from forward search\n",
    "print('Results from forward search:')\n",
    "print(f'Best validation score: {best_val_score_fwd}')\n",
    "print(f'Best train score: {best_train_score_fwd}')\n",
    "print(f'Number of features selected: {len(best_feats_fwd)}')\n",
    "print(f'Features: {best_feats_fwd}')\n",
    "\n",
    "print('--------------------')\n",
    "\n",
    "# results from backward search\n",
    "print('Results from backward search:')\n",
    "print(f'Best validation score: {best_val_score_bwd}')\n",
    "print(f'Best train score: {best_train_score_bwd}')\n",
    "print(f'Number of features selected: {len(best_feats_bwd)}')\n",
    "print(f'Features: {best_feats_bwd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08ef70",
   "metadata": {},
   "source": [
    "We see that forward search and backward search give 2 different set of features. Hence by comparing the train and validation scores of both models we can pick the best one to carry forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f6ae6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two results and pick one from the two\n",
    "\n",
    "# if either one has better validation score than the other, then update best scores\n",
    "if best_val_score_fwd > best_val_score_bwd:\n",
    "    best_val_score = best_val_score_fwd\n",
    "    best_train_score = best_train_score_fwd\n",
    "    best_feats = best_feats_fwd\n",
    "elif best_val_score_fwd < best_val_score_bwd:\n",
    "    best_val_score = best_val_score_bwd\n",
    "    best_train_score = best_train_score_bwd\n",
    "    best_feats = best_feats_bwd\n",
    "else: # if they have equal val scores, store the less overfitting one\n",
    "    if best_train_score_fwd < best_train_score_bwd:\n",
    "        best_val_score = best_val_score_fwd\n",
    "        best_train_score = best_train_score_fwd\n",
    "        best_feats = best_feats_fwd\n",
    "    else:\n",
    "        best_val_score = best_val_score_bwd\n",
    "        best_train_score = best_train_score_bwd\n",
    "        best_feats = best_feats_bwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecdc274",
   "metadata": {},
   "source": [
    "## Best model\n",
    "Construct the pipeline for the best model. This inlcudes constructing the preprocessor, the model, as well as subsetting the feature matrices so that only the features that the best model used above are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f1bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = 'preprocessed_text'\n",
    "\n",
    "# best model input matrices\n",
    "best_X_train = X_train[best_feats+['preprocessed_text']]\n",
    "best_X_val = X_val[best_feats+['preprocessed_text']]\n",
    "\n",
    "# best model pipeline\n",
    "best_preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), best_feats),\n",
    "    (TfidfVectorizer(max_features=30_000, ngram_range=(1,2), tokenizer=tokenizer), text_feature)\n",
    ")\n",
    "best_model = SVC(random_state=123)\n",
    "best_pipeline = make_pipeline(\n",
    "    best_preprocessor, best_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54955da2",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "Perform hyperparameter tuning for the best model. Random search is used for this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c13e4b1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zP9jfTWTkaM",
    "outputId": "02691f47-d448-4518-a73e-ef0dd9856faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['total_tokens',\n",
       "                                                                                'total_tokens_w/o_stopwords',\n",
       "                                                                                'avg_sent_length',\n",
       "                                                                                'proportion_of_A_level_types',\n",
       "                                                                                'num_connectives',\n",
       "                                                                                'logical_operator_density',\n",
       "                                                                                'avg_rank_of_lemmas_in_freq_list',\n",
       "                                                                                'fernandez_huerta_score',\n",
       "                                                                                'syllables_per_...\n",
       "       1.0240e+03, 2.0480e+03, 4.0960e+03, 8.1920e+03, 1.6384e+04]),\n",
       "                                        'svc__gamma': array([3.05175781e-05, 6.10351562e-05, 1.22070312e-04, 2.44140625e-04,\n",
       "       4.88281250e-04, 9.76562500e-04, 1.95312500e-03, 3.90625000e-03,\n",
       "       7.81250000e-03, 1.56250000e-02, 3.12500000e-02, 6.25000000e-02,\n",
       "       1.25000000e-01, 2.50000000e-01, 5.00000000e-01, 1.00000000e+00,\n",
       "       2.00000000e+00, 4.00000000e+00])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gamma and C value range taken from https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "param_grid = {\n",
    "    \"svc__gamma\": 2.0 ** np.arange(-15, 3),\n",
    "    \"svc__C\": 2.0 ** np.arange(-5, 15)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(best_pipeline, \n",
    "                                   scoring='accuracy', \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_jobs=-1, \n",
    "                                   n_iter=15, \n",
    "                                   cv=3,\n",
    "                                   return_train_score=True,\n",
    "                                   verbose=10) # default n_iter=10\n",
    "random_search.fit(best_X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f58bc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "BT1DKXKEZ2SZ",
    "outputId": "7f8c491d-b685-42ec-f3d5-ab46996c667d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.712358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>512.0</td>\n",
       "      <td>35.769719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.712175</td>\n",
       "      <td>0.785960</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.514553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.712175</td>\n",
       "      <td>0.780124</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>512.0</td>\n",
       "      <td>35.420227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712130</td>\n",
       "      <td>0.708214</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.414597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.712084</td>\n",
       "      <td>0.838479</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.121992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.704378</td>\n",
       "      <td>0.717916</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.240456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.501870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>33.723986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>29.560305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>0.474704</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>30.635491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>0.474704</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.125</td>\n",
       "      <td>32.992850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>0.474704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>33.658160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.660548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.261426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>0.474704</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>30.768484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.474692</td>\n",
       "      <td>0.474704</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25.905232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score  mean_train_score param_svc__gamma  \\\n",
       "rank_test_score                                                       \n",
       "1                       0.712358          1.000000           0.0625   \n",
       "2                       0.712175          0.785960         0.001953   \n",
       "2                       0.712175          0.780124         0.000031   \n",
       "4                       0.712130          0.708214         0.000122   \n",
       "5                       0.712084          0.838479         0.007812   \n",
       "6                       0.704378          0.717916         0.000244   \n",
       "7                       0.501870          1.000000              0.5   \n",
       "8                       0.474692          1.000000              4.0   \n",
       "8                       0.474692          0.474704           0.0625   \n",
       "8                       0.474692          0.474704         0.000977   \n",
       "8                       0.474692          0.474704              1.0   \n",
       "8                       0.474692          1.000000              4.0   \n",
       "8                       0.474692          1.000000              1.0   \n",
       "8                       0.474692          0.474704         0.015625   \n",
       "8                       0.474692          0.474704         0.000031   \n",
       "\n",
       "                param_svc__C  mean_fit_time  \n",
       "rank_test_score                              \n",
       "1                      512.0      35.769719  \n",
       "2                        8.0      33.514553  \n",
       "2                      512.0      35.420227  \n",
       "4                       16.0      35.414597  \n",
       "5                        4.0      33.121992  \n",
       "6                       16.0      29.240456  \n",
       "7                     2048.0      33.723986  \n",
       "8                      256.0      29.560305  \n",
       "8                    0.03125      30.635491  \n",
       "8                      0.125      32.992850  \n",
       "8                     0.0625      33.658160  \n",
       "8                       16.0      35.660548  \n",
       "8                        1.0      35.261426  \n",
       "8                    0.03125      30.768484  \n",
       "8                       0.25      25.905232  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\n",
    "        'mean_test_score',\n",
    "        'mean_train_score',\n",
    "        'param_svc__gamma',\n",
    "        'param_svc__C',\n",
    "        'mean_fit_time',\n",
    "        'rank_test_score',\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfe73a1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWDgj66jU1Ts",
    "outputId": "3b8062dc-d736-4868-9432-dd4280fab555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search best hyperparameters: {'svc__gamma': 0.0625, 'svc__C': 512.0}\n",
      "Random Search best model score: 0.712\n",
      "Train score on the full train set: 1.000\n",
      "Validation score on the full validation set: 0.781\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Search best hyperparameters: %s\" % (random_search.best_params_))\n",
    "print(\"Random Search best model score: %0.3f\" % (random_search.best_score_))\n",
    "print(\n",
    "    \"Train score on the full train set: %0.3f\" % (random_search.score(best_X_train, y_train))\n",
    ")\n",
    "print(\n",
    "    \"Validation score on the full validation set: %0.3f\" % (random_search.score(best_X_val, y_val))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e9b11",
   "metadata": {},
   "source": [
    "## Update best model, train and evaluate\n",
    "Re-initialize the best model with the hyperparameter values obtained from the random search. Then train the model on the train set, evaluate on both the validation set and the test set. In the end, save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f9168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation score\n",
    "if random_search.score(best_X_val, y_val) > best_val_score:\n",
    "    best_model = SVC(random_state=123, gamma=random_search.best_params_['svc__gamma'], C=random_search.best_params_['svc__C'])\n",
    "else:\n",
    "    best_model = SVC(random_state=123)\n",
    "    \n",
    "best_pipeline = make_pipeline(\n",
    "        best_preprocessor, best_model\n",
    "    )\n",
    "best_pipeline.fit(best_X_train, y_train)\n",
    "    \n",
    "results_df['SVM best'] = {'train score': best_pipeline.score(best_X_train, y_train), \n",
    "                          'validation score': best_pipeline.score(best_X_val, y_val)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "592315f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test score\n",
    "with open('../data/test_features.json', 'r') as f:\n",
    "    test_feat = json.load(f)\n",
    "\n",
    "test_feat_df = pd.DataFrame(test_feat)\n",
    "\n",
    "X_test = test_feat_df.drop(['level'], axis=1)[best_feats+['preprocessed_text']]\n",
    "y_test = test_feat_df['level'].tolist()\n",
    "\n",
    "results_df['SVM best']['test score'] = best_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f14fe4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train score</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation score</th>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test score</th>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SVM best\n",
       "train score        1.00000\n",
       "validation score   0.78125\n",
       "test score         0.78125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results_df)[['SVM best']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dbe1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "best_model_trained = best_pipeline[1]\n",
    "pickle.dump(best_model_trained, open('../models/svm_best_0613', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58990d36",
   "metadata": {},
   "source": [
    "## Output analysis\n",
    "Printout the texts that the model gave wrong labels to, also print out the predicted label as well as the gold label.\n",
    "\n",
    "Some observation:\n",
    "- In the dataset, the A2 class has the least number of texts (in the train set, A1:A2:B ratio is 85:50:122). We would expect that the model might be predicting many A2 level text as other levels because it was not exposed to enough of A2 level text. However, this is **not** the case. Out of the 7 wrongly predicted texts, the model mispredicted 4 A1 level texts and 2 A2 level texts.\n",
    "- The model is predicting 5 out of the 7 mispredicted texts a label that is either one level higher or one level lower than the gold label. This potentially indicates the vagueness when assignment a text to a specific level, and the model is not able to grasp the small nuance in a text that is potentially in between levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cf3c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = best_pipeline.predict(best_X_val)\n",
    "assert len(y_pred_val) == len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a829ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: tres palabras un jornalero pobre llegó por la noche a una posada. estaba muy cansado y tenía hambre y sed. pero no tenía dinero. sin dinero no pudo obtener nada. ¿cómo obtener dinero para comer? se sentó a una mesa. a la mesa estaban sentados dos panaderos que comían y bebían. el jornalero les contaba de sus viajes. su cuento era muy interesante y ellos lo escuchaban atentamente. finalmente él les dijo: —- propongo una apuesta. diré tres palabras que vds. no pueden repetir. —es absurdo,—contesta...\n",
      "Predicted: A1\n",
      "Gold: A2\n",
      "-----------\n",
      "Text: me llamo elena sánchez y viajé a roma por primera vez hace seis años, en 2011. visité la ciudad italiana con mi novio durante cinco días. lo que más nos gustó fue el coliseo, pero también estuvimos en la fontana di trevi y en el vaticano. el momento más divertido del viaje fue cuando estábamos dando un paseo por el barrio del trastévere y entramos en una tienda de mascotas para comprar una tortuga. ¡siete años después, aún es nuestra mascota! mi novio y yo hemos planeado volver a de vacaciones a...\n",
      "Predicted: A2\n",
      "Gold: B\n",
      "-----------\n",
      "Text: vivo en un pueblo muy pequeño cercano a la montaña, donde hay un lago precioso en donde es habitual ver patos y cisnes nadando. es un lugar muy bonito para pasear y disfrutar de la vida en el campo, pero existen pequeñas incomodidades al existir pocos servicios. en el pueblo solo hay una pequeña tienda de ultramarinos en donde se venden productos de primera necesidad. cuando se necesita ir al médico hay que desplazarse a otro pueblo más grande situado a quince kilómetros, donde hay un centro méd...\n",
      "Predicted: B\n",
      "Gold: A1\n",
      "-----------\n",
      "Text: había una vez un hombre que cortaba piedras de una roca. su trabajo era largo y penoso, y muy mezquino en su salario, por lo que suspiraba tristemente. un día, cansado de su ruda tarea, exclamó: —¡oh! ¿por qué no seré yo bastante rico para pasar la vida tumbado sobre un blando lecho, provisto de cortinas que me libren de los mosquitos? entonces un ángel descendió del cielo y le dijo: —que tu deseo sea satisfecho. y el hombre fue rico, y reposaba en blando lecho, provisto de cortinas de seda roja...\n",
      "Predicted: B\n",
      "Gold: A1\n",
      "-----------\n",
      "Text: el brasil el brasil tiene cuatro veces la extensión de méjico. es casi tan grande como los estados unidos de américa, pero tiene solamente una quinta parte de su población. la mayor parte del brasil no está poblada, porque está cubierta de densas selvas. la vegetación tropical abunda en estas selvas. la mayor parte de la población se halla en la costa sudeste. en las selvas del brasil se encuentran casi todas las plantas tropicales y los animales de la américa del sur. hay más de variedades de p...\n",
      "Predicted: B\n",
      "Gold: A2\n",
      "-----------\n",
      "Text: capítulo el profesor se pone las gafas y coge unos papeles. —el tema más votado —dice— para el crédito de síntesis es «sitges». —¡bieeennn! —los alumnos están contentos. —tenéis toda la semana para preparar el tema —continúa el profesor—. esto es lo que tenéis que hacer para cada asignatura —el profesor empieza a leer—: en ciencias sociales, vais a estudiar el crecimiento de la población y la inmigración. en arte y literatura, vamos a estudiar a santiago rusiñol. —¡profesor! —un alumno levanta l...\n",
      "Predicted: A2\n",
      "Gold: A1\n",
      "-----------\n",
      "Text: d. pedro gómez de aguilar tenía una magnífica finca cerca de la ciudad de cabra. un día del mes de noviembre le avisaron que sus colonos habían abandonado la finca a causa de una invasión de los moros. d. pedro no podía creer las noticias y sin decir nada a sus hijos, montó a caballo y se fue a la finca para informarse del suceso. llovía a cántaros y no vio a nadie en el camino. al llegar a su finca no vio a nadie tampoco y creía que ya se habían ido los moros. algunos momentos después se vio ro...\n",
      "Predicted: A2\n",
      "Gold: A1\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_val)):\n",
    "    if y_pred_val[i] != y_val[i]:\n",
    "        print(f'Text: {best_X_val[\"preprocessed_text\"][i][:500]}...')\n",
    "        print(f'Predicted: {y_pred_val[i]}')\n",
    "        print(f'Gold: {y_val[i]}')\n",
    "        print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27817360",
   "metadata": {},
   "source": [
    "## Save test prediction to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce8f2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_pipeline.predict(X_test)\n",
    "assert len(y_pred_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9951f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {'test_text':[], 'prediction':[], 'gold':[]}\n",
    "for i in range(len(y_test)):\n",
    "    output_dict['test_text'].append(X_test['preprocessed_text'][i])\n",
    "    output_dict['prediction'].append(y_pred_test[i])\n",
    "    output_dict['gold'].append(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "697f81cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capítulo —¡paren ya de pelearse! —el hombre al...</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¡es con voz de la biblia, o verso de walt whit...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>los cuatro hermanos un zapatero tenía cuatro h...</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una mañana entró un caballero en la tienda de ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>había un viejo que tenía una hija muy hermosa....</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           test_text prediction gold\n",
       "0  capítulo —¡paren ya de pelearse! —el hombre al...         A1   A1\n",
       "1  ¡es con voz de la biblia, o verso de walt whit...          B    B\n",
       "2  los cuatro hermanos un zapatero tenía cuatro h...         A2   A2\n",
       "3  una mañana entró un caballero en la tienda de ...         A1   A1\n",
       "4  había un viejo que tenía una hija muy hermosa....         A1   A1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output_dict).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54d922d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../predictions/svm_test_pred.json\", \"w\", encoding=\"utf-8\") as fout:\n",
    "    json.dump(output_dict, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c7d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
