{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMiyDaPBYnYMPusP2AmRcaS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54f4c2ff937242c5a64538ae4313b944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be39cb44c9654d06b654120beb4cbdca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ebf0d8c5dd14ef1937415da488da51d",
              "IPY_MODEL_9c926412c6694c7a90bf06d9cd59d390"
            ]
          }
        },
        "be39cb44c9654d06b654120beb4cbdca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ebf0d8c5dd14ef1937415da488da51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63eafc38297a40a9a348118d014b03e2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc2996d5698b4dcb99179aab925c13fe"
          }
        },
        "9c926412c6694c7a90bf06d9cd59d390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d41c484d49294e2ba7eacbe88a66bac1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 1.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7104195be4194211bd9c382ccf42ebf2"
          }
        },
        "63eafc38297a40a9a348118d014b03e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc2996d5698b4dcb99179aab925c13fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d41c484d49294e2ba7eacbe88a66bac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7104195be4194211bd9c382ccf42ebf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7553e8fba4494dd8a4e3cc1078f1fc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb50a4418bb749a291e639ac446799bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b87cacf947b541c186150d7aecaa8e56",
              "IPY_MODEL_92220c9762ea47b4908f3fe39cd1c565"
            ]
          }
        },
        "fb50a4418bb749a291e639ac446799bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b87cacf947b541c186150d7aecaa8e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83607825f23c4904a7f2578ff1e94492",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1961828,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1961828,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29d7b060eff74adb91af36bc7e8a5fe3"
          }
        },
        "92220c9762ea47b4908f3fe39cd1c565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef63bacd30fa462193434ca1719904a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.96M/1.96M [01:00&lt;00:00, 32.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_731ece8baf364363af1d1e45d503a3ea"
          }
        },
        "83607825f23c4904a7f2578ff1e94492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29d7b060eff74adb91af36bc7e8a5fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef63bacd30fa462193434ca1719904a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "731ece8baf364363af1d1e45d503a3ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9b08eaff763485cb4b526fdd2757a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_548049a87dec4d908dc0b863528510e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d378c75c9904b5f96afb4688a887697",
              "IPY_MODEL_7aab3e1436034eb69a3beab8c9e7ccc1"
            ]
          }
        },
        "548049a87dec4d908dc0b863528510e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d378c75c9904b5f96afb4688a887697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c7bd537826a4305a226dc88cfbf0cbf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8eb87d09b17c418b90a2945d5d7a5619"
          }
        },
        "7aab3e1436034eb69a3beab8c9e7ccc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7029225c2711492c8e93ca8739c32831",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 39.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_faaedacf3def488f8e6ee7331b92726a"
          }
        },
        "6c7bd537826a4305a226dc88cfbf0cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8eb87d09b17c418b90a2945d5d7a5619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7029225c2711492c8e93ca8739c32831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "faaedacf3def488f8e6ee7331b92726a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a5a0582d3a34ee198cd1051525a550e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af332db1c3bd4696bf6f87ed16629d01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab16e04169aa4254af178acf8897b863",
              "IPY_MODEL_8686ba24610a40f6967db0c27c3ca1ed"
            ]
          }
        },
        "af332db1c3bd4696bf6f87ed16629d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab16e04169aa4254af178acf8897b863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a957782832d24d81898ca4c8bbb99a1f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ba4085e1d794e6bb393187e3d145b9f"
          }
        },
        "8686ba24610a40f6967db0c27c3ca1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ae648fd853148838f5c7c8703cacae8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466/466 [00:58&lt;00:00, 7.95B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f66d07c62f034f03a1aecf07cc092607"
          }
        },
        "a957782832d24d81898ca4c8bbb99a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ba4085e1d794e6bb393187e3d145b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ae648fd853148838f5c7c8703cacae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f66d07c62f034f03a1aecf07cc092607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70842f56287442ec90afa451660a8eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66b8ff5b2c9f419e810a6aa007522fe4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0731d50d9f746c3aedabd7786aefab9",
              "IPY_MODEL_0fdd2d5c891d4b8fbb1a3eefb4749c4a"
            ]
          }
        },
        "66b8ff5b2c9f419e810a6aa007522fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0731d50d9f746c3aedabd7786aefab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4ae8ee43ef74b74aa922b4b6511c092",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 541808922,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 541808922,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c2edc05b0914516837e700bce367f65"
          }
        },
        "0fdd2d5c891d4b8fbb1a3eefb4749c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d8661dfccf94506850aff25fe36dea1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 542M/542M [00:10&lt;00:00, 53.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_077bdc7352e34282be21c2622f2c69a6"
          }
        },
        "c4ae8ee43ef74b74aa922b4b6511c092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c2edc05b0914516837e700bce367f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d8661dfccf94506850aff25fe36dea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "077bdc7352e34282be21c2622f2c69a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miataigeli/capstone_FHIS/blob/darya/bert_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xKLzIOjIkBE"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM1b2qIR2caa"
      },
      "source": [
        "In this notebook, we create a BERT pipeline to load the Multiligual BERT model and use it along with two linear layers to do a text classification task - to determine whether the text passed in is 'A' reading level or 'B'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-um0cGSk2X"
      },
      "source": [
        "Based on tutorial here: https://www.youtube.com/watch?v=mw7ay38--ak as well as the BERT tutorial from COLX585: https://github.ubc.ca/MDS-CL-2020-21/COLX_585_trends_students/blob/master/tutorials/BPE-BERT/bert_pytorch.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "injEHSVkWE1X"
      },
      "source": [
        "#### Imports and Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj0W0YOdIPi1",
        "outputId": "0d83bda0-fa17-45c8-de7f-2ea0c74178b4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak550KxaIpl1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IInqOgwdI5lb"
      },
      "source": [
        "#specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS80BGDmKUIS",
        "outputId": "2a11f14a-7de8-4056-dd53-c72e9366c23a"
      },
      "source": [
        "#connect to my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m7XORvdJGiw"
      },
      "source": [
        "### Load and Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMVVAVwdncO_"
      },
      "source": [
        "We read in the corpus of json created previously. For the classification, we will only need the text and its label, which are contained in the `content` and `level` columns, so those are the only ones we keep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VnN6jmTLkdJ",
        "outputId": "5b1a1140-5eb7-4275-f897-2f8f0a390125"
      },
      "source": [
        "# Read in all json files into one pandas dataframe\n",
        "import os\n",
        "\n",
        "corpus_dir = \"/content/drive/MyDrive/capstone/corpus\"\n",
        "corpus_df = pd.DataFrame([], columns = ['content', 'level'])\n",
        "\n",
        "for filename in os.listdir(corpus_dir):\n",
        "    if filename.endswith(\".json\"): \n",
        "         file_path = os.path.join(corpus_dir, filename)\n",
        "         df = pd.read_json(file_path)\n",
        "         df = df.drop(columns=['source', 'author', 'title'])\n",
        "         corpus_df = pd.concat([corpus_df, df])\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "print(corpus_df.describe())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  content level\n",
            "count                                                 308   308\n",
            "unique                                                308     5\n",
            "top     CApÍtULO 4\\n\\nEl local donde ensayan Los Ectop...    A1\n",
            "freq                                                    1    94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYx2n0zMRHcc",
        "outputId": "edb71f0a-5423-413e-ef50-7fdaf747f136"
      },
      "source": [
        "corpus_df['level'].value_counts(normalize = True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1    0.305195\n",
              "B     0.288961\n",
              "A2    0.201299\n",
              "B1    0.136364\n",
              "B2    0.068182\n",
              "Name: level, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o66HoaGRnnuX"
      },
      "source": [
        "As we can see, currently the text is classified into A1, A2, B1, B2 and B levels. This would make classification difficult, since the B level is very similar to the B1 and B2 levels. Therefore, for now we change the levels to A or B only, to simplify the classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4fp5EZYnY2m",
        "outputId": "c0322bd4-0549-448c-b4fc-deceedd983d4"
      },
      "source": [
        "# Change levels to A or B (for now)\n",
        "\n",
        "level_starts_with_A = corpus_df['level'].map(lambda x: x.startswith('A'))\n",
        "level_starts_with_B = corpus_df['level'].map(lambda x: x.startswith('B'))\n",
        "corpus_df.loc[level_starts_with_A, 'level'] = 0 # where the level in the df starts with A, replace level with 'A'\n",
        "corpus_df.loc[level_starts_with_B, 'level'] = 1 # where the level in the df starts with B, replace level with 'B'\n",
        "\n",
        "# print out to test if it worked\n",
        "corpus_df['level'].value_counts(normalize = True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.506494\n",
              "1    0.493506\n",
              "Name: level, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "iA4IDSupB7JJ",
        "outputId": "ace226b8-5783-4c64-86d4-223131b68fea"
      },
      "source": [
        "# Reduce size of corpus\n",
        "corpus_df = corpus_df.iloc[:30]\n",
        "corpus_df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>¡Hola! Mi nombre es Javier. Cuando era niño, m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  content  level\n",
              "count                                                  30     30\n",
              "unique                                                 30      2\n",
              "top     ¡Hola! Mi nombre es Javier. Cuando era niño, m...      0\n",
              "freq                                                    1     19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuqySScrIkyO",
        "outputId": "d21d1848-a58f-4e00-96e3-828d46052e84"
      },
      "source": [
        "corpus_df['level'].value_counts(normalize = True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.633333\n",
              "1    0.366667\n",
              "Name: level, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vab74dGRXHR"
      },
      "source": [
        "### Split into train, validation and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_9z-hUFsNls"
      },
      "source": [
        "We split the data into training, validation and test sets. TODO: make sure the split is the same as the one used for SVM for better comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekaasyTsJHsy"
      },
      "source": [
        "train_text, test_text, train_levels, test_levels = train_test_split(list(corpus_df['content']), list(corpus_df['level']),\n",
        "                                                                    random_state = 2021,\n",
        "                                                                    test_size = 0.3) #did not include stratify\n",
        "\n",
        "# split test into validation and test\n",
        "val_text, test_text, val_levels, test_levels = train_test_split(test_text, test_levels,\n",
        "                                                                random_state = 2021,\n",
        "                                                                test_size=0.5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5c0NQMV3V9p"
      },
      "source": [
        "We load the pretrained BERT model. We will test the Spanish model and the multilingual BERT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "54f4c2ff937242c5a64538ae4313b944",
            "be39cb44c9654d06b654120beb4cbdca",
            "5ebf0d8c5dd14ef1937415da488da51d",
            "9c926412c6694c7a90bf06d9cd59d390",
            "63eafc38297a40a9a348118d014b03e2",
            "bc2996d5698b4dcb99179aab925c13fe",
            "d41c484d49294e2ba7eacbe88a66bac1",
            "7104195be4194211bd9c382ccf42ebf2",
            "7553e8fba4494dd8a4e3cc1078f1fc10",
            "fb50a4418bb749a291e639ac446799bd",
            "b87cacf947b541c186150d7aecaa8e56",
            "92220c9762ea47b4908f3fe39cd1c565",
            "83607825f23c4904a7f2578ff1e94492",
            "29d7b060eff74adb91af36bc7e8a5fe3",
            "ef63bacd30fa462193434ca1719904a7",
            "731ece8baf364363af1d1e45d503a3ea",
            "d9b08eaff763485cb4b526fdd2757a69",
            "548049a87dec4d908dc0b863528510e1",
            "1d378c75c9904b5f96afb4688a887697",
            "7aab3e1436034eb69a3beab8c9e7ccc1",
            "6c7bd537826a4305a226dc88cfbf0cbf",
            "8eb87d09b17c418b90a2945d5d7a5619",
            "7029225c2711492c8e93ca8739c32831",
            "faaedacf3def488f8e6ee7331b92726a"
          ]
        },
        "id": "9NeauiSJ33Rm",
        "outputId": "f96fb657-d5c3-493b-d7af-0af9d213691f"
      },
      "source": [
        "# model_path = 'dccuchile/bert-base-spanish-wwm-uncased' # Spanish model TODO: cased or uncased?\n",
        "# model_path = 'bert-base-multilingual-cased' # multilingual model\n",
        "model_path = 'distilbert-base-multilingual-cased'\n",
        "# tokenizer from pre-trained BERT model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path, return_tensors='pt')\n",
        "# Define label to number dictionary (make it 0 and 1 to be able to use cross-entropy loss)\n",
        "lab2ind = {'A': 0,\n",
        "           'B': 1\n",
        "           }"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54f4c2ff937242c5a64538ae4313b944",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7553e8fba4494dd8a4e3cc1078f1fc10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9b08eaff763485cb4b526fdd2757a69",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "4a5a0582d3a34ee198cd1051525a550e",
            "af332db1c3bd4696bf6f87ed16629d01",
            "ab16e04169aa4254af178acf8897b863",
            "8686ba24610a40f6967db0c27c3ca1ed",
            "a957782832d24d81898ca4c8bbb99a1f",
            "7ba4085e1d794e6bb393187e3d145b9f",
            "8ae648fd853148838f5c7c8703cacae8",
            "f66d07c62f034f03a1aecf07cc092607",
            "70842f56287442ec90afa451660a8eff",
            "66b8ff5b2c9f419e810a6aa007522fe4",
            "a0731d50d9f746c3aedabd7786aefab9",
            "0fdd2d5c891d4b8fbb1a3eefb4749c4a",
            "c4ae8ee43ef74b74aa922b4b6511c092",
            "9c2edc05b0914516837e700bce367f65",
            "5d8661dfccf94506850aff25fe36dea1",
            "077bdc7352e34282be21c2622f2c69a6"
          ]
        },
        "id": "fqJ4VUD9NcKN",
        "outputId": "89d2df02-bbd5-4b8b-c2c4-6f76e4f50c13"
      },
      "source": [
        "# Download the bert model\n",
        "model_path = 'distilbert-base-multilingual-cased'\n",
        "bert_model = BertModel.from_pretrained(model_path, output_attentions = True).to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a5a0582d3a34ee198cd1051525a550e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70842f56287442ec90afa451660a8eff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=541808922.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing BertModel: ['distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'vocab_projector.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'pooler.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WLkZ3i040Ah"
      },
      "source": [
        "# Prepare data\n",
        "def prepare_data(text, levels):\n",
        "  ''' Preprocesses the data for classification. '''\n",
        "\n",
        "  # Tokenize text\n",
        "  tokenized_texts = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False, return_tensors='pt')\n",
        "\n",
        "  # Create label tensor\n",
        "  #labels = [lab2ind[i] for i in levels]\n",
        "  labels = torch.tensor(levels) #torch.tensor(labels)\n",
        "\n",
        "  # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "  # Truncate the texts at 512 since that is the maximum allowed input to BERT\n",
        "  input_ids = tokenized_texts['input_ids'][:, :300]\n",
        "  attention_masks = tokenized_texts['attention_mask'][:, :300]\n",
        "\n",
        "  # Convert all of our data into torch tensors, the required datatype for our model\n",
        "  inputs = torch.tensor(input_ids)\n",
        "  masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return inputs, labels, masks"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cESkbgF8BQKo",
        "outputId": "b4cfecd9-0403-4c6e-a6f6-8243b4329a6c"
      },
      "source": [
        "# Training data\n",
        "train_inputs, train_labels, train_masks = prepare_data(train_text, train_levels)\n",
        "print(train_inputs.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_masks.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([21, 300])\n",
            "torch.Size([21])\n",
            "torch.Size([21, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLKAj5UHE7VQ",
        "outputId": "0f9612b2-48d3-4520-b466-fc4a96320dc6"
      },
      "source": [
        "# Validation data\n",
        "valid_inputs, valid_labels, valid_masks = prepare_data(val_text, val_levels)\n",
        "print(valid_inputs.shape)\n",
        "print(valid_labels.shape)\n",
        "print(valid_masks.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 281])\n",
            "torch.Size([4])\n",
            "torch.Size([4, 281])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGSjlIj9FPfo",
        "outputId": "0e646f16-6f96-44ef-db48-f9938e174c95"
      },
      "source": [
        "# Test data\n",
        "test_inputs, test_labels, test_masks = prepare_data(test_text, test_levels)\n",
        "print(test_inputs.shape)\n",
        "print(test_labels.shape)\n",
        "print(test_masks.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([47, 512])\n",
            "torch.Size([47])\n",
            "torch.Size([47, 512])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbHcyc0F25rz"
      },
      "source": [
        "# Create an iterator for our data\n",
        "batch_size = 16\n",
        "# We'll take training samples in random order in each epoch. \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, \n",
        "                              sampler = RandomSampler(train_data), # Select batches randomly\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "# We'll just read validation set sequentially.\n",
        "validation_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
        "validation_dataloader = DataLoader(validation_data, \n",
        "                                   sampler = SequentialSampler(validation_data), # Pull out batches sequentially.\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGTfa7Oh_-Y_"
      },
      "source": [
        "#### Testing on one example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEj7ao0iN5va"
      },
      "source": [
        "dataiter = iter(train_dataloader)\n",
        "batch = dataiter.next()\n",
        "# Add batch to GPU\n",
        "batch = tuple(t.to(device) for t in batch)\n",
        "# Unpack the inputs from our dataloader\n",
        "input_ids, input_mask, labels = batch"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je3ScRbrXPlk",
        "outputId": "eab1e30c-57b1-46b0-ee62-0cd96bed4806"
      },
      "source": [
        "print(input_ids.shape)\n",
        "print(input_mask.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ4xjCPuN_wa",
        "outputId": "8f5d6cb3-86ce-44ba-ed37-467b05b9a92d"
      },
      "source": [
        "outputs = bert_model(input_ids, attention_mask = input_mask)\n",
        "print(outputs.keys())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['last_hidden_state', 'pooler_output', 'attentions'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J34ezobSkce",
        "outputId": "513c6e00-3301-4277-82b0-6deb8d527374"
      },
      "source": [
        "last_hidden_state = outputs[\"last_hidden_state\"]\n",
        "pooler_output = outputs[\"pooler_output\"]\n",
        "#hidden_states = outputs[\"hidden_states\"]\n",
        "#attentions = outputs[\"attentions\"]\n",
        "print(last_hidden_state.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlSmjknHz7Fw"
      },
      "source": [
        "The last dimension is 768 because that is the dimension of BERT encodings for the model we loaded. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfn5GV5PSmXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44860e23-1191-429b-f52a-a7d70922d108"
      },
      "source": [
        "dense = nn.Linear(768, 768).to(device)\n",
        "dropout = nn.Dropout(0.1).to(device)\n",
        "fc = nn.Linear(768, 2).to(device)\n",
        "softmax = nn.Softmax(dim=1)\n",
        "dense_output = dense(pooler_output)\n",
        "drop_output = dropout(dense_output)\n",
        "fc_output = fc(drop_output)\n",
        "fc_softmax_output = softmax(fc_output)\n",
        "\n",
        "print(fc_softmax_output)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4844, 0.5156],\n",
            "        [0.4706, 0.5294],\n",
            "        [0.4815, 0.5185],\n",
            "        [0.4866, 0.5134],\n",
            "        [0.4358, 0.5642],\n",
            "        [0.5017, 0.4983],\n",
            "        [0.4656, 0.5344],\n",
            "        [0.4936, 0.5064],\n",
            "        [0.4764, 0.5236],\n",
            "        [0.4427, 0.5573],\n",
            "        [0.4811, 0.5189],\n",
            "        [0.4551, 0.5449],\n",
            "        [0.4462, 0.5538],\n",
            "        [0.4343, 0.5657],\n",
            "        [0.4647, 0.5353],\n",
            "        [0.4764, 0.5236]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64GuTwYvTKP5",
        "outputId": "f16e4a4f-0ad5-4568-eee9-9f5c3cad1819"
      },
      "source": [
        "labels = labels.to(device)\n",
        "print(labels)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion(fc_softmax_output, labels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6849, device='cuda:0', grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y_r0nQbZC5Y"
      },
      "source": [
        "#### BERT Class\n",
        "\n",
        "We create a BERT class so that we have a pipeline to train the model. The class is initialized with the pretrained BERT model (that's been loaded in earlier code), a hidden layer size, two linear layers and a dropout. The `forward` method generates a BERT representation of the input using the pretrained model, passes the representations into the first linear layer, then to a TanH activation function and dropout function, and then to the final linear layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW5lHzTnmvH3"
      },
      "source": [
        "We use `pooler_output` as context representation and pass it to a fully connected layer which outputs the prediction probabilities across all labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8YSNixYm62t"
      },
      "source": [
        "Two new feed-forward layers for classification are added on top of BERT. Each input is a context representation (`pooler_output`) that is a 768-dimensional vector, and the output is the probability distribution across all labels that is a 5-dimensional vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M67qPgDQZFCS"
      },
      "source": [
        "#model_path = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
        "model_path = 'distilbert-base-multilingual-cased'\n",
        "class Bert_cls(nn.Module):\n",
        "\n",
        "    def __init__(self, lab2ind, model_path, hidden_size):\n",
        "        ''' Initializes the class. \n",
        "\n",
        "        Arguments: label to index dictionary, path to pretrained model, hidden layer size.\n",
        "\n",
        "        Returns: None\n",
        "\n",
        "        '''\n",
        "        super(Bert_cls, self).__init__()\n",
        "        self.model_path = model_path\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bert_model = BertModel.from_pretrained(model_path)\n",
        "        \n",
        "        self.label_num = len(lab2ind)\n",
        "        \n",
        "        self.dense = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.label_num)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        ''' Generates a BERT representation of the input using the pretrained model, \n",
        "        passes the representations into the first linear layer, then to a TanH activation function and dropout function,\n",
        "        and then to the final linear layer.\n",
        "        \n",
        "        Arguments: input_ids, attention mask\n",
        "\n",
        "        Returns: outputs of neural network and attention mask.\n",
        "        '''\n",
        "        outputs = self.bert_model(input_ids, attention_mask)\n",
        "        pooler_output = outputs['pooler_output']\n",
        "        #attentions = outputs['attentions']\n",
        "        \n",
        "        x = self.dense(pooler_output)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        fc_output = self.fc(x)\n",
        "\n",
        "        return fc_output#, attentions"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AQdDqRSZVw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14d3ef8-e2a8-4120-9525-a13d71043196"
      },
      "source": [
        "# Instantiate model\n",
        "model_path = 'distilbert-base-multilingual-cased'\n",
        "bert_model = Bert_cls(lab2ind, model_path, 768).to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing BertModel: ['distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'vocab_projector.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'pooler.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVnosKCWZi_t",
        "outputId": "0fc02ff5-06f8-4a59-f59c-f2728450710d"
      },
      "source": [
        "# Count number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(bert_model):,} trainable parameters')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 178,445,570 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf39H5euZpGc"
      },
      "source": [
        "#### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XkeKGhcZsPM"
      },
      "source": [
        "# Parameters:\n",
        "lr = 2e-5\n",
        "max_grad_norm = 1.0\n",
        "epochs = 10\n",
        "warmup_proportion = 0.1\n",
        "num_training_steps  = len(train_dataloader) * epochs\n",
        "num_warmup_steps = num_training_steps * warmup_proportion\n",
        "\n",
        "### In Transformers, optimizer and schedules are instantiated like this:\n",
        "# Note: AdamW is a class from the huggingface library\n",
        "# the 'W' stands for 'Weight Decay\"\n",
        "optimizer = AdamW(bert_model.parameters(), lr=lr, correct_bias=False)\n",
        "# schedules\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n",
        "\n",
        "# We use nn.CrossEntropyLoss() as our loss function. \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOoQVKArZ0Fe"
      },
      "source": [
        "# Training the model\n",
        "def train(model, iterator, optimizer, scheduler, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        input_ids, input_mask, labels = batch\n",
        "\n",
        "        # outputs,_ = model(input_ids, input_mask)\n",
        "        outputs = model(input_ids, input_mask)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        # delete used variables to free GPU memory\n",
        "        del batch, input_ids, input_mask, labels\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss += loss.cpu().item()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    # free GPU memory\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifWFXwEzZ335"
      },
      "source": [
        "# Evaluate function\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            input_ids, input_mask, labels = batch\n",
        "\n",
        "            outputs = model(input_ids, input_mask)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # delete used variables to free GPU memory\n",
        "            del batch, input_ids, input_mask\n",
        "            epoch_loss += loss.cpu().item()\n",
        "\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    return epoch_loss / len(iterator), accuracy, f1score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X993LzWmaBym"
      },
      "source": [
        "# create checkpoint directory\n",
        "import os\n",
        "save_path = './drive/My Drive/Colab Notebooks/ckpt_BERT/'\n",
        "if os.path.exists(save_path) == False:\n",
        "    os.makedirs(save_path)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6RJ3UreaCWp",
        "outputId": "ec1c0c14-a1da-48b7-db10-1f22041997b3"
      },
      "source": [
        "from tqdm import trange\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "# Train the model\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "    train_loss = train(bert_model, train_dataloader, optimizer, scheduler, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(bert_model, validation_dataloader, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': bert_model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt_BERT/BERT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, epochs, train_loss, val_loss, val_acc, val_f1))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 1/10 [00:53<08:01, 53.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [1/10], Train Loss: 0.6941, Validation Loss: 1.8138, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [01:14<05:51, 43.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [2/10], Train Loss: 0.7253, Validation Loss: 0.6542, Validation Accuracy: 0.7500, Validation F1: 0.4286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [01:37<04:21, 37.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [3/10], Train Loss: 0.6849, Validation Loss: 0.9764, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [01:59<03:16, 32.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [4/10], Train Loss: 0.4959, Validation Loss: 1.2869, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [02:21<02:28, 29.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [5/10], Train Loss: 0.5746, Validation Loss: 1.2609, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [02:43<01:49, 27.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [6/10], Train Loss: 0.6447, Validation Loss: 0.9942, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [03:10<01:21, 27.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [7/10], Train Loss: 0.5912, Validation Loss: 0.8479, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [03:32<00:51, 25.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [8/10], Train Loss: 0.5842, Validation Loss: 0.8989, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [03:55<00:24, 24.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [9/10], Train Loss: 0.5199, Validation Loss: 0.9439, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [04:28<00:00, 26.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [10/10], Train Loss: 0.5328, Validation Loss: 0.9625, Validation Accuracy: 0.2500, Validation F1: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njly0BBgP2x6"
      },
      "source": [
        "#### Testing Model\n",
        "\n",
        "Below, I test the model with one example that I took from the corpus manually. It predicts 'A' level, which is correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGQ8DOfzgr7w",
        "outputId": "16c30ecd-b3e2-4da8-dba4-290c4fbf7bcc"
      },
      "source": [
        "# Test model\n",
        "text = ['Un chico pelirrojo, un poco gordo, se les acerca sonriendo.\\n\\u2014Hola, M\\u00f3nica. Hola, Laura \\u2014dice.\\nEs Guillermo.\\n\\u2014Hola, Guille \\u2014contestan las chicas\\u2014. Llegas tarde.\\n\\u2014Es que me he dormido.\\n\\u2014S\\u00ed, ya lo veo.\\nGuillermo se sienta al lado de las chicas.\\n\\u2014\\u00bfC\\u00f3mo van? \\u2014pregunta.\\n\\u2014Perdemos por 3 a 1.\\n\\u2014\\u00bfDe verdad?\\n\\u2014S\\u00ed, es que...\\nUn grito interrumpe la conversaci\\u00f3n. \\u00ab\\u00a1Goool!\\u00bb.\\n\\u2014\\u00bfQui\\u00e9n ha marcado? \\u2014pregunta Laura.\\n\\u2014Nosotros.\\n\\u2014Ha marcado Ra\\u00fal, despu\\u00e9s de un pase de Sergio \\u2014explica M\\u00f3nica, contenta.\\n\\n\\ufffd\\n\\n4  f\\u00fatbol sala: modalidad del f\\u00fatbol que se juega en un recinto m\\u00e1s peque\\u00f1o, con \\ncinco jugadores por equipo.\\n\\n5  fase eliminatoria: fase de la competici\\u00f3n entre 16 equipos, anterior a los cuartos de final, entre los ocho mejores.']\n",
        "# Tokenize text\n",
        "tokenized_text = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False, return_tensors='pt')\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = tokenized_text['input_ids'].to(device)\n",
        "print(input_ids.shape)\n",
        "attention_masks = tokenized_text['attention_mask'].to(device)\n",
        "\n",
        "# # Convert all of our data into torch tensors, the required datatype for our model\n",
        "# input = torch.tensor(input_ids)\n",
        "# input = input.to(device)\n",
        "# mask = torch.tensor(attention_masks)\n",
        "# mask = mask.to(device)\n",
        "outputs = bert_model(input_ids, attention_masks)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 215])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmdSqhZRiuge",
        "outputId": "1a1edb3f-0f3f-4696-b8b6-529ec3ebef9c"
      },
      "source": [
        "print(outputs[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.4961, -0.2841], device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtUSRj7sinvm"
      },
      "source": [
        "ind2lab =  {0 :'A', 1: 'B'}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C8M6VW2imWI",
        "outputId": "f20c3388-ce6b-4d19-a14a-e21b4738b705"
      },
      "source": [
        "probabilities, predicted = torch.max(outputs[0].cpu().data,0)\n",
        "print(\"the prediction is: \", ind2lab[predicted.item()])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the prediction is:  A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3AvLzIoQKRQ"
      },
      "source": [
        "(TODO) Test on the test data.\n",
        "Note: this section is incomplete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjFeOw_SOqdk",
        "outputId": "ca68d03f-af8a-44f1-f18d-95a582a42b72"
      },
      "source": [
        "# Test data\n",
        "test_inputs, test_labels, test_masks = prepare_data(test_text, test_levels)\n",
        "print(test_inputs.shape)\n",
        "print(test_labels.shape)\n",
        "print(test_masks.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 300])\n",
            "torch.Size([5])\n",
            "torch.Size([5, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXvwPr3dRF4-",
        "outputId": "e789e323-53f8-40d7-d567-19ecde1a7763"
      },
      "source": [
        "bert_model = Bert_cls(lab2ind, model_path, 768).to(device)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing BertModel: ['distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'vocab_projector.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'pooler.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "bDv1QtoLQP5j",
        "outputId": "d59b2d32-8772-40fd-b07a-3d94848c735f"
      },
      "source": [
        "for test_input, test_mask in zip(test_inputs, test_masks):\n",
        "  outputs = bert_model(test_input, test_mask)\n",
        "  print(outputs)\n",
        "\n",
        "print(test_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c561aecfe450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-48f68c9e71f1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattention\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         '''\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mpooler_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pooler_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#attentions = outputs['attentions']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXAy4rnQzA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}